{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114c3550-18f8-450f-bb32-c58c39cdd83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/.deeplearningcourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import optuna\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing, visualization, param_optim, io_utils, model_io\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);\n",
    "importlib.reload(visualization);\n",
    "importlib.reload(param_optim);\n",
    "importlib.reload(io_utils);\n",
    "importlib.reload(model_io);\n",
    "\n",
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00aafdf9-702a-458b-9a47-95386993e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset creation\n",
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")\n",
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")\n",
    "\n",
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")\n",
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)\n",
    "\n",
    "with io_utils.suppress_output():\n",
    "    time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True);\n",
    "    train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "    \n",
    "    train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "    test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c9db9-3ae8-412b-9583-b349a18fdcbb",
   "metadata": {},
   "source": [
    "### Encoder decoder without id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8437572-89ee-4475-8edd-fe59c408d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition with parameters\n",
    "\n",
    "def define_model_encdec(trial):\n",
    "\n",
    "    # === Hyperparameters (Optuna) ===\n",
    "    encoder_layers = trial.suggest_int(\"encoder_layer_num\", 2, 5)\n",
    "    decoder_layers = trial.suggest_int(\"decoder_layer_num\", 2, 5)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4, step=0.1)   \n",
    "    \n",
    "    \n",
    "    ts_emb_dim=32\n",
    "    n_diff=2\n",
    "    ts_dim=n_diff+1\n",
    "    \n",
    "    pos_embedder=training.pos_emb_cross_attn(length=60,\n",
    "                                             ts_dim=ts_dim,\n",
    "                                             emb_dim=ts_emb_dim,\n",
    "                                             dropout=0.2,\n",
    "                                             num_heads=4,\n",
    "                                             keep_mag=True).to(device=device)\n",
    "    ts_encoder_ff_layer=[\n",
    "        nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "    ]\n",
    "    \n",
    "    ts_decoder_ff_layer=[\n",
    "        nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "    ]\n",
    "    \n",
    "    output_ff=nn.Sequential(\n",
    "        nn.Linear(in_features=ts_emb_dim,out_features=1)\n",
    "    ).to(device=device)\n",
    "\n",
    "\n",
    "    return training.encoder_decoder_teacherforcing(\n",
    "        pos_emb_model=pos_embedder,\n",
    "        output_feedforward=output_ff,\n",
    "        encoder_dropout=dropout,\n",
    "        decoder_dropout=dropout,\n",
    "        encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "        decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "        n_diff=n_diff,\n",
    "        encoder_layer_num=encoder_layers,\n",
    "        decoder_layer_num=decoder_layers,\n",
    "        input_scaler=10000,\n",
    "        ts_emb_dim=ts_emb_dim,\n",
    "        encoder_num_heads=4,\n",
    "        decoder_num_heads=4,\n",
    "        encoder_keep_mag=True,\n",
    "        decoder_keep_mag=True,\n",
    "        return_sum=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af502d7-9d63-404c-951d-1c7a176ec257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 01:56:12,649] A new study created in memory with name: no-name-88af6e0d-968d-473f-9b27-524235b48d9f\n",
      "[I 2025-08-08 01:59:28,976] Trial 0 finished with value: 0.23366540670394897 and parameters: {'lr': 2.9167838844166082e-05, 'weight_decay': 0.0003560543616195853, 'encoder_layer_num': 2, 'decoder_layer_num': 2, 'dropout': 0.0}. Best is trial 0 with value: 0.23366540670394897.\n",
      "[I 2025-08-08 02:05:13,231] Trial 1 finished with value: 0.23018623888492584 and parameters: {'lr': 0.00021027011561293717, 'weight_decay': 1.4468200365481732e-05, 'encoder_layer_num': 3, 'decoder_layer_num': 4, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 02:12:56,232] Trial 2 finished with value: 0.23256000876426697 and parameters: {'lr': 3.15003492135008e-05, 'weight_decay': 8.974867995287607e-06, 'encoder_layer_num': 5, 'decoder_layer_num': 5, 'dropout': 0.4}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 02:20:39,658] Trial 3 finished with value: 0.2341141402721405 and parameters: {'lr': 1.684063615833117e-05, 'weight_decay': 1.078361871516022e-06, 'encoder_layer_num': 5, 'decoder_layer_num': 5, 'dropout': 0.4}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 02:27:18,580] Trial 4 finished with value: 0.23137004673480988 and parameters: {'lr': 8.48455444672687e-05, 'weight_decay': 0.00033262196831558967, 'encoder_layer_num': 3, 'decoder_layer_num': 5, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 02:31:11,069] Trial 5 finished with value: 0.23124082386493683 and parameters: {'lr': 0.0002478978154962961, 'weight_decay': 1.660153170799623e-05, 'encoder_layer_num': 3, 'decoder_layer_num': 2, 'dropout': 0.4}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 02:34:00,272] Trial 6 pruned. \n",
      "[I 2025-08-08 02:36:07,729] Trial 7 pruned. \n",
      "[I 2025-08-08 02:42:01,381] Trial 8 finished with value: 0.23130057752132416 and parameters: {'lr': 0.0002900272370035192, 'weight_decay': 1.0179926835577474e-05, 'encoder_layer_num': 5, 'decoder_layer_num': 3, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 02:45:48,425] Trial 9 pruned. \n",
      "[I 2025-08-08 02:51:40,757] Trial 10 finished with value: 0.23043464124202728 and parameters: {'lr': 0.0011919782410628155, 'weight_decay': 8.493938174347568e-05, 'encoder_layer_num': 4, 'decoder_layer_num': 4, 'dropout': 0.0}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 02:54:36,287] Trial 11 pruned. \n",
      "[I 2025-08-08 03:00:48,450] Trial 12 finished with value: 0.23066405951976776 and parameters: {'lr': 0.0009065687996400788, 'weight_decay': 6.662017175405134e-05, 'encoder_layer_num': 4, 'decoder_layer_num': 4, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:05:22,810] Trial 13 finished with value: 0.23036466538906097 and parameters: {'lr': 0.0006819147567379647, 'weight_decay': 0.002792851888153698, 'encoder_layer_num': 3, 'decoder_layer_num': 3, 'dropout': 0.0}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:07:59,679] Trial 14 pruned. \n",
      "[I 2025-08-08 03:12:45,775] Trial 15 finished with value: 0.23060381412506104 and parameters: {'lr': 0.0007161433338969292, 'weight_decay': 0.007358181765879434, 'encoder_layer_num': 3, 'decoder_layer_num': 3, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:16:37,961] Trial 16 finished with value: 0.23222987353801727 and parameters: {'lr': 0.00012182912662359857, 'weight_decay': 0.0010146177853422695, 'encoder_layer_num': 3, 'decoder_layer_num': 2, 'dropout': 0.2}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:18:39,063] Trial 17 pruned. \n",
      "[I 2025-08-08 03:21:02,118] Trial 18 pruned. \n",
      "[I 2025-08-08 03:24:06,682] Trial 19 pruned. \n",
      "[I 2025-08-08 03:25:43,217] Trial 20 pruned. \n",
      "[I 2025-08-08 03:31:34,626] Trial 21 finished with value: 0.23076514899730682 and parameters: {'lr': 0.0015781687598896662, 'weight_decay': 0.0002012234872123392, 'encoder_layer_num': 4, 'decoder_layer_num': 4, 'dropout': 0.0}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:36:56,598] Trial 22 finished with value: 0.2311791628599167 and parameters: {'lr': 0.0004990217678540009, 'weight_decay': 3.686060119913815e-05, 'encoder_layer_num': 3, 'decoder_layer_num': 4, 'dropout': 0.0}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:43:58,771] Trial 23 finished with value: 0.2308475375175476 and parameters: {'lr': 0.0016725067946823748, 'weight_decay': 0.00013660358553638016, 'encoder_layer_num': 4, 'decoder_layer_num': 5, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:46:39,571] Trial 24 pruned. \n",
      "[I 2025-08-08 03:51:55,929] Trial 25 finished with value: 0.2303067296743393 and parameters: {'lr': 0.0004122643776936505, 'weight_decay': 0.0007697236901430989, 'encoder_layer_num': 4, 'decoder_layer_num': 3, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 03:56:41,054] Trial 26 finished with value: 0.23074688017368317 and parameters: {'lr': 0.0004799607394831784, 'weight_decay': 0.0035674511189192374, 'encoder_layer_num': 3, 'decoder_layer_num': 3, 'dropout': 0.2}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 04:01:57,070] Trial 27 finished with value: 0.2314687818288803 and parameters: {'lr': 0.00018506300956204437, 'weight_decay': 0.0010665135009528522, 'encoder_layer_num': 4, 'decoder_layer_num': 3, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 04:07:43,939] Trial 28 finished with value: 0.23105290532112122 and parameters: {'lr': 0.00035371862945120756, 'weight_decay': 0.0007822941669307076, 'encoder_layer_num': 5, 'decoder_layer_num': 3, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 04:09:24,569] Trial 29 pruned. \n",
      "[I 2025-08-08 04:13:16,718] Trial 30 finished with value: 0.23067036271095276 and parameters: {'lr': 0.002508197199846942, 'weight_decay': 0.0003672625684441754, 'encoder_layer_num': 3, 'decoder_layer_num': 2, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 04:19:07,684] Trial 31 finished with value: 0.23022258281707764 and parameters: {'lr': 0.0007913946660519695, 'weight_decay': 0.001656853362350561, 'encoder_layer_num': 4, 'decoder_layer_num': 4, 'dropout': 0.0}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 04:24:58,586] Trial 32 finished with value: 0.23081740736961365 and parameters: {'lr': 0.0008718571631615826, 'weight_decay': 0.001778893719525921, 'encoder_layer_num': 4, 'decoder_layer_num': 4, 'dropout': 0.0}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 04:28:33,840] Trial 33 pruned. \n",
      "[I 2025-08-08 04:31:11,915] Trial 34 pruned. \n",
      "[I 2025-08-08 04:34:17,827] Trial 35 pruned. \n",
      "[I 2025-08-08 04:40:27,020] Trial 36 finished with value: 0.23053881525993347 and parameters: {'lr': 0.00026871893863874863, 'weight_decay': 0.0014028200828527931, 'encoder_layer_num': 4, 'decoder_layer_num': 4, 'dropout': 0.1}. Best is trial 1 with value: 0.23018623888492584.\n",
      "[I 2025-08-08 04:42:49,720] Trial 37 pruned. \n",
      "[I 2025-08-08 04:46:00,129] Trial 38 pruned. \n",
      "[I 2025-08-08 04:48:38,268] Trial 39 pruned. \n"
     ]
    }
   ],
   "source": [
    "# Study creation\n",
    "study_encdec = optuna.create_study(direction=\"minimize\",\n",
    "                                   pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=4)\n",
    "                                  )\n",
    "\n",
    "study_encdec.optimize(lambda trial: param_optim.objective(trial,\n",
    "                                                          define_model_encdec,\n",
    "                                                          train_loader,\n",
    "                                                          test_loader,\n",
    "                                                          device\n",
    "                                                         ), n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c8e994-6962-456d-b92e-bdfd39cdf146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.23018623888492584\n",
      "    lr: 0.00021027011561293717\n",
      "    weight_decay: 1.4468200365481732e-05\n",
      "    encoder_layer_num: 3\n",
      "    decoder_layer_num: 4\n",
      "    dropout: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Just while debugging let's take a look at best hyperparameters\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study_encdec.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559a3cba-f099-4152-8c63-edfdef08bd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model_data/Encoder_decoder/checkpoint_study.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing hyperparameters is costly, let us save them here just while debugging\n",
    "\n",
    "save_dir = \"../model_data/Encoder_decoder/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(study_encdec, os.path.join(save_dir, \"checkpoint_study.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4af1c2-e650-4f4e-865c-96d9149faa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training using optimal hyperparameters\n",
    "\n",
    "best_trial_encdec = study_encdec.best_trial\n",
    "model_encdec = define_model_encdec(optuna.trial.FixedTrial(best_trial_encdec.params)).to(device)\n",
    "\n",
    "atts_encdec = study_encdec.best_trial.user_attrs\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_encdec.parameters(), \n",
    "                              lr=best_trial_encdec.params[\"lr\"], \n",
    "                              weight_decay=best_trial_encdec.params[\"weight_decay\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode=\"min\",\n",
    "                                                       factor=atts_encdec[\"scheduler_factor\"],\n",
    "                                                       patience=atts_encdec[\"scheduler_patience\"],\n",
    "                                                       threshold=atts_encdec[\"threshold\"],\n",
    "                                                       cooldown=atts_encdec[\"cooldown\"],\n",
    "                                                       min_lr=atts_encdec[\"scheduler_min_lr\"])\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "encdec_best_weights=training.reg_training_loop_rmspe(\n",
    "    optimizer=optimizer,\n",
    "    model=model_encdec,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    ot_steps=20,\n",
    "    report_interval=5,\n",
    "    n_epochs=200,\n",
    "    list_train_loss=train_loss,\n",
    "    list_val_loss=val_loss,\n",
    "    device=device,\n",
    "    eps=1e-8,\n",
    "    scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafe1e2-6183-4468-ae93-1d7d7b5a8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss after training and saves plot\n",
    "\n",
    "vis_dict={(\"encoder-decoder\",\"no id\"):{\"train_loss\": train_loss,\"val_loss\": val_loss}}\n",
    "visualization.training_plots(vis_dict, fig_width=7, save_path=save_dir+\"encdec_loss_fromtraining.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf429667-32c8-4fec-b3eb-181c0d7a9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load\n",
    "\n",
    "model_io.save_model_and_study(\n",
    "    model_encdec,\n",
    "    study_encdec,\n",
    "    save_dir=\"../model_data/Encoder_decoder\",\n",
    "    weights_filename=\"encdec_best_weights.pth\",\n",
    "    study_filename=\"encdec_study.pkl\"\n",
    ")\n",
    "\n",
    "model_encdec, study_encdec = model_io.load_model_and_study(\n",
    "    define_model_encdec,\n",
    "    device,\n",
    "    save_dir=\"../model_data/Encoder_decoder\",\n",
    "    weights_filename=\"encdec_best_weights.pth\",\n",
    "    study_filename=\"encdec_study.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a704acb6-8af1-403a-8d31-20a6c0151cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reproduce loss, useful if the weigths were just loaded to the model\n",
    "train_loss_value = param_optim.validate(model_encdec, train_loader, device, eps=1e-8)\n",
    "val_loss_value = param_optim.validate(model_encdec, test_loader, device, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704447b-a856-4aee-9997-b9085f013a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the loss and saves the plot\n",
    "vis_dict={(\"encoder-decoder\",\"no id\"):{\"train_loss\": train_loss,\"val_loss\": val_loss}}\n",
    "visualization.training_plots(vis_dict, fig_width=7, save_path=save_dir+\"encdec_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c3bc7-1edb-45ed-a425-7a60eadceaba",
   "metadata": {},
   "source": [
    "### Encoder decoder with id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d4276-8eca-4e48-a613-fcf0d001db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset creation\n",
    "RV_tab=pd.read_csv(\"../processed_data/RV_by_row_id.csv\")\n",
    "RV_tab[\"stock_id\"]=RV_tab[\"row_id\"].apply(lambda x: x.split(\"-\")[0])\n",
    "RV_tab[\"time_id\"]=RV_tab[\"row_id\"].apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "# Creates tabular data, most specifically 'emb_id'\n",
    "unique_ids = sorted(RV_tab['stock_id'].unique())\n",
    "id_to_emb = {stock_id: i for i, stock_id in enumerate(unique_ids)}\n",
    "RV_tab['emb_id'] = RV_tab['stock_id'].map(id_to_emb)\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)\n",
    "\n",
    "ts_place, id_place=train_dataset.featureplace[\"sub_int_RV\"], train_dataset.featureplace[\"emb_id\"]\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39070a53-3785-4407-b3ff-68647c2d2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition with parameters\n",
    "def define_model_encdec_id(trial):\n",
    "    encoder_layers = trial.suggest_int(\"encoder_layer_num\", 2, 6)\n",
    "    decoder_layers = trial.suggest_int(\"decoder_layer_num\", 2, 6)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)   \n",
    "\n",
    "    base_model =training.encoder_decoder_teacherforcing(\n",
    "        pos_emb_model=pos_embedder,\n",
    "        output_feedforward=output_ff,\n",
    "        encoder_dropout=dropout,\n",
    "        decoder_dropout=dropout,\n",
    "        encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "        decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "        n_diff=n_diff,\n",
    "        encoder_layer_num=encoder_layers,\n",
    "        decoder_layer_num=decoder_layers, \n",
    "        input_scaler=10000,\n",
    "        ts_emb_dim=ts_emb_dim,\n",
    "        encoder_num_heads=4,\n",
    "        decoder_num_heads=4,\n",
    "        encoder_keep_mag=True,\n",
    "        decoder_keep_mag=True,\n",
    "        return_sum=True\n",
    "    )\n",
    "\n",
    "    id_emb_dim=8\n",
    "    id_hidden_dict=OrderedDict([(\"linear1\", nn.Linear(in_features=id_emb_dim, out_features=32),),\n",
    "                                (\"tanh1\", nn.Tanh()),\n",
    "                                (\"linear2\", nn.Linear(in_features=32, out_features=16)),\n",
    "                                (\"tanh2\", nn.Tanh()),\n",
    "                                (\"linear3\", nn.Linear(in_features=16, out_features=8)),\n",
    "                                (\"tanh3\", nn.Tanh()),\n",
    "                                (\"linear4\", nn.Linear(in_features=8,out_features=1))])\n",
    "    id_hidden_layers=nn.Sequential(id_hidden_dict).to(device=device)\n",
    "\n",
    "    return training.id_learned_embedding_adj_rnn_mtpl(ts_place=ts_place,\n",
    "                                             id_place=id_place, \n",
    "                                             rnn_model=base_model,\n",
    "                                             id_hidden_model=id_hidden_layers,\n",
    "                                             id_input_num=112,\n",
    "                                             emb_dim=id_emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75235f-69e1-4045-b3f0-dbd311b7e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study creation\n",
    "study_encdec_id = optuna.create_study(direction=\"minimize\",\n",
    "                                   pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=4)\n",
    "                                  )\n",
    "\n",
    "study_encdec_id.optimize(lambda trial: param_optim.objective(trial,\n",
    "                                                          define_model_encdec_id,\n",
    "                                                          train_loader,\n",
    "                                                          test_loader,\n",
    "                                                          device\n",
    "                                                         ), n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f62d7-38a1-4ae5-9846-67bdfe6a331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training using optimal hyperparameters\n",
    "\n",
    "best_trial_encdec_id = study_encdec_id.best_trial\n",
    "model_encdec_id = define_model_encdec_id(optuna.trial.FixedTrial(best_trial_encdec_id.params)).to(device)\n",
    "\n",
    "atts_encdec = study_encdec_id.best_trial.user_attrs\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_encdec_id.parameters(), \n",
    "                              lr=best_trial_encdec_id.params[\"lr\"], \n",
    "                              weight_decay=best_trial_encdec_id.params[\"weight_decay\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode=\"min\",\n",
    "                                                       factor=atts_encdec[\"scheduler_factor\"],\n",
    "                                                       patience=atts_encdec[\"scheduler_patience\"],\n",
    "                                                       threshold=atts_encdec[\"threshold\"],\n",
    "                                                       cooldown=atts_encdec[\"cooldown\"],\n",
    "                                                       min_lr=atts_encdec[\"scheduler_min_lr\"])\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "encdec__id_best_weights=training.reg_training_loop_rmspe(\n",
    "    optimizer=optimizer,\n",
    "    model=model_encdec,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    ot_steps=20,\n",
    "    report_interval=5,\n",
    "    n_epochs=200,\n",
    "    list_train_loss=train_loss,\n",
    "    list_val_loss=val_loss,\n",
    "    device=device,\n",
    "    eps=1e-8,\n",
    "    scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3977117-4a94-4f1f-9dac-7c5170042a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load\n",
    "model_io.save_model_and_study(\n",
    "    model_encdec_id,\n",
    "    study_encdec_id,\n",
    "    save_dir=\"../model_data/Encoder_decoder\",\n",
    "    weights_filename=\"encdec_id_best_weights.pth\",\n",
    "    study_filename=\"encdec_id_study.pkl\"\n",
    ")\n",
    "\n",
    "model_encdec_id, study_encdec_id = model_io.load_model_and_study(\n",
    "    define_model_encdec_id,\n",
    "    device,\n",
    "    save_dir=\"../model_data/Encoder_decoder\",\n",
    "    weights_filename=\"encdec_id_best_weights.pth\",\n",
    "    study_filename=\"encdec_id_study.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59f6b7-15bc-48e3-b6c6-06cb248f71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reproduce loss, useful if the weigths were just loaded to the model\n",
    "train_loss_value = param_optim.validate(model_encdec_id, train_loader, device, eps=1e-8)\n",
    "val_loss_value = param_optim.validate(model_encdec_id, test_loader, device, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19dd35-bc1a-4381-91a3-9d288910473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the loss and saves the plot\n",
    "vis_dict={(\"encoder-decoder\",\"no id\"):{\"train_loss\": train_loss,\"val_loss\": val_loss}}\n",
    "visualization.training_plots(vis_dict, fig_width=7, save_path=save_dir+\"encdec_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a906bd-eb5a-44ed-a407-2cfdc73b8d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3871e-39fb-4352-adfa-69c1d2af7ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ec027-61a9-4968-aa7a-ebe4ad95fa62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c25ccb-1bc2-4f8b-a557-1f0d4076cd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c87e9f-58e9-49c1-9c21-59d0a3925e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede7a12-26ad-4b06-9ba1-7a2c74442621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can this help with optuna optimization?\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler(\n",
    "#     seed=42,\n",
    "#     multivariate=True,      # model interactions\n",
    "#     n_startup_trials=8,     # more random exploration up front\n",
    "#     n_ei_candidates=64      # try more candidates each step\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ebb70-0c1e-475e-b7cd-5576af39bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some legacy code (before creating external functions) just in case\n",
    "\n",
    "\n",
    "# Save model and study\n",
    "\n",
    "# save_dir = \"../model_data/Encoder_decoder/\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# torch.save(model_encdec.state_dict(), os.path.join(save_dir, \"encdec_best_weights.pth\"))\n",
    "# joblib.dump(study_encdec, os.path.join(save_dir, \"encdec_study.pkl\"))\n",
    "\n",
    "\n",
    "\n",
    "# Load model and study and re-create model\n",
    "\n",
    "# save_dir = \"../model_data/Encoder_decoder/\"\n",
    "\n",
    "# study_encdec = joblib.load(os.path.join(save_dir, \"encdec_study.pkl\"))\n",
    "# best_trial_encdec = study_encdec.best_trial\n",
    "\n",
    "\n",
    "# model_encdec = define_model_encdec(optuna.trial.FixedTrial(best_trial_encdec.params)).to(device)\n",
    "# state = torch.load(os.path.join(save_dir, \"encdec_best_weights.pth\"), map_location=device)\n",
    "# model_encdec.load_state_dict(state)\n",
    "# with io_utils.suppress_output():\n",
    "#     model_encdec.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
