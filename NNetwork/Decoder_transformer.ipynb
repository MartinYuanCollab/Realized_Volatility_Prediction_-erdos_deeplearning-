{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08fd6fa5",
   "metadata": {},
   "source": [
    "# A transformer with both encoder and decoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e831d0a",
   "metadata": {},
   "source": [
    "### Intuitively, encoders \"understand and interpret\", while decoders \"write and describe\". In file Transformer_with_frozen_conv_1.ipynb, we opted for only using encoder: Our goal is timeseries regression (in the sense that we are looking to create one singular value as the target) and not timeseries prediction (In the sense that we are looking to create a new timeseries), so there was no need for us to implement a decoder to \"create a new timeseries in sequence\". However, it is a fact that our target value is the sum up a new timeseries, so, we now investigate in using autoregression with decoder to generate a new timeseries and then sum its time steps up. It is unclear if this will help at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1a1a7",
   "metadata": {},
   "source": [
    "## Import and preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94c730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing, visualization\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);\n",
    "importlib.reload(visualization);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8353533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3.0\n"
     ]
    }
   ],
   "source": [
    "#Only run this cell if needed. AMD gpus might need this. \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\" # To, possibly fix memory leak issues. \n",
    "\n",
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374d9d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c78ae",
   "metadata": {},
   "source": [
    "## Data preparations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158aba2",
   "metadata": {},
   "source": [
    "### Load time id order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb76708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463a251",
   "metadata": {},
   "source": [
    "### Load timeseries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1924dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abd4d6",
   "metadata": {},
   "source": [
    "### Load target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d11c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")\n",
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)\n",
    "df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42e128",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abdd64d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:396: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:396: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e3e8e2",
   "metadata": {},
   "source": [
    "## The model (Only autoregression, no teacher forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26b507",
   "metadata": {},
   "source": [
    "### As mentioned, we will use autoregression with decoder to create a new timeseries. One thing to note is that we will NOT be implementing teacher forcing with masked decoder for now. Teacher forcing is a powerful tool, but the context is not the same: We do not have another timeseries to as ground truth to train toward, so we have \"nothing to hide\" with the masking. Instead of teacher forcing, we are using the loss calculated with the actual target (future RV) and the aoturegression created timeseries to train. This might not even be possible: I foresee memory explosion since, normally, autoregression is done with no_grad() context and can take a huge amount of memory (since grad will keep the computation graph, which is HUGE if we are doing autoregression). But we will see. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7183172",
   "metadata": {},
   "source": [
    "### Create the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e1d23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d948c",
   "metadata": {},
   "source": [
    "### Create components needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7383b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_emb_dim=32\n",
    "n_diff=2\n",
    "ts_dim=n_diff+1\n",
    "\n",
    "pos_embedder=training.pos_emb_cross_attn(length=60,ts_dim=ts_dim,emb_dim=ts_emb_dim,dropout=0.2,num_heads=4,keep_mag=True).to(device=device)\n",
    "\n",
    "ts_encoder_ff_layer=[\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "]\n",
    "\n",
    "ts_decoder_ff_layer=[\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "]\n",
    "\n",
    "output_ff=nn.Sequential(\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=1)\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed9678",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e76560c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_encoder_decoder_model=training.encoder_decoder_autoregressionOnly(\n",
    "    pos_emb_model=pos_embedder,\n",
    "    output_feedforward=output_ff,\n",
    "    encoder_dropout=0.2,\n",
    "    decoder_dropout=0.2,\n",
    "    encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "    decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "    n_diff=n_diff,\n",
    "    encoder_layer_num=2,\n",
    "    decoder_layer_num=2,\n",
    "    input_scaler=10000,\n",
    "    ts_emb_dim=ts_emb_dim,\n",
    "    encoder_num_heads=4,\n",
    "    decoder_num_heads=4,\n",
    "    encoder_keep_mag=True,\n",
    "    decoder_keep_mag=True,\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff33d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(trans_encoder_decoder_model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode=\"min\",factor=0.5,patience=5,min_lr=1e-7)\n",
    "\n",
    "# Loss tracking\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15bc3951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "encoder_decoder_autoregressionOnly                           --\n",
       "â”œâ”€frozen_diff_conv: 1-1                                      --\n",
       "â”‚    â””â”€Conv1d: 2-1                                           (2)\n",
       "â”œâ”€pos_emb_cross_attn: 1-2                                    --\n",
       "â”‚    â””â”€Linear: 2-2                                           128\n",
       "â”‚    â””â”€Embedding: 2-3                                        1,920\n",
       "â”‚    â””â”€MultiheadAttention: 2-4                               3,168\n",
       "â”‚    â”‚    â””â”€NonDynamicallyQuantizableLinear: 3-1             1,056\n",
       "â”‚    â””â”€LayerNorm: 2-5                                        64\n",
       "â”œâ”€ModuleList: 1-3                                            --\n",
       "â”‚    â””â”€ts_encoder: 2-6                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-2                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-3                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-4                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-5                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-7                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-6                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-7                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-8                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-9                                   64\n",
       "â”œâ”€ModuleList: 1-4                                            --\n",
       "â”‚    â””â”€ts_decoder: 2-8                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-10                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-11                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-12                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-13                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-14                                 4,192\n",
       "â”‚    â””â”€ts_decoder: 2-9                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-15                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-16                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-17                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-18                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-19                                 4,192\n",
       "â”œâ”€Sequential: 1-5                                            --\n",
       "â”‚    â””â”€Linear: 2-10                                          33\n",
       "=====================================================================================\n",
       "Total params: 48,995\n",
       "Trainable params: 48,993\n",
       "Non-trainable params: 2\n",
       "====================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(trans_encoder_decoder_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67e7b1",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3366e38",
   "metadata": {},
   "source": [
    "### As of now, the model has issue with memory: it is using all the 12 GB of my AMD GPU. I need to look deeper in attempt to fix this. According to my reading, since grad context keeps all the computation graphs, and autoregression may have HUGE graph, this is kinda expected. The only way, for now, I can see to bypass this is doing teacher training and doing autoregression under no_grad() context. But we will see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eff097ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new best validation loss at epoch  1  with validation loss of  tensor(0.2411, device='cuda:0') .\n",
      "At  369.77681493759155  epoch  1 has training loss  tensor(0.3011, device='cuda:0')  and validation loss  tensor(0.2411, device='cuda:0') .\n",
      "\n",
      "All  1  epochs have been completed.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 1  with validation loss:  tensor(0.2411, device='cuda:0') .\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "Training completed. 369.77681493759155 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('pos_emb.ts_proj.weight',\n",
       "              tensor([[-0.3843, -0.3015, -0.0931],\n",
       "                      [ 0.4646,  0.3181, -0.4585],\n",
       "                      [ 0.0774,  0.2500,  0.1523],\n",
       "                      [ 0.2109,  0.0603, -0.2079],\n",
       "                      [ 0.3515,  0.5568, -0.5259],\n",
       "                      [-0.4578,  0.0814, -0.4787],\n",
       "                      [ 0.2437, -0.5187, -0.3568],\n",
       "                      [ 0.0760, -0.1143,  0.5240],\n",
       "                      [-0.5289,  0.5211,  0.0415],\n",
       "                      [-0.2832, -0.3558, -0.1094],\n",
       "                      [ 0.4084,  0.3462, -0.3008],\n",
       "                      [-0.1695,  0.0738, -0.5456],\n",
       "                      [ 0.3674, -0.2036, -0.4466],\n",
       "                      [ 0.1383, -0.3125, -0.2650],\n",
       "                      [ 0.0036, -0.5362,  0.3534],\n",
       "                      [-0.0999, -0.3039,  0.3064],\n",
       "                      [-0.2338,  0.3621, -0.5526],\n",
       "                      [-0.4418,  0.0477, -0.3004],\n",
       "                      [-0.1954,  0.4903,  0.5681],\n",
       "                      [ 0.4248,  0.4640,  0.4794],\n",
       "                      [ 0.1650, -0.0639,  0.3811],\n",
       "                      [-0.1792,  0.5349,  0.1316],\n",
       "                      [ 0.0345,  0.2335,  0.5026],\n",
       "                      [-0.0077,  0.4935, -0.2814],\n",
       "                      [-0.3503,  0.0725, -0.2852],\n",
       "                      [-0.1249, -0.1399,  0.4298],\n",
       "                      [-0.3922,  0.3206, -0.3095],\n",
       "                      [ 0.3171,  0.2101, -0.4913],\n",
       "                      [ 0.1663, -0.3908,  0.5430],\n",
       "                      [ 0.4753, -0.4124, -0.1314],\n",
       "                      [ 0.4739,  0.4467,  0.5144],\n",
       "                      [ 0.1076, -0.4088, -0.2895]], device='cuda:0')),\n",
       "             ('pos_emb.ts_proj.bias',\n",
       "              tensor([-0.2782, -0.5402, -0.2169, -0.2954,  0.4690, -0.2290,  0.0028,  0.4469,\n",
       "                       0.5098,  0.4918, -0.0556, -0.5558,  0.1103,  0.1639,  0.4841,  0.2579,\n",
       "                       0.2104,  0.5137, -0.0683, -0.5424, -0.5627,  0.3916, -0.3379,  0.1544,\n",
       "                      -0.0704, -0.3200,  0.4124, -0.5739, -0.0873, -0.0248, -0.5528,  0.4997],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_emb.weight',\n",
       "              tensor([[ 0.6239,  1.8906, -0.3432,  ...,  0.4540, -1.3568,  0.2550],\n",
       "                      [-0.1570,  1.3685,  0.6564,  ..., -0.3325, -0.2218,  1.1987],\n",
       "                      [-0.3693, -0.2851, -1.3745,  ...,  0.6232, -1.1161, -0.2023],\n",
       "                      ...,\n",
       "                      [-0.1397, -0.7295,  1.2254,  ...,  0.6887, -0.2607,  0.0175],\n",
       "                      [-1.5176, -0.1922,  0.9753,  ...,  0.0901,  0.3425, -0.1456],\n",
       "                      [ 0.3700,  2.2620, -0.4109,  ...,  1.1165, -0.4045, -0.1576]],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.in_proj_weight',\n",
       "              tensor([[-0.1983, -0.0139,  0.0996,  ..., -0.1037,  0.0413, -0.1781],\n",
       "                      [ 0.1650,  0.1355, -0.0774,  ...,  0.0965,  0.1798,  0.0266],\n",
       "                      [ 0.0610, -0.1004, -0.2153,  ..., -0.0295, -0.0700,  0.1293],\n",
       "                      ...,\n",
       "                      [ 0.0257,  0.0240, -0.0892,  ..., -0.2045, -0.1242, -0.0668],\n",
       "                      [-0.2040, -0.0893, -0.0909,  ...,  0.1120, -0.1453, -0.2084],\n",
       "                      [ 0.0206,  0.1882, -0.0905,  ..., -0.2087,  0.1827, -0.1989]],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.in_proj_bias',\n",
       "              tensor([ 1.2609e-02,  1.9179e-02,  2.6357e-03,  5.8343e-03,  5.8716e-03,\n",
       "                      -5.6499e-03,  1.4378e-02, -7.6445e-04,  9.7090e-04, -1.8049e-02,\n",
       "                      -7.0987e-03, -4.4298e-04,  5.2278e-03,  1.1504e-03,  1.3251e-02,\n",
       "                      -1.8877e-02, -1.0924e-02, -2.5839e-03, -1.0104e-02, -4.5411e-03,\n",
       "                       1.7962e-02,  7.0334e-03,  1.9927e-02,  8.9535e-03, -1.8568e-03,\n",
       "                       2.0528e-02,  2.9972e-03,  3.8897e-03,  4.4498e-03, -1.1419e-02,\n",
       "                      -6.5081e-03, -7.9619e-03,  1.1493e-04,  1.1746e-04, -2.7589e-05,\n",
       "                      -2.8008e-04,  7.0436e-05,  4.5535e-05, -1.2363e-04,  2.5216e-05,\n",
       "                       2.6946e-04,  8.5442e-05,  1.4659e-04, -2.3990e-04, -1.8591e-04,\n",
       "                       2.6347e-05, -4.2068e-05, -6.1095e-06, -1.4862e-04, -1.3967e-04,\n",
       "                       4.0437e-05,  8.0933e-05,  2.9968e-04,  1.5214e-04,  4.9676e-04,\n",
       "                      -3.4841e-04,  4.2662e-05,  1.6616e-07, -1.0381e-04, -3.3993e-05,\n",
       "                      -2.5653e-04,  1.8417e-04,  9.8550e-05, -2.0324e-05, -5.8654e-03,\n",
       "                       2.4433e-03,  9.7836e-03, -1.0805e-02,  7.1215e-03, -1.6470e-02,\n",
       "                       1.4612e-02, -4.4902e-04, -1.2766e-02,  1.0273e-02, -1.8214e-03,\n",
       "                      -2.5300e-02,  6.3767e-03,  5.8865e-03,  1.1984e-03,  2.7157e-03,\n",
       "                      -1.8642e-02, -1.4089e-02,  1.2620e-02, -3.4805e-03, -2.4837e-03,\n",
       "                      -1.4012e-02, -1.9096e-02,  1.8186e-02,  1.6932e-03,  3.2543e-03,\n",
       "                       5.5757e-03,  1.3504e-02,  3.7927e-03, -1.8158e-03, -2.4280e-04,\n",
       "                       1.4490e-02], device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.out_proj.weight',\n",
       "              tensor([[ 0.0553, -0.0110,  0.0372,  ..., -0.1600,  0.1709,  0.0831],\n",
       "                      [ 0.1789, -0.0978,  0.1654,  ...,  0.1081, -0.0374, -0.0798],\n",
       "                      [-0.1410,  0.0762,  0.0954,  ...,  0.0124,  0.0512,  0.0982],\n",
       "                      ...,\n",
       "                      [-0.1313, -0.0816, -0.0626,  ...,  0.1737, -0.0456, -0.1024],\n",
       "                      [-0.1395,  0.0040, -0.1381,  ..., -0.0867, -0.0316, -0.1323],\n",
       "                      [ 0.1385,  0.0115,  0.0716,  ...,  0.0041,  0.1486,  0.1632]],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.out_proj.bias',\n",
       "              tensor([ 6.3791e-05, -8.0431e-03, -1.0890e-02, -3.4177e-03,  2.5987e-02,\n",
       "                       2.0448e-03, -4.8622e-03,  3.0190e-03,  1.3027e-02,  1.6208e-02,\n",
       "                       1.8560e-04, -1.5141e-02, -2.0382e-03,  8.6714e-04,  8.0737e-03,\n",
       "                       7.1853e-03, -3.1745e-03,  3.6174e-03,  4.5196e-03,  7.6326e-03,\n",
       "                      -1.2871e-02,  7.4589e-04, -1.3897e-02,  6.7808e-03,  6.5030e-04,\n",
       "                       4.7088e-03,  8.6220e-03, -1.0929e-02, -1.4744e-04, -1.1004e-02,\n",
       "                      -1.8774e-02,  1.4576e-02], device='cuda:0')),\n",
       "             ('pos_emb.pos_norm.weight',\n",
       "              tensor([0.9925, 0.9931, 0.9973, 0.9938, 1.0002, 0.9857, 0.9879, 0.9929, 0.9830,\n",
       "                      0.9817, 0.9888, 1.0147, 0.9898, 1.0026, 0.9924, 1.0010, 0.9924, 0.9902,\n",
       "                      0.9873, 0.9691, 0.9934, 0.9851, 0.9786, 0.9804, 0.9898, 0.9828, 0.9847,\n",
       "                      0.9786, 1.0048, 0.9672, 0.9831, 0.9997], device='cuda:0')),\n",
       "             ('pos_emb.pos_norm.bias',\n",
       "              tensor([ 0.0002, -0.0100, -0.0153, -0.0047,  0.0281,  0.0030, -0.0049,  0.0042,\n",
       "                       0.0148,  0.0209, -0.0004, -0.0145, -0.0034,  0.0003,  0.0091,  0.0082,\n",
       "                      -0.0058,  0.0065,  0.0056,  0.0067, -0.0144,  0.0036, -0.0178,  0.0047,\n",
       "                       0.0024,  0.0019,  0.0072, -0.0144, -0.0003, -0.0145, -0.0171,  0.0165],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.in_proj_weight',\n",
       "              tensor([[-0.1234,  0.1918, -0.0423,  ..., -0.1267, -0.1418, -0.1118],\n",
       "                      [-0.0563, -0.1216,  0.1778,  ..., -0.0334, -0.1923, -0.0205],\n",
       "                      [-0.0073,  0.1066, -0.0840,  ...,  0.1762, -0.0306,  0.0930],\n",
       "                      ...,\n",
       "                      [-0.0862, -0.1938, -0.2056,  ...,  0.0012,  0.1766, -0.1074],\n",
       "                      [ 0.0117,  0.1125,  0.1747,  ..., -0.0983,  0.1089,  0.1095],\n",
       "                      [-0.1670,  0.1167, -0.0891,  ...,  0.1990, -0.0340, -0.0403]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.in_proj_bias',\n",
       "              tensor([ 8.7393e-03, -1.2709e-03, -1.0360e-02, -1.1688e-02, -9.6082e-03,\n",
       "                       9.6104e-03, -6.2108e-03,  3.9119e-03,  2.3674e-03, -3.0102e-03,\n",
       "                       2.4336e-03,  4.2943e-04,  7.5091e-03, -2.8510e-03,  2.4317e-03,\n",
       "                       3.7068e-03, -4.5355e-04,  1.0400e-02, -1.3635e-02,  1.0506e-02,\n",
       "                       2.2004e-03,  1.4308e-02,  7.6063e-03,  1.1986e-02, -1.1261e-02,\n",
       "                      -1.1165e-02, -8.8532e-03, -1.2915e-02, -9.0091e-03, -7.4257e-03,\n",
       "                      -2.5952e-03,  6.6133e-03,  1.8502e-06,  8.7095e-05, -1.6626e-05,\n",
       "                       1.8146e-05, -5.2602e-05,  1.6307e-04,  2.6362e-05,  3.2443e-05,\n",
       "                      -1.4136e-04, -8.2383e-05, -8.8649e-06,  4.6245e-05,  2.1431e-04,\n",
       "                      -5.1488e-05,  9.7786e-06,  2.1131e-04, -1.0906e-04,  3.5972e-05,\n",
       "                       3.0523e-06, -8.1627e-06, -4.0723e-04,  6.5285e-05, -7.0166e-05,\n",
       "                       7.0295e-05,  2.4053e-05,  4.9743e-05, -1.9331e-04,  3.7180e-05,\n",
       "                      -8.4813e-06, -1.0228e-05, -9.7941e-05, -7.1982e-05,  2.6676e-03,\n",
       "                      -5.2860e-03,  2.8748e-03,  1.9912e-02,  2.3196e-03, -6.1174e-03,\n",
       "                       1.3732e-02,  7.5545e-03, -2.4257e-02,  4.0730e-03,  2.7305e-05,\n",
       "                       3.7851e-03,  1.7710e-02,  8.9319e-03, -1.3307e-02,  3.2778e-03,\n",
       "                      -4.8667e-04, -5.1697e-04, -3.3187e-03,  1.7131e-02, -4.1324e-04,\n",
       "                      -4.2258e-03, -7.0944e-03,  6.7896e-03, -2.5352e-03, -2.6395e-03,\n",
       "                       3.8332e-02, -8.1422e-03,  7.4461e-04, -1.7622e-02, -3.5646e-03,\n",
       "                       1.4635e-02], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.out_proj.weight',\n",
       "              tensor([[-0.1408,  0.1756, -0.0333,  ..., -0.0157, -0.1515, -0.0341],\n",
       "                      [ 0.0209, -0.1485,  0.0144,  ..., -0.0053, -0.0052, -0.0011],\n",
       "                      [ 0.1107,  0.0595,  0.0972,  ..., -0.0087, -0.0631,  0.0303],\n",
       "                      ...,\n",
       "                      [-0.0407,  0.0286,  0.0838,  ...,  0.0251, -0.1338, -0.0892],\n",
       "                      [-0.0115,  0.1363,  0.1208,  ...,  0.1895, -0.0886,  0.1195],\n",
       "                      [ 0.1672,  0.1162,  0.1512,  ...,  0.0065, -0.0893,  0.0546]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.out_proj.bias',\n",
       "              tensor([-0.0008, -0.0127, -0.0088, -0.0073,  0.0241,  0.0023, -0.0058,  0.0047,\n",
       "                       0.0210,  0.0150,  0.0055, -0.0227,  0.0019,  0.0002,  0.0142,  0.0058,\n",
       "                      -0.0131,  0.0056,  0.0114,  0.0056, -0.0139,  0.0067, -0.0157,  0.0062,\n",
       "                      -0.0010,  0.0016,  0.0068, -0.0157, -0.0013, -0.0081, -0.0201,  0.0196],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm1.weight',\n",
       "              tensor([0.9908, 1.0139, 0.9959, 0.9925, 1.0001, 0.9681, 0.9884, 0.9928, 0.9929,\n",
       "                      0.9927, 0.9915, 1.0210, 0.9860, 0.9894, 0.9926, 0.9963, 0.9896, 0.9922,\n",
       "                      0.9844, 0.9872, 0.9945, 0.9822, 0.9873, 0.9760, 0.9889, 0.9770, 0.9821,\n",
       "                      0.9769, 1.0023, 0.9724, 0.9883, 1.0031], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm1.bias',\n",
       "              tensor([ 2.1456e-03, -1.4624e-02, -7.2926e-03, -4.2139e-03,  1.5993e-02,\n",
       "                       4.0937e-03, -4.1052e-03,  2.7249e-03,  1.7951e-02,  1.4191e-02,\n",
       "                       8.3276e-04, -1.5578e-02, -1.9873e-03, -3.7695e-05,  1.0359e-02,\n",
       "                       4.4875e-03, -1.2430e-02,  3.7879e-03,  7.0872e-03,  2.6162e-03,\n",
       "                      -1.1249e-02,  5.5370e-03, -1.3438e-02,  5.0417e-03,  1.9464e-03,\n",
       "                       3.1540e-03,  7.2994e-03, -1.0835e-02, -2.3682e-04, -1.1008e-02,\n",
       "                      -1.5759e-02,  1.2675e-02], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.0.weight',\n",
       "              tensor([[ 0.0048,  0.1009, -0.0209,  ..., -0.1249, -0.1596,  0.0687],\n",
       "                      [-0.0923, -0.0557,  0.0084,  ..., -0.0919,  0.1619,  0.0654],\n",
       "                      [ 0.1039, -0.0990, -0.1641,  ...,  0.0794, -0.1645,  0.0751],\n",
       "                      ...,\n",
       "                      [ 0.0654, -0.0103,  0.1619,  ...,  0.1004, -0.1170,  0.0052],\n",
       "                      [ 0.1132,  0.0006, -0.0247,  ..., -0.1108,  0.1734,  0.0941],\n",
       "                      [ 0.0435, -0.1119, -0.0461,  ...,  0.0280, -0.0944, -0.0381]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.0.bias',\n",
       "              tensor([ 0.1047, -0.0091,  0.0427, -0.0747,  0.1089, -0.1288, -0.1378,  0.0160,\n",
       "                      -0.0366, -0.0221,  0.1022, -0.1307,  0.0544,  0.1562,  0.1643,  0.0789,\n",
       "                       0.1125,  0.1116,  0.0936, -0.0127,  0.1553, -0.0278, -0.1054, -0.0569,\n",
       "                      -0.1556, -0.0259, -0.0332, -0.1420, -0.1280,  0.0418, -0.0704, -0.0593,\n",
       "                      -0.0843, -0.1253, -0.1340, -0.0631, -0.0420,  0.1289, -0.0471,  0.0729,\n",
       "                      -0.1071,  0.1345,  0.1061,  0.0934, -0.0051, -0.1651,  0.1774, -0.0957,\n",
       "                       0.0151, -0.0986, -0.0195,  0.0981, -0.1308,  0.0395, -0.0775, -0.1469,\n",
       "                      -0.0114, -0.1010,  0.1648,  0.0249,  0.0745, -0.0837, -0.0127,  0.1446],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.2.weight',\n",
       "              tensor([[-0.0599, -0.0510, -0.0763,  ...,  0.1184,  0.1106, -0.1098],\n",
       "                      [ 0.0741,  0.0797,  0.0462,  ..., -0.0742,  0.1188,  0.0351],\n",
       "                      [-0.0467, -0.0998, -0.1030,  ...,  0.1187, -0.0855, -0.0819],\n",
       "                      ...,\n",
       "                      [ 0.0239, -0.0893, -0.0844,  ..., -0.0358,  0.0079, -0.0834],\n",
       "                      [ 0.0643,  0.1039, -0.0168,  ..., -0.0773, -0.0818, -0.0698],\n",
       "                      [ 0.0070, -0.0189, -0.1221,  ...,  0.0222, -0.1324, -0.1164]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.2.bias',\n",
       "              tensor([ 1.0321e-01, -8.1236e-02,  1.1497e-01,  1.1524e-02, -3.2705e-02,\n",
       "                       1.2706e-01,  9.1568e-02, -2.9685e-02, -6.5696e-02,  2.8741e-03,\n",
       "                       6.5752e-02, -8.3839e-02, -4.0118e-02, -8.7490e-02,  1.9100e-02,\n",
       "                       2.7358e-02,  3.2476e-02,  4.7678e-02, -2.0808e-02,  8.5996e-02,\n",
       "                      -1.1137e-01,  8.8564e-02, -5.1728e-02, -9.9163e-02, -3.2366e-02,\n",
       "                       3.6273e-02,  5.3216e-02,  7.6059e-02,  6.3055e-05,  7.1141e-02,\n",
       "                       8.4082e-02,  9.7176e-02], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm2.weight',\n",
       "              tensor([0.9894, 0.9948, 0.9844, 0.9920, 0.9953, 0.9777, 0.9889, 0.9886, 0.9869,\n",
       "                      0.9951, 0.9882, 1.0160, 0.9860, 0.9862, 0.9921, 0.9900, 0.9905, 0.9949,\n",
       "                      0.9837, 0.9865, 0.9933, 0.9868, 0.9897, 0.9743, 0.9883, 0.9800, 0.9925,\n",
       "                      0.9782, 1.0005, 0.9813, 0.9823, 1.0019], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm2.bias',\n",
       "              tensor([ 2.0951e-03, -1.5142e-02, -2.7398e-03, -9.1736e-04,  9.3424e-03,\n",
       "                       3.6878e-03, -3.3409e-03,  9.0169e-04,  1.6381e-02,  1.9778e-02,\n",
       "                       8.1569e-05, -8.9528e-03, -2.6626e-03,  7.1642e-04,  8.4939e-03,\n",
       "                       4.7634e-03, -9.8193e-03,  5.8232e-04,  1.0376e-02,  1.3532e-03,\n",
       "                      -7.9475e-03,  3.5535e-03, -9.6944e-03,  3.8236e-03,  3.7104e-03,\n",
       "                       7.5257e-03,  7.3307e-03, -8.3215e-03,  1.0535e-03, -6.4226e-03,\n",
       "                      -1.0920e-02,  8.5605e-03], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.in_proj_weight',\n",
       "              tensor([[-1.1973e-01,  2.1223e-01, -2.0497e-01,  ..., -1.1507e-01,\n",
       "                        1.3273e-01,  1.2689e-01],\n",
       "                      [ 8.0731e-02, -3.7388e-02, -4.1717e-02,  ...,  8.1274e-02,\n",
       "                       -2.0099e-01,  1.6470e-01],\n",
       "                      [-1.2697e-01,  2.1019e-01,  1.2008e-01,  ..., -1.5278e-01,\n",
       "                        1.4489e-01,  1.6301e-01],\n",
       "                      ...,\n",
       "                      [ 5.2706e-02,  2.6191e-02,  2.8156e-02,  ..., -6.6025e-03,\n",
       "                        2.1387e-01,  1.3394e-01],\n",
       "                      [-3.1652e-02,  1.0806e-01, -1.9075e-01,  ..., -1.9149e-01,\n",
       "                        1.8892e-01, -4.2409e-05],\n",
       "                      [-1.3886e-01,  2.0795e-01, -5.4121e-03,  ..., -3.9945e-02,\n",
       "                        2.3120e-02, -1.7187e-01]], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.in_proj_bias',\n",
       "              tensor([-1.3771e-02, -1.6032e-02, -1.6010e-02, -7.2918e-03, -1.6443e-02,\n",
       "                      -1.6569e-02, -2.8652e-02,  5.0151e-03, -1.9358e-02, -5.0004e-03,\n",
       "                      -1.5087e-02, -1.4996e-02,  1.0653e-02,  1.7061e-02,  2.5036e-02,\n",
       "                       2.1855e-02,  8.0087e-03, -1.0512e-02,  1.6719e-02, -4.3326e-03,\n",
       "                      -7.8182e-03,  1.0390e-02, -6.5525e-03,  2.0859e-03, -1.6077e-02,\n",
       "                      -8.1211e-03,  3.9281e-03,  5.7834e-03,  8.1521e-03, -4.8621e-03,\n",
       "                       8.7066e-03,  2.2660e-03,  1.5671e-05,  4.5120e-05, -2.3222e-05,\n",
       "                      -1.7959e-05,  4.7365e-05,  8.0289e-05,  2.6759e-05,  2.5944e-05,\n",
       "                       1.3201e-05, -1.5544e-05, -4.9356e-05, -1.1436e-05,  8.5711e-05,\n",
       "                       2.4430e-05, -1.9634e-05, -1.7883e-04, -3.8121e-05, -1.7271e-05,\n",
       "                       3.7213e-05, -6.0345e-06, -2.4517e-06, -1.4900e-05, -1.3154e-05,\n",
       "                       2.7545e-05, -4.7752e-05, -6.7357e-05,  1.1540e-04, -3.4928e-05,\n",
       "                       4.1037e-06,  1.6039e-05, -4.9002e-05, -7.0894e-05,  1.2291e-02,\n",
       "                       7.0742e-03, -6.3367e-04,  3.1514e-03, -1.9159e-03,  1.9749e-03,\n",
       "                       7.7457e-03,  2.7242e-03, -6.6237e-04,  3.3625e-03, -1.5895e-02,\n",
       "                      -8.4613e-03, -1.1934e-02,  7.1739e-04,  1.4424e-04,  1.3358e-03,\n",
       "                       1.9792e-02, -5.7922e-03,  7.2106e-03, -6.3506e-04, -6.8951e-03,\n",
       "                      -5.5098e-03,  1.5551e-02,  5.6248e-04,  1.1298e-02, -2.2151e-02,\n",
       "                       7.5986e-03,  7.3271e-03, -8.4970e-04, -1.6397e-03, -8.2582e-04,\n",
       "                      -9.5583e-03], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.out_proj.weight',\n",
       "              tensor([[-0.1230, -0.0829, -0.1691,  ..., -0.0094,  0.0641,  0.0941],\n",
       "                      [-0.0996, -0.1139, -0.0951,  ..., -0.0204,  0.0232, -0.1819],\n",
       "                      [-0.0709,  0.0718,  0.0631,  ...,  0.1044, -0.0739,  0.1744],\n",
       "                      ...,\n",
       "                      [ 0.0536,  0.1450,  0.0540,  ..., -0.0346,  0.1349,  0.0662],\n",
       "                      [-0.0834, -0.1137,  0.1450,  ..., -0.0211, -0.0732,  0.1203],\n",
       "                      [ 0.1957,  0.0926,  0.1304,  ...,  0.0758,  0.1434, -0.0696]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.out_proj.bias',\n",
       "              tensor([-0.0003, -0.0036, -0.0081, -0.0056,  0.0151,  0.0003, -0.0074,  0.0022,\n",
       "                       0.0057,  0.0200,  0.0054, -0.0127, -0.0011, -0.0007,  0.0131,  0.0040,\n",
       "                      -0.0101,  0.0008,  0.0123,  0.0060, -0.0124,  0.0058, -0.0155,  0.0075,\n",
       "                       0.0016,  0.0047,  0.0029, -0.0078, -0.0012, -0.0054, -0.0047,  0.0114],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm1.weight',\n",
       "              tensor([0.9883, 0.9914, 1.0009, 1.0105, 0.9903, 0.9810, 0.9925, 0.9896, 0.9944,\n",
       "                      0.9930, 0.9871, 1.0062, 0.9779, 0.9798, 0.9953, 0.9906, 0.9885, 0.9934,\n",
       "                      0.9885, 0.9909, 0.9935, 0.9951, 0.9879, 0.9764, 0.9886, 0.9836, 0.9920,\n",
       "                      0.9803, 0.9928, 0.9832, 0.9850, 0.9981], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm1.bias',\n",
       "              tensor([ 0.0041, -0.0045,  0.0009,  0.0029,  0.0033,  0.0024, -0.0020, -0.0026,\n",
       "                       0.0039,  0.0121, -0.0010, -0.0032, -0.0042,  0.0012,  0.0040,  0.0016,\n",
       "                      -0.0060, -0.0042,  0.0079,  0.0035, -0.0038, -0.0002, -0.0041,  0.0087,\n",
       "                       0.0054,  0.0105,  0.0036, -0.0008,  0.0014, -0.0068, -0.0028,  0.0013],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.0.weight',\n",
       "              tensor([[ 0.0048,  0.1009, -0.0209,  ..., -0.1249, -0.1596,  0.0687],\n",
       "                      [-0.0923, -0.0557,  0.0084,  ..., -0.0919,  0.1619,  0.0654],\n",
       "                      [ 0.1039, -0.0990, -0.1641,  ...,  0.0794, -0.1645,  0.0751],\n",
       "                      ...,\n",
       "                      [ 0.0654, -0.0103,  0.1619,  ...,  0.1004, -0.1170,  0.0052],\n",
       "                      [ 0.1132,  0.0006, -0.0247,  ..., -0.1108,  0.1734,  0.0941],\n",
       "                      [ 0.0435, -0.1119, -0.0461,  ...,  0.0280, -0.0944, -0.0381]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.0.bias',\n",
       "              tensor([ 0.1047, -0.0091,  0.0427, -0.0747,  0.1089, -0.1288, -0.1378,  0.0160,\n",
       "                      -0.0366, -0.0221,  0.1022, -0.1307,  0.0544,  0.1562,  0.1643,  0.0789,\n",
       "                       0.1125,  0.1116,  0.0936, -0.0127,  0.1553, -0.0278, -0.1054, -0.0569,\n",
       "                      -0.1556, -0.0259, -0.0332, -0.1420, -0.1280,  0.0418, -0.0704, -0.0593,\n",
       "                      -0.0843, -0.1253, -0.1340, -0.0631, -0.0420,  0.1289, -0.0471,  0.0729,\n",
       "                      -0.1071,  0.1345,  0.1061,  0.0934, -0.0051, -0.1651,  0.1774, -0.0957,\n",
       "                       0.0151, -0.0986, -0.0195,  0.0981, -0.1308,  0.0395, -0.0775, -0.1469,\n",
       "                      -0.0114, -0.1010,  0.1648,  0.0249,  0.0745, -0.0837, -0.0127,  0.1446],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.2.weight',\n",
       "              tensor([[-0.0599, -0.0510, -0.0763,  ...,  0.1184,  0.1106, -0.1098],\n",
       "                      [ 0.0741,  0.0797,  0.0462,  ..., -0.0742,  0.1188,  0.0351],\n",
       "                      [-0.0467, -0.0998, -0.1030,  ...,  0.1187, -0.0855, -0.0819],\n",
       "                      ...,\n",
       "                      [ 0.0239, -0.0893, -0.0844,  ..., -0.0358,  0.0079, -0.0834],\n",
       "                      [ 0.0643,  0.1039, -0.0168,  ..., -0.0773, -0.0818, -0.0698],\n",
       "                      [ 0.0070, -0.0189, -0.1221,  ...,  0.0222, -0.1324, -0.1164]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.2.bias',\n",
       "              tensor([ 1.0321e-01, -8.1236e-02,  1.1497e-01,  1.1524e-02, -3.2705e-02,\n",
       "                       1.2706e-01,  9.1568e-02, -2.9685e-02, -6.5696e-02,  2.8741e-03,\n",
       "                       6.5752e-02, -8.3839e-02, -4.0118e-02, -8.7490e-02,  1.9100e-02,\n",
       "                       2.7358e-02,  3.2476e-02,  4.7678e-02, -2.0808e-02,  8.5996e-02,\n",
       "                      -1.1137e-01,  8.8564e-02, -5.1728e-02, -9.9163e-02, -3.2366e-02,\n",
       "                       3.6273e-02,  5.3216e-02,  7.6059e-02,  6.3055e-05,  7.1141e-02,\n",
       "                       8.4082e-02,  9.7176e-02], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm2.weight',\n",
       "              tensor([0.9865, 0.9918, 0.9729, 1.0019, 0.9847, 0.9880, 0.9924, 0.9883, 0.9846,\n",
       "                      0.9936, 0.9867, 0.9953, 0.9626, 0.9720, 0.9933, 0.9874, 0.9888, 0.9908,\n",
       "                      0.9807, 0.9924, 0.9892, 0.9930, 0.9832, 0.9777, 0.9825, 0.9849, 0.9894,\n",
       "                      0.9784, 0.9912, 0.9866, 0.9839, 0.9938], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm2.bias',\n",
       "              tensor([ 0.0055, -0.0014,  0.0044,  0.0065, -0.0022,  0.0044, -0.0013, -0.0034,\n",
       "                       0.0078,  0.0046, -0.0029,  0.0006, -0.0041,  0.0018,  0.0006,  0.0033,\n",
       "                      -0.0044, -0.0065,  0.0066,  0.0019, -0.0006, -0.0022,  0.0012,  0.0070,\n",
       "                       0.0079,  0.0131,  0.0035,  0.0005,  0.0030, -0.0050, -0.0034, -0.0002],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1104,  0.0780,  0.1631,  ...,  0.0149, -0.0586,  0.1747],\n",
       "                      [-0.1188, -0.1753,  0.0062,  ..., -0.0641,  0.1175, -0.0933],\n",
       "                      [ 0.0199,  0.1024, -0.1210,  ...,  0.0813,  0.1818,  0.1758],\n",
       "                      ...,\n",
       "                      [-0.1648, -0.1818,  0.1807,  ...,  0.1211,  0.0317, -0.2092],\n",
       "                      [ 0.1622,  0.1872,  0.1066,  ...,  0.1898, -0.0357,  0.0110],\n",
       "                      [ 0.1045,  0.0015,  0.0566,  ..., -0.1711,  0.2061,  0.0150]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.in_proj_bias',\n",
       "              tensor([ 5.7865e-03,  4.2136e-03, -4.1169e-03, -1.1759e-03, -1.4442e-02,\n",
       "                      -5.2530e-03,  1.6314e-04, -4.7967e-03, -2.0262e-03,  5.4048e-03,\n",
       "                       5.2951e-03,  5.0357e-03, -3.0012e-03, -1.0257e-02, -6.4828e-03,\n",
       "                      -6.4513e-03,  3.3736e-03, -6.6918e-03,  1.1019e-02,  2.6588e-05,\n",
       "                       6.4757e-03,  7.6442e-03,  1.4834e-02,  1.0356e-02,  5.8055e-04,\n",
       "                       1.1770e-02, -8.2957e-04, -2.4874e-04,  2.7647e-03,  9.2998e-03,\n",
       "                      -3.0351e-03,  1.1588e-02, -6.6374e-05, -1.7031e-04, -6.2279e-05,\n",
       "                       2.6820e-06, -3.7134e-05, -1.6887e-04, -5.8464e-05,  6.1558e-05,\n",
       "                      -1.4537e-06, -6.0078e-06,  1.4671e-05,  3.4893e-05,  1.2094e-05,\n",
       "                      -1.7015e-05,  2.4244e-05, -4.2242e-05, -2.3718e-04, -2.6243e-04,\n",
       "                       1.6272e-05,  1.1992e-04,  1.3938e-04,  4.4150e-06, -1.6612e-04,\n",
       "                      -3.5524e-05,  1.2512e-04,  6.1543e-05,  1.7332e-05, -2.4151e-05,\n",
       "                       1.1144e-04,  1.0654e-04, -8.8397e-05,  8.3201e-05,  4.0198e-03,\n",
       "                      -9.2479e-04, -4.5251e-03,  7.5010e-04,  1.9674e-03, -4.5587e-03,\n",
       "                       7.9800e-03, -2.3136e-04, -1.8633e-03,  3.1706e-03, -7.9090e-03,\n",
       "                      -1.1607e-02, -6.2762e-03,  8.5520e-03, -3.8207e-03,  3.4123e-03,\n",
       "                       2.5724e-03,  6.9982e-04, -5.2901e-03,  4.1908e-03,  8.2856e-03,\n",
       "                       5.8643e-03, -2.7486e-04,  4.2954e-03,  1.6108e-04, -4.3400e-03,\n",
       "                      -3.8586e-03, -6.2263e-03,  1.4901e-03,  1.2905e-03,  5.7997e-03,\n",
       "                      -5.2995e-03], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.out_proj.weight',\n",
       "              tensor([[-0.0612,  0.0453,  0.0314,  ...,  0.0667,  0.1270,  0.1565],\n",
       "                      [-0.0050,  0.0068,  0.0524,  ..., -0.0766, -0.0721, -0.0590],\n",
       "                      [ 0.0151,  0.0323,  0.0386,  ..., -0.0644,  0.0050,  0.1201],\n",
       "                      ...,\n",
       "                      [ 0.0821, -0.1345, -0.1679,  ...,  0.0138,  0.1252, -0.0867],\n",
       "                      [-0.1456, -0.0139,  0.0092,  ...,  0.0419, -0.1559,  0.1593],\n",
       "                      [-0.1488,  0.1510, -0.0459,  ...,  0.1031, -0.1555,  0.0198]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.out_proj.bias',\n",
       "              tensor([-4.3566e-03, -5.9094e-03, -7.4737e-03, -8.9687e-03, -4.7259e-04,\n",
       "                      -2.1562e-03,  1.0790e-03, -2.2449e-03,  2.8140e-03,  1.2950e-03,\n",
       "                      -4.5955e-03,  4.7690e-04, -2.2400e-03,  7.3321e-03,  3.8337e-03,\n",
       "                       5.0949e-03,  5.0430e-03,  1.7754e-03,  5.3164e-03,  4.0863e-03,\n",
       "                       2.2213e-03, -4.8028e-03,  6.2662e-04,  3.2025e-03,  2.0469e-05,\n",
       "                      -2.2069e-03, -1.1634e-03,  7.3144e-03, -5.0830e-03,  3.6798e-03,\n",
       "                      -4.3460e-03, -1.8875e-03], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm1.weight',\n",
       "              tensor([0.9936, 0.9961, 0.9985, 0.9996, 0.9818, 0.9856, 0.9905, 1.0011, 0.9924,\n",
       "                      0.9870, 0.9910, 0.9809, 0.9970, 1.0009, 0.9907, 0.9925, 0.9868, 0.9874,\n",
       "                      0.9801, 0.9820, 0.9792, 0.9851, 0.9810, 0.9884, 0.9980, 0.9964, 0.9904,\n",
       "                      0.9902, 0.9932, 0.9890, 0.9969, 0.9925], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm1.bias',\n",
       "              tensor([-3.5154e-03, -5.4658e-03, -7.0119e-03, -7.4160e-03, -1.3121e-03,\n",
       "                      -2.0789e-03,  1.1836e-03, -2.1531e-03,  2.5312e-03,  7.2369e-04,\n",
       "                      -4.1251e-03,  6.0890e-04, -1.9990e-03,  7.0551e-03,  3.5798e-03,\n",
       "                       4.3203e-03,  4.6843e-03,  1.6028e-03,  5.4264e-03,  3.8208e-03,\n",
       "                       3.0401e-03, -4.5736e-03,  5.6009e-04,  2.9307e-03, -8.1494e-05,\n",
       "                      -2.0302e-03, -1.0726e-03,  7.3063e-03, -4.5094e-03,  3.1417e-03,\n",
       "                      -3.7204e-03, -1.4594e-03], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.in_proj_weight',\n",
       "              tensor([[ 0.1014, -0.1553,  0.1021,  ..., -0.1086,  0.1830, -0.0735],\n",
       "                      [ 0.1621,  0.1931,  0.2114,  ...,  0.0180,  0.0682, -0.1300],\n",
       "                      [-0.0917, -0.1296,  0.0301,  ..., -0.1077, -0.0191,  0.1265],\n",
       "                      ...,\n",
       "                      [ 0.1136, -0.0431,  0.1022,  ..., -0.0078, -0.0975,  0.0414],\n",
       "                      [ 0.0862, -0.0247, -0.1654,  ...,  0.0760, -0.1469,  0.1506],\n",
       "                      [ 0.0329, -0.0535, -0.1102,  ...,  0.2039,  0.1519,  0.1034]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.in_proj_bias',\n",
       "              tensor([-2.6575e-04, -3.4285e-03,  6.8074e-03,  1.8849e-03, -1.6801e-04,\n",
       "                      -1.0502e-02, -7.0358e-03,  1.2783e-03, -3.2945e-03, -3.5711e-04,\n",
       "                       7.9034e-04,  3.5435e-03,  1.8819e-02, -9.9351e-04,  2.2620e-06,\n",
       "                       1.5615e-03,  9.6682e-03, -2.7793e-03, -4.2029e-03,  2.8567e-03,\n",
       "                      -1.0184e-02, -1.1962e-02,  6.6560e-03, -5.5809e-04, -1.5842e-02,\n",
       "                      -2.1086e-03,  2.3896e-03, -5.5389e-03, -1.9954e-03,  2.9767e-03,\n",
       "                       1.3781e-02,  8.4244e-03,  4.8699e-05, -1.9593e-05, -2.3254e-06,\n",
       "                      -1.6072e-05,  7.4172e-05, -8.5013e-06,  1.6459e-05,  8.6673e-06,\n",
       "                       7.6968e-05, -7.9604e-05, -3.5881e-05,  1.5716e-05, -5.1081e-06,\n",
       "                       3.4035e-05, -4.0944e-05,  1.5436e-05,  4.0386e-06,  1.1350e-05,\n",
       "                      -1.0668e-05,  7.0373e-05, -2.3110e-06, -2.1183e-05, -8.7247e-06,\n",
       "                       7.2974e-05,  5.5187e-06,  1.9579e-05,  3.0888e-05, -1.8030e-05,\n",
       "                      -4.0912e-06,  9.6471e-06,  3.8056e-05,  8.6449e-05, -6.9145e-04,\n",
       "                       5.2981e-03, -2.9855e-03,  5.8975e-03,  8.1410e-04,  2.8744e-03,\n",
       "                       2.7393e-03, -9.7619e-03, -3.8854e-03,  6.1639e-03,  5.2033e-03,\n",
       "                      -9.0707e-04, -1.5053e-03,  3.9458e-03,  1.6574e-03,  4.3472e-03,\n",
       "                      -8.9932e-03, -3.6996e-03, -3.6776e-03, -1.3540e-03,  3.7652e-04,\n",
       "                       5.6528e-03,  6.2295e-03, -8.7998e-04,  9.1538e-03, -5.6539e-04,\n",
       "                      -1.5147e-03, -4.3238e-03, -5.0991e-03,  5.8632e-03, -7.1149e-03,\n",
       "                      -2.0241e-03], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.out_proj.weight',\n",
       "              tensor([[ 0.1260, -0.0289,  0.1601,  ..., -0.0909, -0.0221, -0.1480],\n",
       "                      [-0.0091, -0.1429,  0.1415,  ..., -0.1577, -0.0252,  0.1209],\n",
       "                      [-0.1808, -0.1380,  0.1141,  ..., -0.0284,  0.0588,  0.0220],\n",
       "                      ...,\n",
       "                      [ 0.0180, -0.0451,  0.1770,  ..., -0.0004,  0.1044,  0.0235],\n",
       "                      [ 0.1528, -0.1735,  0.0010,  ..., -0.1334,  0.1013, -0.1709],\n",
       "                      [ 0.0474,  0.1589, -0.1390,  ..., -0.0547,  0.0238,  0.1222]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.out_proj.bias',\n",
       "              tensor([-0.0036, -0.0048, -0.0070, -0.0080,  0.0031, -0.0022,  0.0046, -0.0026,\n",
       "                       0.0028,  0.0001, -0.0042,  0.0009, -0.0019,  0.0082,  0.0038,  0.0049,\n",
       "                       0.0047,  0.0018,  0.0046,  0.0044,  0.0018, -0.0047,  0.0005,  0.0029,\n",
       "                      -0.0002, -0.0021, -0.0010,  0.0073, -0.0046,  0.0034, -0.0037, -0.0018],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm2.weight',\n",
       "              tensor([0.9917, 0.9954, 0.9962, 0.9964, 0.9831, 0.9850, 0.9923, 0.9946, 0.9925,\n",
       "                      0.9848, 0.9916, 0.9680, 0.9961, 1.0009, 0.9897, 0.9920, 0.9865, 0.9875,\n",
       "                      0.9774, 0.9814, 0.9781, 0.9845, 0.9778, 0.9880, 0.9954, 0.9965, 0.9848,\n",
       "                      0.9891, 0.9930, 0.9890, 0.9946, 0.9913], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm2.bias',\n",
       "              tensor([-2.1348e-03, -2.0462e-03, -5.1880e-03, -5.2949e-03,  1.4697e-03,\n",
       "                      -2.2446e-03,  3.6858e-03, -2.1118e-03,  2.3089e-03,  6.3655e-05,\n",
       "                      -3.3147e-03,  1.0114e-03, -2.6987e-03,  6.3652e-03,  3.6496e-03,\n",
       "                       3.9888e-03,  4.4634e-03,  1.6445e-03,  5.0761e-03,  3.9591e-03,\n",
       "                       3.0590e-03, -4.4156e-03,  5.6321e-04,  2.6768e-03, -3.3872e-04,\n",
       "                      -2.0334e-03, -8.8511e-04,  6.9207e-03, -3.6888e-03,  2.8689e-03,\n",
       "                      -2.5909e-03, -1.2628e-03], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.0.weight',\n",
       "              tensor([[-0.0529, -0.0908, -0.1072,  ...,  0.0024, -0.0260,  0.0445],\n",
       "                      [ 0.1157,  0.1710, -0.1063,  ..., -0.0168,  0.1173,  0.1396],\n",
       "                      [ 0.1699, -0.0446, -0.0805,  ...,  0.0423, -0.0060, -0.1009],\n",
       "                      ...,\n",
       "                      [-0.1130, -0.1107,  0.0565,  ..., -0.1280, -0.1278,  0.1667],\n",
       "                      [-0.0371,  0.1534,  0.1211,  ..., -0.0371, -0.1441,  0.1740],\n",
       "                      [ 0.0517,  0.0596, -0.1424,  ..., -0.0434, -0.0624,  0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.0.bias',\n",
       "              tensor([ 0.1250, -0.0389,  0.1080,  0.0483,  0.0616,  0.0097, -0.0855, -0.1344,\n",
       "                       0.1197,  0.1170,  0.0621, -0.0556, -0.1779, -0.0355, -0.1223, -0.0435,\n",
       "                       0.1075,  0.0933,  0.0464,  0.0669,  0.0739, -0.1271, -0.1664, -0.1497,\n",
       "                      -0.0078, -0.0136, -0.0450, -0.0633, -0.0810,  0.0130, -0.0943, -0.1162,\n",
       "                       0.1669,  0.0025, -0.0770,  0.1186,  0.0178, -0.1166, -0.1817, -0.1685,\n",
       "                      -0.1582,  0.0697,  0.0573, -0.1292,  0.1468,  0.0875,  0.0345, -0.0847,\n",
       "                      -0.1627, -0.0794, -0.1509,  0.0258,  0.0432,  0.1672, -0.1165,  0.1638,\n",
       "                       0.1550, -0.1052, -0.0125,  0.0264, -0.1446, -0.1021,  0.0977,  0.0464],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.2.weight',\n",
       "              tensor([[-0.0870, -0.0467,  0.0352,  ...,  0.0733,  0.0624,  0.0999],\n",
       "                      [-0.0410,  0.0094, -0.0523,  ...,  0.0250, -0.1248, -0.0381],\n",
       "                      [ 0.0268,  0.1164, -0.0398,  ..., -0.0891, -0.0555,  0.0519],\n",
       "                      ...,\n",
       "                      [ 0.0052,  0.0004, -0.0045,  ...,  0.0428, -0.0819,  0.0614],\n",
       "                      [-0.0394, -0.0566,  0.0408,  ...,  0.0549,  0.0920, -0.0333],\n",
       "                      [-0.0180,  0.0928, -0.0468,  ...,  0.0882,  0.0132, -0.0866]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.2.bias',\n",
       "              tensor([ 0.0585,  0.1064,  0.0521,  0.1031,  0.1237, -0.1213,  0.0781,  0.0614,\n",
       "                       0.0912,  0.0513, -0.0695,  0.1079,  0.0674, -0.0165, -0.1109,  0.0604,\n",
       "                      -0.0788,  0.0018, -0.0863, -0.0711, -0.1065, -0.0734,  0.0335,  0.0490,\n",
       "                       0.0803, -0.0497,  0.0875,  0.0938, -0.0306, -0.0409, -0.1238, -0.0312],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.in_proj_weight',\n",
       "              tensor([[-0.1840, -0.1371,  0.0334,  ..., -0.1415, -0.1816, -0.0837],\n",
       "                      [-0.0065,  0.0303, -0.1555,  ...,  0.1399,  0.1741,  0.1346],\n",
       "                      [-0.1467,  0.0880,  0.1940,  ...,  0.1791, -0.1965, -0.0117],\n",
       "                      ...,\n",
       "                      [-0.0278,  0.0631,  0.1806,  ..., -0.0101, -0.0837, -0.0606],\n",
       "                      [-0.1139, -0.1828, -0.0182,  ..., -0.1794,  0.1162, -0.0118],\n",
       "                      [ 0.0568,  0.0455,  0.2181,  ...,  0.2078,  0.0091, -0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.in_proj_bias',\n",
       "              tensor([-3.4779e-04, -3.8642e-04, -1.3584e-03,  7.1353e-03, -3.3398e-03,\n",
       "                      -4.9916e-05,  3.9133e-03, -8.8737e-03, -3.9072e-04, -5.7999e-03,\n",
       "                      -6.7834e-03, -4.2991e-03, -4.2669e-03, -6.0382e-03, -7.5695e-03,\n",
       "                       2.7287e-03, -2.9782e-03,  5.3681e-03, -2.2835e-03,  5.5154e-03,\n",
       "                      -5.3907e-03, -1.7552e-02, -1.8198e-03,  7.6807e-03, -2.9660e-03,\n",
       "                      -4.3007e-03,  2.5770e-03,  4.4829e-03, -2.1451e-03, -2.6145e-03,\n",
       "                       1.0613e-03,  4.9507e-03,  1.6353e-05, -3.4783e-06, -1.8623e-06,\n",
       "                      -3.1311e-05,  7.3742e-06,  4.1310e-05, -6.2786e-05,  6.0374e-05,\n",
       "                       1.7878e-04,  2.9187e-04, -2.4499e-04, -1.1555e-04,  4.7408e-05,\n",
       "                      -7.3853e-05, -9.3848e-05, -8.1266e-05, -6.9857e-05,  4.1825e-06,\n",
       "                       5.4913e-05,  1.6716e-05,  7.7005e-05, -1.2440e-04,  1.1146e-04,\n",
       "                       1.1139e-04,  6.3340e-06, -1.8811e-05,  5.8059e-05, -1.3604e-06,\n",
       "                       4.1177e-05, -4.6268e-05, -1.2381e-04, -3.4031e-05, -2.1262e-03,\n",
       "                      -2.1090e-03, -4.9520e-03, -2.2403e-03,  2.7080e-03, -3.0166e-03,\n",
       "                       1.2248e-03, -1.1446e-03,  2.0432e-03,  4.2251e-04,  2.1429e-03,\n",
       "                       2.9798e-03, -7.0758e-03,  8.5998e-03,  5.0991e-04,  8.7091e-03,\n",
       "                       3.0609e-03,  2.8288e-03,  2.3952e-03, -3.1454e-03,  2.5314e-04,\n",
       "                      -7.4422e-04,  1.0973e-04,  5.5719e-03, -1.3843e-02,  9.5828e-03,\n",
       "                       4.4526e-03, -9.2842e-03,  5.0618e-04,  5.9381e-04,  3.9967e-03,\n",
       "                       2.2650e-03], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0936,  0.1106, -0.0811,  ..., -0.0260, -0.1330,  0.1459],\n",
       "                      [ 0.1343, -0.0858,  0.0909,  ...,  0.1746,  0.0625,  0.1037],\n",
       "                      [ 0.0768,  0.1505,  0.1441,  ...,  0.1495, -0.0962, -0.1521],\n",
       "                      ...,\n",
       "                      [-0.0716,  0.0154, -0.0110,  ..., -0.0174,  0.0675, -0.0134],\n",
       "                      [-0.0228,  0.0885, -0.0158,  ...,  0.1269,  0.0968, -0.1062],\n",
       "                      [ 0.1275, -0.0391, -0.1072,  ..., -0.0541,  0.0098,  0.0943]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.out_proj.bias',\n",
       "              tensor([-7.7301e-03, -1.6209e-03, -8.3922e-03, -9.2153e-03,  2.2998e-03,\n",
       "                      -1.3087e-03,  5.3255e-03, -4.6339e-03,  1.9653e-03, -3.3493e-03,\n",
       "                      -4.3299e-03,  7.7824e-04, -4.4692e-04,  1.3271e-02,  3.6220e-03,\n",
       "                       4.6339e-03,  3.2845e-03,  2.3425e-03,  4.4040e-03,  4.5589e-03,\n",
       "                      -6.5158e-04, -4.3695e-03, -9.0912e-05,  2.7429e-03,  6.1654e-04,\n",
       "                      -3.2199e-03, -1.5129e-03,  8.0105e-03, -4.7600e-03,  3.2929e-03,\n",
       "                      -6.8797e-03, -3.0173e-03], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm1.weight',\n",
       "              tensor([0.9963, 0.9952, 0.9976, 0.9988, 0.9777, 0.9861, 0.9927, 0.9757, 0.9913,\n",
       "                      0.9847, 0.9916, 0.9855, 0.9988, 1.0038, 0.9901, 0.9925, 0.9846, 0.9930,\n",
       "                      0.9825, 0.9786, 0.9830, 0.9837, 0.9668, 0.9850, 1.0000, 0.9972, 0.9887,\n",
       "                      0.9860, 0.9890, 0.9878, 0.9921, 0.9918], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm1.bias',\n",
       "              tensor([-0.0052, -0.0010, -0.0067, -0.0069,  0.0005, -0.0017,  0.0044, -0.0033,\n",
       "                       0.0012, -0.0038, -0.0038,  0.0003, -0.0014,  0.0102,  0.0035,  0.0037,\n",
       "                       0.0029,  0.0024,  0.0051,  0.0041,  0.0008, -0.0041, -0.0002,  0.0024,\n",
       "                       0.0011, -0.0032, -0.0015,  0.0074, -0.0041,  0.0025, -0.0050, -0.0021],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.in_proj_weight',\n",
       "              tensor([[-0.0219,  0.0856, -0.0769,  ..., -0.1162,  0.1423,  0.1288],\n",
       "                      [ 0.1792, -0.0474, -0.1012,  ...,  0.1809, -0.0814, -0.0452],\n",
       "                      [ 0.2059,  0.0693, -0.1892,  ..., -0.1808,  0.0025, -0.1364],\n",
       "                      ...,\n",
       "                      [-0.1935, -0.0931,  0.1767,  ..., -0.1562, -0.1860, -0.1076],\n",
       "                      [ 0.1106, -0.1646,  0.1538,  ..., -0.2138,  0.0225,  0.1268],\n",
       "                      [ 0.0163, -0.1253,  0.0075,  ..., -0.0204,  0.1758,  0.0061]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.in_proj_bias',\n",
       "              tensor([ 8.7590e-03,  1.2701e-03, -1.8860e-03,  3.5281e-04, -4.0910e-03,\n",
       "                       1.4820e-03, -1.7780e-03, -1.7809e-02, -3.6451e-03, -3.4634e-03,\n",
       "                      -1.6680e-03, -1.6588e-03, -2.9575e-03, -1.3664e-02, -3.2208e-03,\n",
       "                      -1.9734e-03, -8.4868e-03, -1.6209e-02,  7.7505e-03, -2.5223e-03,\n",
       "                      -1.9609e-03,  2.1628e-03, -9.7201e-03,  4.2824e-03, -4.9623e-03,\n",
       "                      -1.2977e-03, -1.7548e-04, -1.2632e-02,  3.4083e-03, -2.3395e-04,\n",
       "                       2.0235e-03,  2.1002e-03, -2.8041e-05,  6.5906e-05, -3.1708e-05,\n",
       "                      -8.9689e-05,  8.0188e-05,  1.7876e-05, -2.4917e-05,  7.9736e-05,\n",
       "                       2.8936e-05, -7.6253e-05, -4.7383e-05,  5.1608e-05,  2.6155e-05,\n",
       "                      -2.0052e-05, -1.5248e-05, -8.3701e-05,  8.3587e-04, -2.5134e-04,\n",
       "                      -2.8931e-04,  6.0635e-04, -2.8216e-04, -1.2918e-04, -3.8503e-04,\n",
       "                       6.0441e-05,  4.1393e-04, -1.2775e-04,  1.6870e-04, -5.5505e-05,\n",
       "                      -3.3530e-04, -4.8188e-05,  1.7216e-04, -5.6616e-05, -3.4754e-03,\n",
       "                       4.9118e-04,  8.7266e-04,  1.8991e-03,  1.1027e-03,  6.6640e-03,\n",
       "                       5.5859e-03,  4.2541e-03, -2.2720e-03, -4.1767e-04,  5.2951e-03,\n",
       "                      -2.8852e-03,  5.9203e-03, -6.9126e-04, -3.5315e-03, -6.2208e-03,\n",
       "                      -3.7495e-03, -4.1007e-03,  1.7067e-03, -1.8564e-03, -1.2875e-03,\n",
       "                      -1.0328e-02, -1.3048e-03,  1.2139e-03,  1.8363e-03,  8.5675e-04,\n",
       "                      -3.7991e-03,  3.0405e-03, -3.0002e-03, -3.7055e-03,  9.2476e-03,\n",
       "                       2.2231e-04], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.out_proj.weight',\n",
       "              tensor([[ 0.0776,  0.1114,  0.1196,  ...,  0.0366, -0.1338,  0.1655],\n",
       "                      [ 0.0912, -0.0522,  0.0657,  ...,  0.0981, -0.0454, -0.0101],\n",
       "                      [ 0.1121, -0.0397,  0.0788,  ...,  0.0080, -0.1537, -0.0319],\n",
       "                      ...,\n",
       "                      [-0.0492,  0.1462, -0.0651,  ...,  0.0797,  0.1580,  0.0367],\n",
       "                      [ 0.0536,  0.1505,  0.0003,  ...,  0.0928,  0.0007, -0.0641],\n",
       "                      [ 0.0584, -0.1338,  0.1432,  ...,  0.1216, -0.0286, -0.0172]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.out_proj.bias',\n",
       "              tensor([-5.3178e-03, -1.5433e-03, -7.0967e-03, -7.0385e-03,  1.0729e-03,\n",
       "                      -1.4917e-03,  5.0088e-03, -3.0815e-03,  1.6561e-03, -3.5158e-03,\n",
       "                      -3.7552e-03,  2.2041e-04, -1.6207e-03,  1.1372e-02,  3.5307e-03,\n",
       "                       3.8672e-03,  2.9204e-03,  2.8607e-03,  5.0876e-03,  4.0450e-03,\n",
       "                       4.6525e-04, -4.3093e-03, -6.6139e-07,  2.4045e-03,  1.2040e-03,\n",
       "                      -3.3720e-03, -1.4560e-03,  7.0987e-03, -3.9475e-03,  2.7048e-03,\n",
       "                      -4.3414e-03, -2.3234e-03], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm2.weight',\n",
       "              tensor([0.9903, 0.9942, 0.9944, 0.9930, 0.9807, 0.9862, 0.9909, 0.9745, 0.9904,\n",
       "                      0.9823, 0.9906, 0.9730, 0.9946, 0.9972, 0.9872, 0.9910, 0.9844, 0.9870,\n",
       "                      0.9808, 0.9787, 0.9798, 0.9830, 0.9838, 0.9844, 0.9937, 0.9948, 0.9825,\n",
       "                      0.9860, 0.9886, 0.9845, 0.9828, 0.9904], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm2.bias',\n",
       "              tensor([-1.4557e-03, -4.9203e-04, -4.0675e-03, -3.3197e-03, -1.5917e-03,\n",
       "                      -2.3920e-03,  2.6890e-03, -1.7190e-03, -9.9711e-06, -3.8248e-03,\n",
       "                      -2.4885e-03, -4.7125e-05, -4.0330e-03,  4.7166e-03,  3.5410e-03,\n",
       "                       2.4161e-03,  3.1261e-03,  2.4723e-03,  6.5172e-03,  3.3210e-03,\n",
       "                       2.2947e-03, -4.0565e-03,  4.0694e-04,  2.1036e-03,  2.3275e-03,\n",
       "                      -3.2688e-03, -1.3427e-03,  5.7835e-03, -3.2996e-03,  1.8481e-03,\n",
       "                      -1.5815e-03, -1.0395e-03], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.0.weight',\n",
       "              tensor([[-0.0529, -0.0908, -0.1072,  ...,  0.0024, -0.0260,  0.0445],\n",
       "                      [ 0.1157,  0.1710, -0.1063,  ..., -0.0168,  0.1173,  0.1396],\n",
       "                      [ 0.1699, -0.0446, -0.0805,  ...,  0.0423, -0.0060, -0.1009],\n",
       "                      ...,\n",
       "                      [-0.1130, -0.1107,  0.0565,  ..., -0.1280, -0.1278,  0.1667],\n",
       "                      [-0.0371,  0.1534,  0.1211,  ..., -0.0371, -0.1441,  0.1740],\n",
       "                      [ 0.0517,  0.0596, -0.1424,  ..., -0.0434, -0.0624,  0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.0.bias',\n",
       "              tensor([ 0.1250, -0.0389,  0.1080,  0.0483,  0.0616,  0.0097, -0.0855, -0.1344,\n",
       "                       0.1197,  0.1170,  0.0621, -0.0556, -0.1779, -0.0355, -0.1223, -0.0435,\n",
       "                       0.1075,  0.0933,  0.0464,  0.0669,  0.0739, -0.1271, -0.1664, -0.1497,\n",
       "                      -0.0078, -0.0136, -0.0450, -0.0633, -0.0810,  0.0130, -0.0943, -0.1162,\n",
       "                       0.1669,  0.0025, -0.0770,  0.1186,  0.0178, -0.1166, -0.1817, -0.1685,\n",
       "                      -0.1582,  0.0697,  0.0573, -0.1292,  0.1468,  0.0875,  0.0345, -0.0847,\n",
       "                      -0.1627, -0.0794, -0.1509,  0.0258,  0.0432,  0.1672, -0.1165,  0.1638,\n",
       "                       0.1550, -0.1052, -0.0125,  0.0264, -0.1446, -0.1021,  0.0977,  0.0464],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.2.weight',\n",
       "              tensor([[-0.0870, -0.0467,  0.0352,  ...,  0.0733,  0.0624,  0.0999],\n",
       "                      [-0.0410,  0.0094, -0.0523,  ...,  0.0250, -0.1248, -0.0381],\n",
       "                      [ 0.0268,  0.1164, -0.0398,  ..., -0.0891, -0.0555,  0.0519],\n",
       "                      ...,\n",
       "                      [ 0.0052,  0.0004, -0.0045,  ...,  0.0428, -0.0819,  0.0614],\n",
       "                      [-0.0394, -0.0566,  0.0408,  ...,  0.0549,  0.0920, -0.0333],\n",
       "                      [-0.0180,  0.0928, -0.0468,  ...,  0.0882,  0.0132, -0.0866]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.2.bias',\n",
       "              tensor([ 0.0585,  0.1064,  0.0521,  0.1031,  0.1237, -0.1213,  0.0781,  0.0614,\n",
       "                       0.0912,  0.0513, -0.0695,  0.1079,  0.0674, -0.0165, -0.1109,  0.0604,\n",
       "                      -0.0788,  0.0018, -0.0863, -0.0711, -0.1065, -0.0734,  0.0335,  0.0490,\n",
       "                       0.0803, -0.0497,  0.0875,  0.0938, -0.0306, -0.0409, -0.1238, -0.0312],\n",
       "                     device='cuda:0')),\n",
       "             ('output_feedforward.0.weight',\n",
       "              tensor([[ 0.0630, -0.0073,  0.1184, -0.0408,  0.0737, -0.1462, -0.0552, -0.1410,\n",
       "                       -0.0363, -0.0111,  0.0855,  0.0372,  0.0184, -0.0489,  0.0765,  0.1444,\n",
       "                        0.1491, -0.0518, -0.0292, -0.1391, -0.0901, -0.0999,  0.1486,  0.1398,\n",
       "                        0.0061,  0.0062, -0.1262, -0.0040, -0.1364,  0.1656,  0.0504, -0.1585]],\n",
       "                     device='cuda:0')),\n",
       "             ('output_feedforward.0.bias', tensor([0.0311], device='cuda:0'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(\n",
    "    optimizer=optimizer,\n",
    "    model=trans_encoder_decoder_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    ot_steps=20,\n",
    "    report_interval=5,\n",
    "    n_epochs=1,\n",
    "    list_train_loss=train_loss,\n",
    "    list_val_loss=val_loss,\n",
    "    device=device,\n",
    "    eps=1e-8,\n",
    "    scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa253fa",
   "metadata": {},
   "source": [
    "## The Model (With only teacher forcing, using the current timeseries as ground_target) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3bc98",
   "metadata": {},
   "source": [
    "### The reason we went, first to the autoregression only method was that there was no ground target, but what if we just use the current sequence (the current encoder memory) as the ground target in the decoder? Intuitively this is asking the cross attention layers: For the time steps in my query (the ground target), how can I adjust the query with the values (encoder output), based on the attention of keys (encoder output) on the query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1e8b3",
   "metadata": {},
   "source": [
    "### A comment on masking\n",
    "\n",
    "The formula for masked attention is $Attention(Q,K,V,M)=softmax(QK^T/\\sqrt{d_Q}\\ + \\ M)\\ V$ (where $d_Q$ is the number of row of $Q$, e.g the length of the timeseries in our context, and $M$ stands for the mask). \n",
    "\n",
    "In our case, we are using the \"casual mask\": (example of dimension length of Query timeseries being 3) \n",
    "\n",
    "$$M:=\\begin{pmatrix}\n",
    "    0 & -\\inf & -\\inf \\\\ \n",
    "    0 & 0 & -\\inf \\\\ \n",
    "    0 & 0 & 0 \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "For sake of understanding, consider following example in full: \n",
    "\n",
    "$$X:=\\begin{pmatrix}\n",
    "    1 & 0 \\\\ \n",
    "    0.5 & 1 \\\\ \n",
    "    0 & 1.5 \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "For context, in above, the \"length of timeseries $X$\" is the number of row of $X$, i.e. 3. And the \"dimension of each time step of $X$\" is number of column of $X$ i.e. 2. \n",
    "We will use a pythonic notation $X[i]$ to indicate the $i^th$ row of $X$ for $0\\leq i\\leq 2$. \n",
    "\n",
    "We take $Q=K=V:=X$ (so we are doing a self attention), and have that (we are setting $\\sqrt{d_Q}$ to be 1, for simplicity): \n",
    "\n",
    "$$QK^T=\\begin{pmatrix}\n",
    "    1 & 0.5 & 0 \\\\ \n",
    "    0.5 & 1.25 & 1.5 \\\\ \n",
    "    0 & 1.5 & 2.25 \n",
    "\\end{pmatrix}$$ \n",
    "\n",
    "And so \n",
    "\n",
    "$$QK^T+M=\\begin{pmatrix}\n",
    "    1 & -\\inf & -\\inf \\\\ \n",
    "    0.5 & 1.25 & -\\inf \\\\ \n",
    "    0 & 1.5 & 2.25 \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Then we apply the softmax on this matrix, recall definition of the soft max: \n",
    "\n",
    "$$ softmax(x_{i}):=\\frac{e^{x_{i}}}{\\sum\\limits_{j\\in \\text{ index set}} e^{x_{j}}} $$\n",
    "\n",
    "We should get something close to: \n",
    "\n",
    "$$ Attn=\\begin{pmatrix}\n",
    "    1 & 0 & 0 \\\\ \n",
    "    0.32 & 0.68 & 0 \\\\ \n",
    "    0.06 & 0.21 & 0.73 \n",
    "\\end{pmatrix} V = \\begin{pmatrix}\n",
    "    1 \\cdot  X\\left[ 0 \\right] \\\\ \n",
    "    0.32\\ \\cdot  X\\left[ 0 \\right]  +  0.68 \\cdot  X\\left[ 1 \\right] \\\\ \n",
    "    0.06\\ \\cdot  X\\left[ 0 \\right]  +  0.21 \\cdot  X\\left[ 1 \\right]  +  0.73 \\cdot  X\\left[ 2 \\right]\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Notice that in practice (not in current example), $X$ would be \"shifted down\" (before even the first calculation) in the sense that $X[0]$ is set to 0, and $X[i]$ is set to the \"old\" $X[i-1]$ for all $i>0$ with the last row removed. As an example, the shifted down version of $X$ is \n",
    "\n",
    "$$ \\begin{pmatrix}0 & 0 \\\\ 1 & 0 \\\\ 0.5 & 1\\end{pmatrix} $$\n",
    "\n",
    "Intuitively, $Attn[i]$ is only determined by $X[j]$ for $0\\leq j\\leq i$ for all $i$. This makes it so that \"Attention with casual masking can not look into the future for current step\". \n",
    "\n",
    "One should note that above is only applied to the self attention layer on the ground target of our custom decoder. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f0437",
   "metadata": {},
   "source": [
    "### Create dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bda4a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548fadb6",
   "metadata": {},
   "source": [
    "### Create components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc14a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_emb_dim=32\n",
    "n_diff=2\n",
    "ts_dim=n_diff+1\n",
    "\n",
    "pos_embedder=training.pos_emb_cross_attn(length=60,ts_dim=ts_dim,emb_dim=ts_emb_dim,dropout=0.2,num_heads=4,keep_mag=True).to(device=device)\n",
    "\n",
    "ts_encoder_ff_layer=[\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "]\n",
    "\n",
    "ts_decoder_ff_layer=[\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "]\n",
    "\n",
    "output_ff=nn.Sequential(\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=1)\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba9378",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd6155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_encoder_decoder_tf_model=training.encoder_decoder_teacherforcing(\n",
    "    pos_emb_model=pos_embedder,\n",
    "    output_feedforward=output_ff,\n",
    "    encoder_dropout=0.2,\n",
    "    decoder_dropout=0.2,\n",
    "    encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "    decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "    n_diff=n_diff,\n",
    "    encoder_layer_num=2,\n",
    "    decoder_layer_num=2,\n",
    "    input_scaler=10000,\n",
    "    ts_emb_dim=ts_emb_dim,\n",
    "    encoder_num_heads=4,\n",
    "    decoder_num_heads=4,\n",
    "    encoder_keep_mag=True,\n",
    "    decoder_keep_mag=True,\n",
    "    return_sum=True\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107bebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(trans_encoder_decoder_tf_model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode=\"min\",factor=0.5,patience=5,min_lr=1e-7)\n",
    "\n",
    "# Loss tracking\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a420c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "encoder_decoder_teacherforcing                               --\n",
       "â”œâ”€frozen_diff_conv: 1-1                                      --\n",
       "â”‚    â””â”€Conv1d: 2-1                                           (2)\n",
       "â”œâ”€pos_emb_cross_attn: 1-2                                    --\n",
       "â”‚    â””â”€Linear: 2-2                                           128\n",
       "â”‚    â””â”€Embedding: 2-3                                        1,920\n",
       "â”‚    â””â”€MultiheadAttention: 2-4                               3,168\n",
       "â”‚    â”‚    â””â”€NonDynamicallyQuantizableLinear: 3-1             1,056\n",
       "â”‚    â””â”€LayerNorm: 2-5                                        64\n",
       "â”œâ”€ModuleList: 1-3                                            --\n",
       "â”‚    â””â”€ts_encoder: 2-6                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-2                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-3                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-4                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-5                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-7                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-6                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-7                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-8                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-9                                   64\n",
       "â”œâ”€ModuleList: 1-4                                            --\n",
       "â”‚    â””â”€ts_decoder: 2-8                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-10                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-11                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-12                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-13                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-14                                 4,192\n",
       "â”‚    â””â”€ts_decoder: 2-9                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-15                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-16                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-17                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-18                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-19                                 4,192\n",
       "â”œâ”€Sequential: 1-5                                            --\n",
       "â”‚    â””â”€Linear: 2-10                                          33\n",
       "=====================================================================================\n",
       "Total params: 48,995\n",
       "Trainable params: 48,993\n",
       "Non-trainable params: 2\n",
       "====================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(trans_encoder_decoder_tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e797de",
   "metadata": {},
   "source": [
    "### Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d2745e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new best validation loss at epoch  1  with validation loss of  tensor(0.2360, device='cuda:0') .\n",
      "At  24.368682146072388  epoch  1 has training loss  tensor(0.2746, device='cuda:0')  and validation loss  tensor(0.2360, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  2  with validation loss of  tensor(0.2356, device='cuda:0') .\n",
      "A new best validation loss at epoch  3  with validation loss of  tensor(0.2337, device='cuda:0') .\n",
      "A new best validation loss at epoch  4  with validation loss of  tensor(0.2316, device='cuda:0') .\n",
      "At  126.59550452232361  epoch  5 has training loss  tensor(0.2489, device='cuda:0')  and validation loss  tensor(0.2322, device='cuda:0') .\n",
      "\n",
      "At  254.07837462425232  epoch  10 has training loss  tensor(0.2474, device='cuda:0')  and validation loss  tensor(0.2334, device='cuda:0') .\n",
      "\n",
      "At epoch 10, learning rate has been updated from 0.001 to 0.0005, reloading previous best model weights from epoch 4 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "A new best validation loss at epoch  11  with validation loss of  tensor(0.2305, device='cuda:0') .\n",
      "At  381.963880777359  epoch  15 has training loss  tensor(0.2455, device='cuda:0')  and validation loss  tensor(0.2338, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  16  with validation loss of  tensor(0.2302, device='cuda:0') .\n",
      "At  510.6774184703827  epoch  20 has training loss  tensor(0.2447, device='cuda:0')  and validation loss  tensor(0.2303, device='cuda:0') .\n",
      "\n",
      "At epoch 22, learning rate has been updated from 0.0005 to 0.00025, reloading previous best model weights from epoch 16 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "A new best validation loss at epoch  23  with validation loss of  tensor(0.2300, device='cuda:0') .\n",
      "At  640.1796228885651  epoch  25 has training loss  tensor(0.2438, device='cuda:0')  and validation loss  tensor(0.2301, device='cuda:0') .\n",
      "\n",
      "At epoch 29, learning rate has been updated from 0.00025 to 0.000125, reloading previous best model weights from epoch 23 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  770.478236913681  epoch  30 has training loss  tensor(0.2426, device='cuda:0')  and validation loss  tensor(0.2304, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  31  with validation loss of  tensor(0.2300, device='cuda:0') .\n",
      "A new best validation loss at epoch  34  with validation loss of  tensor(0.2299, device='cuda:0') .\n",
      "At  900.7824077606201  epoch  35 has training loss  tensor(0.2425, device='cuda:0')  and validation loss  tensor(0.2303, device='cuda:0') .\n",
      "\n",
      "At  1030.697425365448  epoch  40 has training loss  tensor(0.2423, device='cuda:0')  and validation loss  tensor(0.2314, device='cuda:0') .\n",
      "\n",
      "At epoch 40, learning rate has been updated from 0.000125 to 6.25e-05, reloading previous best model weights from epoch 34 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "A new best validation loss at epoch  42  with validation loss of  tensor(0.2298, device='cuda:0') .\n",
      "At  1160.9671623706818  epoch  45 has training loss  tensor(0.2418, device='cuda:0')  and validation loss  tensor(0.2302, device='cuda:0') .\n",
      "\n",
      "At epoch 48, learning rate has been updated from 6.25e-05 to 3.125e-05, reloading previous best model weights from epoch 42 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  1291.4897248744965  epoch  50 has training loss  tensor(0.2415, device='cuda:0')  and validation loss  tensor(0.2300, device='cuda:0') .\n",
      "\n",
      "At epoch 54, learning rate has been updated from 3.125e-05 to 1.5625e-05, reloading previous best model weights from epoch 42 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  1422.023981332779  epoch  55 has training loss  tensor(0.2414, device='cuda:0')  and validation loss  tensor(0.2302, device='cuda:0') .\n",
      "\n",
      "At  1552.516384601593  epoch  60 has training loss  tensor(0.2414, device='cuda:0')  and validation loss  tensor(0.2305, device='cuda:0') .\n",
      "\n",
      "At epoch 60, learning rate has been updated from 1.5625e-05 to 7.8125e-06, reloading previous best model weights from epoch 42 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 42  with validation loss:  tensor(0.2298, device='cuda:0') .\n",
      " The total number of epoch trained is  62 .\n",
      " Training completed in:  1604.637042760849 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('pos_emb.ts_proj.weight',\n",
       "              tensor([[ 0.5243, -0.2829,  0.1898],\n",
       "                      [ 0.1887,  0.1524, -0.3744],\n",
       "                      [-0.4206, -0.2532,  0.3629],\n",
       "                      [-0.0923,  0.0470,  0.2774],\n",
       "                      [-0.3300, -0.5331, -0.2996],\n",
       "                      [-0.0594, -0.2248, -0.1744],\n",
       "                      [-0.2332, -0.2448, -0.3765],\n",
       "                      [ 0.3739,  0.1150,  0.2523],\n",
       "                      [ 0.2041, -0.5227, -0.2917],\n",
       "                      [-0.3198,  0.3190,  0.1713],\n",
       "                      [-0.1335,  0.1406,  0.0728],\n",
       "                      [-0.3787,  0.2856, -0.1774],\n",
       "                      [ 0.3807, -0.4102, -0.2325],\n",
       "                      [ 0.1481, -0.0115, -0.1855],\n",
       "                      [ 0.0272,  0.3295,  0.0888],\n",
       "                      [-0.5111, -0.2753, -0.0785],\n",
       "                      [ 0.5766, -0.0617, -0.3039],\n",
       "                      [ 0.0300, -0.1933,  0.3012],\n",
       "                      [-0.2925, -0.1909,  0.1449],\n",
       "                      [ 0.1767, -0.2107, -0.2445],\n",
       "                      [ 0.3357, -0.1387, -0.0987],\n",
       "                      [ 0.1075, -0.1032,  0.1972],\n",
       "                      [-0.0604, -0.3734,  0.3556],\n",
       "                      [-0.5212,  0.1433,  0.1022],\n",
       "                      [ 0.2228, -0.6037, -0.4338],\n",
       "                      [-0.0549,  0.4311,  0.1873],\n",
       "                      [-0.0392, -0.1887, -0.2457],\n",
       "                      [-0.1709, -0.0382,  0.3300],\n",
       "                      [ 0.1392, -0.4524, -0.2727],\n",
       "                      [-0.4222,  0.2107, -0.3827],\n",
       "                      [ 0.2909, -0.3976, -0.2844],\n",
       "                      [ 0.1624,  0.1208, -0.0796]], device='cuda:0')),\n",
       "             ('pos_emb.ts_proj.bias',\n",
       "              tensor([-0.3019,  0.2836,  0.3164,  0.2308, -0.3342,  0.0526,  0.5367, -0.4126,\n",
       "                       0.1862, -0.0467,  0.5539,  0.2931,  0.3527, -0.3284, -0.2934,  0.0896,\n",
       "                       0.1727,  0.5797,  0.2616, -0.5172, -0.1208, -0.5043,  0.1644, -0.0633,\n",
       "                       0.2328, -0.3714, -0.1860,  0.4513, -0.2515,  0.2336, -0.1001,  0.1191],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_emb.weight',\n",
       "              tensor([[-0.2467,  0.4863,  1.6131,  ...,  1.1534,  0.2963, -0.8521],\n",
       "                      [-0.3376, -0.9835, -1.0627,  ...,  1.1016, -0.1834,  1.7877],\n",
       "                      [ 0.0472, -1.4857, -0.4454,  ..., -1.4425,  0.2244,  0.5991],\n",
       "                      ...,\n",
       "                      [ 0.9575,  0.3539,  0.5004,  ..., -0.1378,  0.2249,  0.4509],\n",
       "                      [ 0.0184,  1.2176,  0.3489,  ..., -0.7481,  0.4166, -1.2956],\n",
       "                      [-0.5357, -0.8191,  1.2668,  ..., -0.4813,  1.7434, -0.7242]],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.in_proj_weight',\n",
       "              tensor([[-0.1231, -0.0008,  0.0761,  ..., -0.1161,  0.0555,  0.1632],\n",
       "                      [-0.1503,  0.2324, -0.1166,  ...,  0.1914,  0.1203,  0.1693],\n",
       "                      [ 0.1713, -0.0553, -0.0579,  ..., -0.1844, -0.1792, -0.0780],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.1481,  0.0026,  ..., -0.0613,  0.0562, -0.0893],\n",
       "                      [-0.2117, -0.0792, -0.1069,  ...,  0.2165, -0.0380,  0.0240],\n",
       "                      [-0.0772,  0.0710,  0.1214,  ...,  0.1416,  0.1012, -0.1734]],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.in_proj_bias',\n",
       "              tensor([ 3.0062e-03, -3.7004e-02,  3.5549e-02, -4.2981e-02, -7.8523e-02,\n",
       "                       7.8567e-02, -7.4644e-03,  3.3989e-02,  9.3950e-03, -8.3335e-03,\n",
       "                      -1.1059e-02, -3.1734e-02, -3.6551e-02, -1.5213e-02, -1.2508e-02,\n",
       "                       1.4380e-03,  9.1067e-03, -7.4100e-02, -5.7430e-02, -1.0535e-01,\n",
       "                      -2.7744e-02, -1.6745e-02, -2.5163e-02,  7.0414e-03, -5.2830e-02,\n",
       "                      -4.7440e-02,  1.1116e-02,  1.8214e-03,  4.2013e-03, -4.0678e-03,\n",
       "                      -3.3766e-02,  1.9769e-02, -1.5446e-04,  1.0149e-04,  1.6614e-04,\n",
       "                       1.8696e-04, -1.2649e-04, -1.9372e-04, -5.0371e-05, -1.5630e-05,\n",
       "                       9.1292e-04, -1.0931e-04,  2.1912e-04, -2.0570e-04,  1.3884e-03,\n",
       "                       1.2917e-03,  9.1767e-04,  1.3007e-03,  9.5151e-04,  2.6730e-04,\n",
       "                       3.2024e-05,  4.4008e-04,  1.7973e-05, -3.3391e-06, -6.2993e-04,\n",
       "                      -2.8540e-04, -3.7127e-04, -3.1858e-05, -1.2717e-03, -3.3200e-04,\n",
       "                      -1.0735e-03,  3.9330e-04, -2.5387e-04, -1.4299e-04,  1.3293e-02,\n",
       "                       6.1166e-03, -1.1777e-02,  9.7340e-03,  5.5767e-03,  2.0809e-02,\n",
       "                      -6.1126e-03,  6.3271e-03, -6.0017e-07, -2.5717e-03, -1.6241e-02,\n",
       "                       1.4782e-02, -4.9354e-03,  2.2137e-02, -4.8672e-03,  5.1387e-03,\n",
       "                      -2.4967e-02,  3.6847e-02,  1.7531e-02,  1.2584e-02,  8.6297e-03,\n",
       "                      -1.6730e-02, -2.0741e-02, -2.7764e-03,  2.8159e-03, -1.5240e-02,\n",
       "                      -1.7978e-02, -2.7458e-02,  2.6943e-02, -1.9226e-02, -1.3017e-02,\n",
       "                      -5.1705e-03], device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.out_proj.weight',\n",
       "              tensor([[ 0.0666, -0.0550,  0.0465,  ..., -0.0664, -0.0596,  0.0212],\n",
       "                      [-0.1272, -0.0075,  0.0988,  ...,  0.0927, -0.0546, -0.0932],\n",
       "                      [ 0.0809,  0.0052, -0.0947,  ..., -0.0144, -0.3120,  0.0570],\n",
       "                      ...,\n",
       "                      [ 0.2611,  0.0193, -0.1007,  ..., -0.0282, -0.1919, -0.0735],\n",
       "                      [ 0.0590,  0.0455,  0.0423,  ..., -0.0334, -0.0478, -0.0057],\n",
       "                      [ 0.0256, -0.0153,  0.1413,  ...,  0.0381,  0.1662, -0.0841]],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_attn.out_proj.bias',\n",
       "              tensor([-0.0552, -0.0572,  0.0276, -0.0219, -0.0131,  0.0287,  0.0417, -0.0462,\n",
       "                       0.0137,  0.0191,  0.0618,  0.0211, -0.0130, -0.0554,  0.0034,  0.0573,\n",
       "                      -0.0203,  0.1088,  0.0338, -0.0598, -0.0354, -0.0423,  0.0737,  0.0475,\n",
       "                       0.0119, -0.0572, -0.0141,  0.0454, -0.0143,  0.0341, -0.0240, -0.0203],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_emb.pos_norm.weight',\n",
       "              tensor([0.7693, 0.7927, 0.7920, 0.8385, 0.8735, 0.7715, 0.8902, 0.7407, 0.8927,\n",
       "                      0.8388, 0.8758, 0.7107, 0.8781, 0.8537, 0.8097, 0.8425, 0.8733, 0.9320,\n",
       "                      0.8618, 0.8903, 0.8158, 0.8657, 0.8183, 0.8893, 0.8740, 0.8947, 0.8166,\n",
       "                      0.7940, 0.7864, 0.9630, 0.8256, 0.7720], device='cuda:0')),\n",
       "             ('pos_emb.pos_norm.bias',\n",
       "              tensor([-0.0560, -0.0629,  0.0400, -0.0467, -0.0284,  0.0489,  0.0376, -0.0672,\n",
       "                       0.0022,  0.0337,  0.0602,  0.0242,  0.0052, -0.0458,  0.0014,  0.0674,\n",
       "                      -0.0167,  0.0966,  0.0286, -0.0469, -0.0560, -0.0348,  0.0858,  0.0329,\n",
       "                       0.0082, -0.0644, -0.0150,  0.0418, -0.0177,  0.0701, -0.0582, -0.0249],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.in_proj_weight',\n",
       "              tensor([[-0.0857, -0.0577,  0.2444,  ..., -0.0296,  0.0919, -0.0608],\n",
       "                      [ 0.1100,  0.0844,  0.1361,  ..., -0.1715, -0.0415,  0.1161],\n",
       "                      [-0.0781, -0.1478,  0.1472,  ...,  0.0464, -0.0973,  0.1314],\n",
       "                      ...,\n",
       "                      [ 0.0859, -0.0762,  0.0158,  ...,  0.0495, -0.1533,  0.0390],\n",
       "                      [-0.1645, -0.2093,  0.1861,  ...,  0.1269, -0.1537,  0.0024],\n",
       "                      [-0.0320,  0.0125,  0.1054,  ...,  0.1544, -0.0901, -0.0615]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.in_proj_bias',\n",
       "              tensor([ 3.9076e-04,  6.5478e-02,  2.3768e-03, -2.3574e-03, -2.2096e-02,\n",
       "                       1.0212e-02,  4.6086e-02,  5.2526e-02,  3.2172e-02,  1.8615e-02,\n",
       "                       1.4165e-02,  3.0548e-02, -2.9795e-02,  1.3548e-02, -1.7994e-02,\n",
       "                       2.4305e-02, -4.0787e-03, -3.4270e-02,  6.6212e-02, -2.5628e-02,\n",
       "                       1.0302e-04,  5.8059e-02, -3.9465e-02, -6.9291e-02, -2.7621e-02,\n",
       "                      -3.1315e-02,  4.7886e-02, -1.3429e-02, -2.6409e-03,  1.7148e-02,\n",
       "                      -2.0842e-02, -2.5637e-02,  1.8355e-04,  5.4450e-04, -1.3355e-04,\n",
       "                      -1.3366e-04, -3.1109e-04, -1.1327e-05, -2.6298e-06, -8.2522e-05,\n",
       "                      -1.0431e-04,  4.0279e-04, -4.1191e-04, -1.1963e-04, -9.5492e-04,\n",
       "                       4.1849e-04,  1.7599e-05,  1.8665e-04, -5.6309e-06,  4.5584e-04,\n",
       "                      -7.3484e-04,  8.0313e-05,  2.3242e-04, -5.5557e-04, -1.2065e-05,\n",
       "                       1.2808e-03,  2.2437e-04, -5.6524e-05, -3.3464e-04, -3.7693e-05,\n",
       "                       7.5631e-05, -2.4822e-04, -1.0486e-04,  1.3916e-04, -1.3690e-02,\n",
       "                      -1.2279e-01, -6.0034e-02, -1.4106e-02, -6.5099e-02,  5.7555e-03,\n",
       "                       1.0870e-01, -2.1801e-02,  3.7518e-02, -7.4257e-02, -1.0403e-02,\n",
       "                       3.1751e-02,  6.3104e-03, -1.5674e-02,  6.2430e-02,  6.7906e-02,\n",
       "                       1.5055e-02,  3.3312e-02, -2.9195e-02, -6.8381e-04,  7.9454e-02,\n",
       "                       2.6565e-02,  1.5417e-02, -9.8908e-04,  5.7144e-02, -7.2398e-02,\n",
       "                      -2.9876e-02, -2.4360e-02,  3.4461e-02, -2.0167e-02,  1.4147e-02,\n",
       "                       4.0709e-02], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.out_proj.weight',\n",
       "              tensor([[ 0.0651, -0.0177,  0.1170,  ..., -0.1347,  0.0672, -0.0917],\n",
       "                      [-0.1027, -0.0586, -0.0736,  ...,  0.0920,  0.1047,  0.0722],\n",
       "                      [ 0.1887, -0.2206, -0.0701,  ...,  0.0298, -0.1325, -0.1706],\n",
       "                      ...,\n",
       "                      [ 0.0857,  0.2289, -0.0285,  ..., -0.0831, -0.1344, -0.0740],\n",
       "                      [ 0.0408, -0.1611, -0.0106,  ...,  0.0180,  0.0331,  0.1752],\n",
       "                      [ 0.0923,  0.2026,  0.1122,  ..., -0.0312, -0.0286,  0.1495]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_attn.out_proj.bias',\n",
       "              tensor([-0.0942, -0.0235,  0.0471, -0.0182, -0.0847,  0.0534,  0.0551, -0.1091,\n",
       "                       0.0256,  0.0197,  0.1162,  0.1028,  0.0470, -0.0734, -0.0382,  0.0676,\n",
       "                      -0.0160,  0.2070,  0.0530, -0.0818, -0.0575, -0.0889,  0.1670,  0.0080,\n",
       "                       0.0378, -0.1402, -0.0632,  0.0700, -0.1032,  0.0793, -0.0565, -0.0092],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm1.weight',\n",
       "              tensor([0.6604, 0.8014, 0.7758, 0.8456, 0.9644, 0.8520, 0.8763, 0.7457, 0.8002,\n",
       "                      0.7460, 0.8491, 0.6014, 0.9212, 0.7463, 0.7834, 0.7895, 0.8172, 0.9053,\n",
       "                      0.7757, 0.8541, 0.7601, 0.8697, 0.8151, 0.8625, 0.8927, 0.8804, 0.8545,\n",
       "                      0.7591, 0.7835, 0.9905, 0.7937, 0.7866], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm1.bias',\n",
       "              tensor([-4.9046e-02, -7.1880e-02,  4.9692e-02, -3.4719e-02, -1.4125e-02,\n",
       "                       7.8056e-02,  2.4349e-02, -5.8112e-02,  1.4162e-03,  2.5291e-02,\n",
       "                       4.3003e-02, -5.2113e-04,  9.3189e-03, -2.6015e-02, -1.0475e-02,\n",
       "                       4.9107e-02, -1.2934e-02,  7.6449e-02,  3.0627e-02, -3.1213e-02,\n",
       "                      -4.4244e-02, -1.8864e-02,  6.7877e-02,  2.7901e-02,  1.2069e-02,\n",
       "                      -8.6616e-02, -9.5137e-03,  3.5201e-02, -6.9819e-03,  6.7429e-02,\n",
       "                      -2.8050e-02, -4.0924e-06], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.0.weight',\n",
       "              tensor([[-0.1589, -0.1213, -0.0090,  ..., -0.0449, -0.1178, -0.1426],\n",
       "                      [-0.1838,  0.1027, -0.0931,  ..., -0.0645, -0.1459,  0.0330],\n",
       "                      [ 0.0442,  0.0107,  0.1440,  ..., -0.1254,  0.0247, -0.1932],\n",
       "                      ...,\n",
       "                      [-0.1061, -0.1138,  0.0863,  ...,  0.0906, -0.0673,  0.0654],\n",
       "                      [-0.1469, -0.0694,  0.1819,  ...,  0.0644,  0.0149, -0.1423],\n",
       "                      [ 0.1299,  0.0315,  0.1107,  ..., -0.1147, -0.1634,  0.0757]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.0.bias',\n",
       "              tensor([ 0.0160, -0.0121, -0.0749,  0.0793, -0.1146, -0.0078,  0.0056, -0.0333,\n",
       "                      -0.1110,  0.1009, -0.0430, -0.2746, -0.1503, -0.0748,  0.0640,  0.0192,\n",
       "                      -0.1369,  0.0358, -0.1050, -0.2184,  0.0659, -0.0185, -0.1371, -0.1457,\n",
       "                      -0.0069, -0.2198, -0.1009, -0.0512, -0.0457, -0.1439, -0.0746, -0.0268,\n",
       "                      -0.1934, -0.1520, -0.2091, -0.1585, -0.0549, -0.0420, -0.1320, -0.2390,\n",
       "                      -0.0301,  0.0931,  0.0775, -0.0207, -0.0065, -0.2174, -0.1460, -0.0485,\n",
       "                      -0.1442, -0.1657, -0.0240, -0.0430, -0.2342,  0.0700, -0.0507,  0.0509,\n",
       "                      -0.0385, -0.1399, -0.0317,  0.0525, -0.1493,  0.0862, -0.1013,  0.0546],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.2.weight',\n",
       "              tensor([[ 0.0478, -0.0395,  0.0982,  ..., -0.0017,  0.0521,  0.0704],\n",
       "                      [-0.1075,  0.0329,  0.1203,  ...,  0.1909,  0.0191, -0.0319],\n",
       "                      [-0.1289, -0.0846, -0.0464,  ..., -0.2306,  0.0038, -0.0546],\n",
       "                      ...,\n",
       "                      [-0.0423, -0.0457,  0.0840,  ..., -0.0596, -0.0293,  0.0253],\n",
       "                      [ 0.0052,  0.0567,  0.0365,  ..., -0.1615, -0.0922,  0.0324],\n",
       "                      [ 0.1605,  0.0399, -0.0396,  ..., -0.0720, -0.0115,  0.0462]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_feedforward.2.bias',\n",
       "              tensor([-0.0752, -0.1530,  0.0583,  0.0539, -0.1190, -0.0074,  0.0425, -0.0292,\n",
       "                       0.0656,  0.0885,  0.0599,  0.0176, -0.0270, -0.0475,  0.0657,  0.0839,\n",
       "                      -0.0302,  0.1002,  0.0302,  0.0421,  0.0385,  0.0245,  0.1248,  0.0411,\n",
       "                       0.0366, -0.0619,  0.0668,  0.0126,  0.1039,  0.0240, -0.0693, -0.0479],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm2.weight',\n",
       "              tensor([0.7918, 0.8200, 0.8231, 0.8589, 0.9153, 0.9641, 0.8849, 0.8123, 0.7913,\n",
       "                      0.7977, 0.8659, 0.7756, 0.8668, 0.8850, 0.8286, 0.8491, 0.8480, 0.9214,\n",
       "                      0.8626, 0.8701, 0.8254, 0.8398, 0.8158, 0.8455, 0.8663, 0.7942, 0.8547,\n",
       "                      0.8153, 0.7844, 0.9576, 0.8112, 0.7858], device='cuda:0')),\n",
       "             ('encoder_layers.0.encoder_norm2.bias',\n",
       "              tensor([-0.0278, -0.0512,  0.0479, -0.0361, -0.0262,  0.0678,  0.0071, -0.0451,\n",
       "                      -0.0105,  0.0245,  0.0257, -0.0362, -0.0167,  0.0035,  0.0086,  0.0248,\n",
       "                       0.0037,  0.0551,  0.0007, -0.0127,  0.0075,  0.0015,  0.0529,  0.0035,\n",
       "                      -0.0071, -0.0611,  0.0016,  0.0204,  0.0512,  0.0251, -0.0217, -0.0095],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.in_proj_weight',\n",
       "              tensor([[-0.1309, -0.0782,  0.2747,  ...,  0.0404, -0.1002, -0.1484],\n",
       "                      [-0.0100, -0.1477, -0.0887,  ...,  0.1451,  0.0134, -0.1002],\n",
       "                      [ 0.2084, -0.0503,  0.0901,  ..., -0.1200,  0.1400,  0.1876],\n",
       "                      ...,\n",
       "                      [ 0.1778,  0.0042,  0.1776,  ..., -0.1682, -0.0737, -0.1035],\n",
       "                      [ 0.1365, -0.1255, -0.0725,  ..., -0.1669,  0.0344, -0.0691],\n",
       "                      [ 0.2710, -0.0317,  0.2617,  ...,  0.0948,  0.0770,  0.1847]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.in_proj_bias',\n",
       "              tensor([ 1.6352e-02, -1.5222e-02, -2.7435e-02,  1.6997e-02, -2.5280e-02,\n",
       "                      -3.6986e-02,  3.2610e-02,  2.9154e-02,  3.5756e-02,  5.0532e-02,\n",
       "                      -5.3228e-02,  1.0151e-02,  1.8914e-02,  2.8553e-02,  1.9177e-02,\n",
       "                       3.1675e-02,  1.0937e-02, -6.8878e-03,  5.3203e-02,  4.2689e-02,\n",
       "                       2.8012e-02, -1.6727e-02,  2.2797e-02,  3.7702e-03,  4.2133e-02,\n",
       "                      -9.2815e-03,  3.6703e-02,  6.6466e-02, -5.3733e-02, -3.9813e-02,\n",
       "                      -5.5667e-02, -7.3637e-03,  2.1179e-05,  5.6928e-05,  1.6662e-04,\n",
       "                      -4.1785e-07, -1.1188e-04, -6.6413e-05,  3.1282e-05,  2.7543e-05,\n",
       "                       1.5508e-05, -4.8210e-05, -5.7735e-05, -8.4760e-05, -1.0240e-04,\n",
       "                      -1.6498e-04, -1.6776e-05,  4.4722e-05,  1.0666e-04,  2.8041e-05,\n",
       "                       2.6683e-05, -1.2865e-04, -5.2027e-05,  2.8099e-06,  5.7005e-05,\n",
       "                      -7.0133e-05, -2.3509e-05,  1.5154e-04,  4.1493e-05,  3.5384e-05,\n",
       "                      -2.8327e-05,  1.1512e-04,  5.9010e-04,  7.5139e-05,  2.9953e-02,\n",
       "                      -7.6004e-02, -5.3340e-04,  8.1826e-03,  4.6425e-03, -1.9377e-03,\n",
       "                      -1.0973e-02, -5.8123e-03,  1.7487e-02,  2.5306e-02, -2.6116e-02,\n",
       "                      -1.0982e-02,  7.4072e-03, -1.6609e-02,  6.7311e-03, -6.0299e-03,\n",
       "                       3.2332e-03,  1.4636e-02, -9.7991e-02, -6.1032e-02,  1.2227e-02,\n",
       "                      -2.3079e-02, -2.6073e-02,  2.8804e-02, -2.2059e-02, -2.7460e-02,\n",
       "                       1.8705e-02, -3.6062e-02,  8.2624e-02, -9.2484e-03, -7.3978e-02,\n",
       "                       5.0702e-02], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.out_proj.weight',\n",
       "              tensor([[-0.0746,  0.0143,  0.0727,  ...,  0.0678, -0.0746, -0.0685],\n",
       "                      [-0.1691, -0.0141,  0.1317,  ...,  0.0564,  0.0252, -0.0834],\n",
       "                      [ 0.0112, -0.0076, -0.0253,  ...,  0.1491,  0.1478,  0.0110],\n",
       "                      ...,\n",
       "                      [ 0.0847,  0.1614, -0.2720,  ...,  0.1126, -0.0328,  0.0933],\n",
       "                      [ 0.0220, -0.0029,  0.0393,  ...,  0.1534,  0.0789, -0.0141],\n",
       "                      [ 0.0677, -0.1303,  0.0839,  ...,  0.1613, -0.0841, -0.0869]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_attn.out_proj.bias',\n",
       "              tensor([-0.0453, -0.0567,  0.0284, -0.0699, -0.0931,  0.0152,  0.0155, -0.0756,\n",
       "                       0.0037,  0.0032,  0.0693, -0.0547,  0.0445, -0.0111,  0.0029,  0.0389,\n",
       "                       0.0143,  0.1099, -0.0461, -0.0326,  0.0038, -0.0164,  0.1093, -0.0220,\n",
       "                      -0.0183, -0.1753, -0.0220,  0.0380, -0.0050,  0.0199, -0.0399, -0.0022],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm1.weight',\n",
       "              tensor([0.7647, 0.8394, 0.8162, 0.8727, 0.8959, 0.9347, 0.8480, 0.7658, 0.8339,\n",
       "                      0.7980, 0.8267, 0.7924, 0.8486, 0.9028, 0.7928, 0.8477, 0.8367, 0.8828,\n",
       "                      0.8891, 0.8565, 0.8755, 0.8321, 0.8018, 0.8236, 0.8917, 0.9603, 0.8628,\n",
       "                      0.7803, 0.8560, 0.9903, 0.8139, 0.8104], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm1.bias',\n",
       "              tensor([-0.0074, -0.0463,  0.0337, -0.0468, -0.0074,  0.0321, -0.0034, -0.0240,\n",
       "                      -0.0039,  0.0174,  0.0075, -0.0410, -0.0269, -0.0004,  0.0192,  0.0079,\n",
       "                       0.0048,  0.0313, -0.0181, -0.0007,  0.0097,  0.0120,  0.0293,  0.0169,\n",
       "                      -0.0240, -0.0408,  0.0007,  0.0152,  0.0284,  0.0115, -0.0083, -0.0008],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.0.weight',\n",
       "              tensor([[-0.1589, -0.1213, -0.0090,  ..., -0.0449, -0.1178, -0.1426],\n",
       "                      [-0.1838,  0.1027, -0.0931,  ..., -0.0645, -0.1459,  0.0330],\n",
       "                      [ 0.0442,  0.0107,  0.1440,  ..., -0.1254,  0.0247, -0.1932],\n",
       "                      ...,\n",
       "                      [-0.1061, -0.1138,  0.0863,  ...,  0.0906, -0.0673,  0.0654],\n",
       "                      [-0.1469, -0.0694,  0.1819,  ...,  0.0644,  0.0149, -0.1423],\n",
       "                      [ 0.1299,  0.0315,  0.1107,  ..., -0.1147, -0.1634,  0.0757]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.0.bias',\n",
       "              tensor([ 0.0160, -0.0121, -0.0749,  0.0793, -0.1146, -0.0078,  0.0056, -0.0333,\n",
       "                      -0.1110,  0.1009, -0.0430, -0.2746, -0.1503, -0.0748,  0.0640,  0.0192,\n",
       "                      -0.1369,  0.0358, -0.1050, -0.2184,  0.0659, -0.0185, -0.1371, -0.1457,\n",
       "                      -0.0069, -0.2198, -0.1009, -0.0512, -0.0457, -0.1439, -0.0746, -0.0268,\n",
       "                      -0.1934, -0.1520, -0.2091, -0.1585, -0.0549, -0.0420, -0.1320, -0.2390,\n",
       "                      -0.0301,  0.0931,  0.0775, -0.0207, -0.0065, -0.2174, -0.1460, -0.0485,\n",
       "                      -0.1442, -0.1657, -0.0240, -0.0430, -0.2342,  0.0700, -0.0507,  0.0509,\n",
       "                      -0.0385, -0.1399, -0.0317,  0.0525, -0.1493,  0.0862, -0.1013,  0.0546],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.2.weight',\n",
       "              tensor([[ 0.0478, -0.0395,  0.0982,  ..., -0.0017,  0.0521,  0.0704],\n",
       "                      [-0.1075,  0.0329,  0.1203,  ...,  0.1909,  0.0191, -0.0319],\n",
       "                      [-0.1289, -0.0846, -0.0464,  ..., -0.2306,  0.0038, -0.0546],\n",
       "                      ...,\n",
       "                      [-0.0423, -0.0457,  0.0840,  ..., -0.0596, -0.0293,  0.0253],\n",
       "                      [ 0.0052,  0.0567,  0.0365,  ..., -0.1615, -0.0922,  0.0324],\n",
       "                      [ 0.1605,  0.0399, -0.0396,  ..., -0.0720, -0.0115,  0.0462]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_feedforward.2.bias',\n",
       "              tensor([-0.0752, -0.1530,  0.0583,  0.0539, -0.1190, -0.0074,  0.0425, -0.0292,\n",
       "                       0.0656,  0.0885,  0.0599,  0.0176, -0.0270, -0.0475,  0.0657,  0.0839,\n",
       "                      -0.0302,  0.1002,  0.0302,  0.0421,  0.0385,  0.0245,  0.1248,  0.0411,\n",
       "                       0.0366, -0.0619,  0.0668,  0.0126,  0.1039,  0.0240, -0.0693, -0.0479],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm2.weight',\n",
       "              tensor([0.8032, 0.8424, 0.8254, 0.8753, 0.8245, 0.8930, 0.8594, 0.8519, 0.8132,\n",
       "                      0.8030, 0.8025, 0.7930, 0.8285, 0.9241, 0.8162, 0.8407, 0.8096, 0.8757,\n",
       "                      0.7524, 0.8537, 0.8471, 0.8239, 0.7947, 0.7996, 0.9242, 0.9004, 0.8748,\n",
       "                      0.8316, 0.9003, 0.9145, 0.8242, 0.8100], device='cuda:0')),\n",
       "             ('encoder_layers.1.encoder_norm2.bias',\n",
       "              tensor([ 0.0010, -0.0526,  0.0571, -0.0232,  0.0474,  0.0106, -0.0072, -0.0066,\n",
       "                      -0.0437,  0.0263, -0.0182, -0.0583, -0.0641,  0.0028,  0.0140,  0.0211,\n",
       "                      -0.0240,  0.0101,  0.0233,  0.0126,  0.0165,  0.0233,  0.0036,  0.0332,\n",
       "                      -0.0172,  0.0247, -0.0021,  0.0063,  0.0480, -0.0225, -0.0081, -0.0303],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.in_proj_weight',\n",
       "              tensor([[ 1.8134e-01,  1.1529e-01,  1.1530e-01,  ..., -1.9448e-01,\n",
       "                        1.8422e-01,  2.3894e-01],\n",
       "                      [-1.2397e-01,  4.5207e-02, -8.1844e-02,  ...,  6.5512e-02,\n",
       "                       -7.1931e-02,  1.3955e-01],\n",
       "                      [ 1.9323e-01, -8.0288e-02,  1.1686e-04,  ..., -2.4550e-01,\n",
       "                        2.6280e-02, -1.1538e-01],\n",
       "                      ...,\n",
       "                      [-1.8157e-01, -1.1446e-01,  1.1977e-01,  ...,  1.4490e-01,\n",
       "                        1.8285e-01, -7.7089e-02],\n",
       "                      [-1.8180e-01, -9.3029e-02, -1.8051e-01,  ...,  2.8113e-01,\n",
       "                        1.6048e-02,  6.2523e-02],\n",
       "                      [ 3.2973e-03, -2.3543e-01, -1.7784e-02,  ...,  9.9511e-02,\n",
       "                       -2.1956e-01,  8.9868e-02]], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.in_proj_bias',\n",
       "              tensor([ 6.1420e-03, -1.7289e-02, -7.6377e-02, -1.2644e-02, -1.0588e-01,\n",
       "                       9.3235e-03, -7.4502e-02,  9.8430e-02,  2.0601e-02, -6.0012e-02,\n",
       "                       9.3253e-04,  3.6723e-02,  9.3423e-03,  5.8035e-02,  3.8202e-02,\n",
       "                       8.0863e-02, -8.3526e-02, -5.7854e-02,  8.2236e-03, -1.2203e-02,\n",
       "                       5.7406e-02, -1.2832e-01, -1.9755e-02, -3.5635e-02, -4.7777e-03,\n",
       "                       6.0975e-02,  2.7015e-02, -2.5294e-02, -5.3012e-02,  4.2629e-02,\n",
       "                       3.8385e-02, -4.2203e-03, -1.0913e-04, -1.3810e-04, -1.8360e-04,\n",
       "                      -1.2602e-04,  1.1477e-04, -3.6429e-04, -5.2885e-05, -7.2403e-06,\n",
       "                      -3.7917e-04, -1.4843e-04,  1.1822e-04, -2.4478e-04,  1.4965e-04,\n",
       "                      -1.2054e-04, -1.2539e-04, -3.0499e-04, -9.1501e-05, -5.7974e-07,\n",
       "                       4.1447e-05,  2.4171e-05, -7.8052e-05,  3.2743e-05,  1.3228e-04,\n",
       "                       7.6917e-05,  1.7183e-05, -5.2526e-05, -1.6237e-05,  9.1919e-05,\n",
       "                       4.5604e-04, -2.1632e-04, -1.3991e-04,  8.5175e-05,  3.1673e-02,\n",
       "                       6.4214e-02, -7.4086e-03, -4.9691e-02, -3.2877e-02, -7.7823e-03,\n",
       "                       1.6464e-02,  1.3988e-02, -1.4018e-02,  1.5923e-02, -5.0684e-03,\n",
       "                      -1.2213e-02, -2.8537e-03,  1.7284e-02, -4.2853e-03, -2.8184e-02,\n",
       "                      -1.0831e-02, -1.1075e-02, -2.6034e-03,  1.9378e-02,  1.1214e-02,\n",
       "                      -3.2835e-02,  1.8047e-02,  4.6012e-02, -2.7333e-02, -2.6944e-02,\n",
       "                       3.1693e-02,  3.1871e-02, -4.7174e-02, -1.9880e-02,  9.5333e-03,\n",
       "                      -3.4937e-02], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0924, -0.0999, -0.1071,  ...,  0.1480,  0.1075, -0.1351],\n",
       "                      [-0.0448, -0.1310,  0.1592,  ..., -0.0122,  0.0482, -0.0114],\n",
       "                      [ 0.0011, -0.2178,  0.0610,  ..., -0.0490,  0.1339, -0.0833],\n",
       "                      ...,\n",
       "                      [ 0.1436, -0.1651,  0.0761,  ..., -0.2278, -0.1342, -0.0785],\n",
       "                      [-0.1431, -0.0651, -0.0119,  ..., -0.0887, -0.1100, -0.1471],\n",
       "                      [-0.0344, -0.0038, -0.2553,  ...,  0.1265,  0.1233, -0.0511]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_self_attn.out_proj.bias',\n",
       "              tensor([ 0.0045, -0.0385,  0.0053, -0.0042, -0.0728,  0.0659, -0.0084, -0.0477,\n",
       "                       0.0060,  0.0070,  0.0215, -0.0122, -0.0226,  0.0143, -0.0344,  0.0436,\n",
       "                       0.0154,  0.0979, -0.0357,  0.0032,  0.0101,  0.0195,  0.0570, -0.0115,\n",
       "                      -0.0187, -0.1233, -0.0053,  0.0176,  0.0341,  0.0029, -0.0207,  0.0092],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm1.weight',\n",
       "              tensor([0.8211, 0.8973, 0.7896, 0.7794, 0.8774, 0.9313, 0.8504, 0.9018, 0.8261,\n",
       "                      0.8175, 0.8701, 0.8541, 0.8758, 0.8453, 0.8433, 0.8985, 0.8512, 1.0096,\n",
       "                      0.8809, 0.8602, 0.8017, 0.8824, 0.8503, 0.8520, 0.8556, 0.9213, 0.8285,\n",
       "                      0.8457, 0.8926, 0.9181, 0.8373, 0.8491], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm1.bias',\n",
       "              tensor([ 0.0102, -0.0386,  0.0019, -0.0010, -0.0407,  0.0426, -0.0135, -0.0322,\n",
       "                       0.0030,  0.0058,  0.0101, -0.0128, -0.0493,  0.0170, -0.0288,  0.0322,\n",
       "                       0.0158,  0.0830, -0.0332,  0.0088,  0.0059,  0.0251,  0.0374, -0.0095,\n",
       "                      -0.0182, -0.0918,  0.0016,  0.0120,  0.0365,  0.0042, -0.0106,  0.0050],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.in_proj_weight',\n",
       "              tensor([[ 0.0488, -0.1115, -0.0246,  ..., -0.0358, -0.2227,  0.0747],\n",
       "                      [-0.2452,  0.1517, -0.0856,  ...,  0.0814,  0.0825, -0.3072],\n",
       "                      [ 0.1135,  0.0006,  0.0984,  ...,  0.1188,  0.0078, -0.0894],\n",
       "                      ...,\n",
       "                      [ 0.0088,  0.1769,  0.1388,  ...,  0.0853, -0.2462, -0.0212],\n",
       "                      [-0.1051, -0.0240,  0.1521,  ...,  0.1335, -0.0853, -0.1226],\n",
       "                      [ 0.0028,  0.1433,  0.1654,  ..., -0.1406,  0.1010, -0.0821]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.in_proj_bias',\n",
       "              tensor([ 5.7941e-02, -1.3652e-02, -3.3256e-02, -4.0252e-02,  7.8844e-03,\n",
       "                      -3.7990e-03,  5.6426e-03,  3.8241e-02, -2.5984e-02,  9.8772e-02,\n",
       "                      -5.0112e-02,  4.5502e-02,  3.3300e-03, -6.6569e-02,  4.1834e-02,\n",
       "                       4.4098e-02,  8.2156e-03,  7.1663e-02, -2.2703e-02, -1.7542e-02,\n",
       "                      -1.7442e-02, -2.1639e-02, -1.7377e-02, -4.0567e-03, -1.0612e-01,\n",
       "                       4.1080e-02,  2.3033e-02, -2.3860e-02, -4.7868e-02,  4.6102e-02,\n",
       "                      -6.1604e-02, -2.1300e-02, -2.7767e-05,  1.8395e-04, -2.1742e-04,\n",
       "                       7.4896e-05, -1.1088e-04,  1.6940e-04, -2.9863e-04,  4.5314e-05,\n",
       "                      -2.3826e-04,  3.3249e-04, -1.6046e-05,  4.6238e-04,  8.4529e-05,\n",
       "                      -3.7732e-05, -1.5074e-04,  1.0992e-05,  5.3538e-05, -6.5188e-05,\n",
       "                       1.1304e-04,  3.6310e-05,  9.8507e-06, -1.5983e-05,  3.2806e-04,\n",
       "                       1.4645e-04, -1.3902e-04,  2.1011e-04, -1.2367e-05, -2.0412e-04,\n",
       "                      -1.0703e-05, -2.7744e-05, -4.1492e-04,  3.4666e-05,  2.0167e-02,\n",
       "                       1.9294e-02,  1.0746e-02,  1.8161e-02, -2.1538e-02, -3.6563e-02,\n",
       "                      -1.1729e-02,  1.5824e-02,  2.3498e-02,  7.5295e-02,  1.0953e-02,\n",
       "                      -1.5679e-02,  3.1759e-02, -6.5657e-02, -1.7860e-02, -3.2424e-04,\n",
       "                       4.8822e-02,  2.1925e-02, -3.4427e-02,  5.6341e-03, -8.9421e-03,\n",
       "                      -1.0214e-03,  9.3976e-03, -5.7532e-02,  2.3710e-02, -2.3136e-02,\n",
       "                      -6.7989e-03,  1.8121e-02,  9.6699e-03,  4.1473e-02, -1.3228e-02,\n",
       "                      -3.1809e-02], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.out_proj.weight',\n",
       "              tensor([[ 9.7375e-02, -3.8083e-02,  1.5720e-01,  ..., -8.2844e-02,\n",
       "                       -1.4692e-01, -1.7345e-02],\n",
       "                      [ 1.8782e-01,  7.5479e-03,  5.6468e-02,  ...,  8.3096e-02,\n",
       "                       -2.1559e-01, -5.9459e-02],\n",
       "                      [ 2.9704e-02, -1.3618e-01, -9.8012e-02,  ..., -4.3336e-02,\n",
       "                        7.1078e-02,  1.1997e-02],\n",
       "                      ...,\n",
       "                      [ 9.6225e-02, -5.2840e-02, -4.5249e-02,  ...,  1.1491e-01,\n",
       "                       -1.3701e-01,  5.0999e-02],\n",
       "                      [ 8.7491e-02, -7.4306e-03, -6.9883e-03,  ..., -1.6978e-02,\n",
       "                        1.1115e-04,  8.3357e-02],\n",
       "                      [ 4.3101e-02,  8.1062e-02,  5.1532e-02,  ...,  3.9650e-02,\n",
       "                       -6.8143e-02,  1.2807e-01]], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_cross_attn.out_proj.bias',\n",
       "              tensor([ 0.0098, -0.0566,  0.0046,  0.0040, -0.0452,  0.0590, -0.0154, -0.0439,\n",
       "                       0.0002,  0.0167,  0.0097, -0.0003, -0.0684,  0.0183, -0.0306,  0.0506,\n",
       "                       0.0153,  0.0807, -0.0367,  0.0091,  0.0052,  0.0293,  0.0288, -0.0091,\n",
       "                      -0.0028, -0.0803,  0.0066,  0.0082,  0.0250,  0.0045, -0.0088, -0.0097],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm2.weight',\n",
       "              tensor([0.8111, 0.8671, 0.7535, 0.7746, 0.8332, 0.8561, 0.8386, 0.9195, 0.8105,\n",
       "                      0.7925, 0.8517, 0.8660, 0.8287, 0.7109, 0.8336, 0.9016, 0.8272, 0.9370,\n",
       "                      0.8730, 0.8424, 0.8161, 0.8617, 0.8055, 0.8409, 0.8037, 0.9327, 0.8052,\n",
       "                      0.8557, 0.8699, 0.8638, 0.8770, 0.8170], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_norm2.bias',\n",
       "              tensor([ 1.5379e-02, -5.6710e-02,  1.0069e-03,  7.3185e-03, -1.5632e-05,\n",
       "                       2.2147e-02, -1.6725e-02, -3.0625e-02, -3.6631e-03,  1.6883e-02,\n",
       "                      -6.4247e-04, -4.6991e-03, -1.2006e-01,  2.1036e-02, -1.8666e-02,\n",
       "                       4.6454e-02,  1.2158e-02,  5.1187e-02, -2.8638e-02,  1.5525e-02,\n",
       "                       5.1970e-04,  3.5090e-02, -6.5143e-03, -4.6877e-03, -5.7174e-03,\n",
       "                      -5.6363e-02,  1.2710e-02,  1.0357e-02,  3.7263e-02,  5.5294e-03,\n",
       "                       8.6171e-04, -1.4512e-02], device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.0.weight',\n",
       "              tensor([[ 0.1942,  0.2160,  0.1148,  ...,  0.0137,  0.0289,  0.0358],\n",
       "                      [ 0.0188, -0.0980,  0.0354,  ..., -0.0228,  0.4109, -0.1035],\n",
       "                      [-0.0710,  0.1747,  0.1740,  ...,  0.0782, -0.0925,  0.1080],\n",
       "                      ...,\n",
       "                      [-0.0162, -0.0157,  0.1829,  ..., -0.0006,  0.2555, -0.0665],\n",
       "                      [ 0.0711,  0.0441,  0.0283,  ..., -0.0334,  0.0944,  0.0794],\n",
       "                      [-0.0986,  0.1661,  0.0513,  ..., -0.0824,  0.0121, -0.0574]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.0.bias',\n",
       "              tensor([-0.0240, -0.0292, -0.0263,  0.0306,  0.0498,  0.0252,  0.0610,  0.0037,\n",
       "                       0.0644, -0.1367, -0.0077, -0.1354, -0.0931,  0.0443,  0.1253, -0.0569,\n",
       "                      -0.1446, -0.0027,  0.1267, -0.1551, -0.1205, -0.0390, -0.0285, -0.0014,\n",
       "                       0.0334,  0.0069, -0.0385, -0.0859,  0.0188, -0.1648, -0.0221,  0.0062,\n",
       "                       0.0170, -0.0077, -0.0101, -0.0925, -0.1386,  0.0521, -0.1224,  0.0219,\n",
       "                      -0.0764, -0.1314, -0.1003,  0.0379,  0.0293,  0.1768, -0.0427, -0.2523,\n",
       "                      -0.1017,  0.1148, -0.1618, -0.0901, -0.0075,  0.0513,  0.0084,  0.0059,\n",
       "                      -0.1267, -0.1364, -0.0212,  0.0116, -0.0427, -0.1307,  0.0206,  0.0819],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.2.weight',\n",
       "              tensor([[-0.0442,  0.1170,  0.0550,  ..., -0.1747, -0.0362, -0.0230],\n",
       "                      [-0.0793,  0.0893, -0.1893,  ..., -0.0946, -0.0733,  0.0667],\n",
       "                      [-0.0721,  0.0736, -0.1248,  ..., -0.0706, -0.0309,  0.0725],\n",
       "                      ...,\n",
       "                      [-0.2553,  0.1058,  0.0040,  ..., -0.1037,  0.0523, -0.1094],\n",
       "                      [ 0.0513, -0.0059,  0.1422,  ...,  0.0536,  0.0377, -0.0824],\n",
       "                      [-0.1472,  0.0874, -0.1464,  ..., -0.1791, -0.0899, -0.0042]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.0.decoder_feedforward.2.bias',\n",
       "              tensor([ 0.1009, -0.0170, -0.0263,  0.0153,  0.0952, -0.0446,  0.0222,  0.0534,\n",
       "                       0.0219,  0.1093, -0.1124, -0.0366,  0.0827, -0.0580, -0.0814, -0.0536,\n",
       "                      -0.0058,  0.0522,  0.0957, -0.0217, -0.1060, -0.0175,  0.0440, -0.0032,\n",
       "                       0.0145,  0.0693,  0.0889, -0.0015, -0.0317, -0.0619, -0.0443, -0.0717],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1032, -0.0764, -0.0338,  ..., -0.3462, -0.0759,  0.0588],\n",
       "                      [-0.1803, -0.0366,  0.0587,  ..., -0.0335, -0.2702, -0.1835],\n",
       "                      [-0.1095, -0.0871, -0.1022,  ..., -0.0088, -0.1337, -0.0631],\n",
       "                      ...,\n",
       "                      [-0.1372,  0.1262, -0.2504,  ...,  0.1562, -0.0932, -0.0644],\n",
       "                      [-0.1021, -0.0507,  0.0533,  ...,  0.0390,  0.0706,  0.0569],\n",
       "                      [ 0.0489,  0.1828,  0.1174,  ..., -0.0605,  0.1025, -0.0393]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.in_proj_bias',\n",
       "              tensor([ 3.8762e-02, -6.9956e-03, -5.4446e-02, -3.9858e-02,  3.8683e-02,\n",
       "                      -5.5651e-02, -8.4083e-02,  5.8710e-02,  7.7136e-02, -1.3328e-02,\n",
       "                       2.3679e-02,  5.9608e-02, -3.0713e-03, -5.7874e-02,  4.9824e-02,\n",
       "                      -5.4228e-03, -1.7332e-03, -2.3426e-03, -5.1634e-02, -4.4909e-02,\n",
       "                      -1.3043e-02,  2.9508e-02, -5.2499e-02, -4.2734e-02, -9.0687e-02,\n",
       "                      -3.9678e-02,  8.9478e-02, -7.5696e-02, -1.8099e-02,  4.4351e-02,\n",
       "                       1.3596e-01,  5.0212e-02, -1.9062e-06, -2.2975e-04, -8.1902e-07,\n",
       "                      -2.5944e-04, -4.1780e-04,  1.0763e-05,  2.8408e-05, -5.9497e-05,\n",
       "                      -3.1989e-04,  3.8465e-05, -3.5404e-05,  9.7850e-05, -1.7220e-05,\n",
       "                      -1.6090e-04,  5.7025e-05, -1.0522e-04, -1.1697e-04,  5.0903e-05,\n",
       "                      -6.5813e-05, -1.8366e-04, -6.3908e-06, -2.7353e-04,  3.1709e-04,\n",
       "                      -4.3124e-04, -5.0788e-04, -6.3033e-04,  2.1326e-04,  1.8285e-04,\n",
       "                       4.2535e-05,  4.6109e-04,  4.3241e-06, -3.1890e-04, -5.3692e-02,\n",
       "                      -1.3465e-02,  3.0029e-02, -2.2864e-02,  2.2607e-02, -1.1045e-02,\n",
       "                      -5.0964e-04, -2.1506e-02,  2.5545e-02,  1.8509e-02, -3.4068e-02,\n",
       "                      -5.3875e-02, -3.9529e-02, -4.1114e-02, -1.1681e-02, -1.3114e-02,\n",
       "                       2.3758e-02,  1.7229e-02, -1.0586e-03,  6.1144e-03,  2.7897e-02,\n",
       "                       2.8820e-02, -2.2118e-02,  3.1276e-02, -5.1536e-02,  1.3690e-02,\n",
       "                       8.3695e-02,  9.8274e-03, -9.1298e-03,  4.5108e-02, -3.0639e-03,\n",
       "                       8.5842e-03], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.out_proj.weight',\n",
       "              tensor([[ 0.1123,  0.0039, -0.0957,  ...,  0.1090, -0.0574, -0.0324],\n",
       "                      [ 0.0261, -0.0276, -0.0563,  ..., -0.0088,  0.0220,  0.1528],\n",
       "                      [ 0.0785, -0.0553, -0.1602,  ...,  0.0971,  0.0810,  0.0147],\n",
       "                      ...,\n",
       "                      [ 0.1340,  0.1973, -0.1702,  ..., -0.0747,  0.0400,  0.0347],\n",
       "                      [-0.0787,  0.0696, -0.0815,  ...,  0.0431, -0.0057,  0.0659],\n",
       "                      [-0.1208, -0.0170, -0.1111,  ...,  0.1867,  0.0217,  0.1092]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_self_attn.out_proj.bias',\n",
       "              tensor([ 0.0134, -0.0124,  0.0205,  0.0145, -0.0978,  0.1054, -0.0212, -0.0010,\n",
       "                      -0.0135, -0.0081, -0.0192,  0.0381, -0.0047,  0.0087, -0.0217,  0.0120,\n",
       "                       0.0177,  0.1525, -0.0083,  0.0158, -0.0103,  0.0079, -0.0091, -0.0179,\n",
       "                       0.0008,  0.0026,  0.0203,  0.0144,  0.0097,  0.0394,  0.0222,  0.0168],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm1.weight',\n",
       "              tensor([0.7800, 0.9033, 0.7809, 0.7834, 0.8430, 0.8858, 0.8396, 0.8384, 0.7686,\n",
       "                      0.8101, 0.8003, 0.8596, 0.7840, 0.7595, 0.8295, 0.7286, 0.8336, 1.0169,\n",
       "                      0.8120, 0.8335, 0.8188, 0.8413, 0.8272, 0.8237, 0.7652, 0.8169, 0.7816,\n",
       "                      0.8403, 0.8017, 0.8566, 0.8088, 0.7776], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm1.bias',\n",
       "              tensor([ 0.0126, -0.0271,  0.0209,  0.0138, -0.0092,  0.0424, -0.0154,  0.0025,\n",
       "                      -0.0074, -0.0079, -0.0181,  0.0284, -0.0091,  0.0035, -0.0094,  0.0109,\n",
       "                       0.0076,  0.0877, -0.0006,  0.0174, -0.0073,  0.0199, -0.0336, -0.0112,\n",
       "                       0.0035,  0.0093,  0.0268,  0.0169,  0.0175,  0.0390,  0.0299,  0.0129],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.in_proj_weight',\n",
       "              tensor([[-0.1410, -0.0386, -0.0445,  ...,  0.1061, -0.0055, -0.1702],\n",
       "                      [ 0.0921,  0.1236,  0.0425,  ..., -0.0618, -0.0206,  0.0816],\n",
       "                      [ 0.0374, -0.0717, -0.0026,  ...,  0.0262, -0.1474,  0.1744],\n",
       "                      ...,\n",
       "                      [ 0.1345, -0.0406,  0.0038,  ...,  0.1949,  0.0069,  0.0856],\n",
       "                      [-0.2194, -0.1092, -0.0268,  ..., -0.1144, -0.1062, -0.0418],\n",
       "                      [-0.0124, -0.0453,  0.0381,  ..., -0.0430,  0.1170, -0.1531]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.in_proj_bias',\n",
       "              tensor([-4.2021e-02, -3.7537e-02, -2.3479e-02,  9.6580e-03, -3.6173e-02,\n",
       "                       2.7912e-02, -4.3817e-02,  8.5077e-02,  3.5880e-02, -1.6904e-02,\n",
       "                       8.9353e-02, -6.3359e-02,  1.0774e-01, -9.7786e-02, -6.2398e-02,\n",
       "                       8.2347e-03, -3.1909e-02, -6.0583e-03, -6.9724e-02,  1.5312e-02,\n",
       "                      -3.8167e-03, -1.5175e-02, -1.9111e-02,  5.8258e-03, -7.3892e-02,\n",
       "                      -3.7551e-02, -9.3588e-02,  2.3631e-02, -2.9928e-02, -1.2633e-01,\n",
       "                      -9.1331e-02, -2.0572e-02, -1.6951e-04,  2.5021e-05, -1.4494e-04,\n",
       "                       1.8690e-06, -2.4201e-04, -5.0336e-05,  1.6633e-04, -1.6632e-04,\n",
       "                       8.3561e-05, -6.9679e-05, -2.7179e-04, -3.7869e-05, -6.1157e-06,\n",
       "                      -2.3717e-06, -5.6099e-05,  1.4879e-04,  4.2233e-04,  1.0057e-04,\n",
       "                       2.0795e-05, -2.6262e-05, -9.8725e-05, -1.6735e-04, -1.8469e-05,\n",
       "                      -8.6025e-05, -6.0148e-04,  7.8636e-04,  8.7222e-04,  2.1077e-05,\n",
       "                       3.8157e-05,  1.3285e-03,  1.0204e-03, -2.4515e-04, -6.6413e-03,\n",
       "                       7.3426e-02,  1.7873e-02, -9.0974e-03, -1.5201e-02, -4.2252e-03,\n",
       "                       4.0120e-02,  1.5969e-02, -1.0349e-02,  2.1423e-02, -3.9850e-02,\n",
       "                       4.4517e-02,  3.6951e-03,  1.3340e-02, -1.8990e-02,  1.9958e-02,\n",
       "                      -2.0822e-02, -9.6458e-03, -1.2515e-02,  4.8718e-03,  2.0256e-03,\n",
       "                       4.3549e-02, -1.5992e-02,  2.9019e-03,  2.2977e-02, -2.6388e-02,\n",
       "                      -1.4305e-02, -2.4169e-02, -2.2922e-02, -2.0407e-03, -1.9860e-02,\n",
       "                      -4.6880e-02], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.out_proj.weight',\n",
       "              tensor([[ 0.1386,  0.0832, -0.1708,  ..., -0.0112, -0.1630, -0.1183],\n",
       "                      [ 0.0161,  0.1103, -0.1587,  ...,  0.0934,  0.0531, -0.0248],\n",
       "                      [-0.1018,  0.0878, -0.0738,  ...,  0.0311,  0.0715,  0.0842],\n",
       "                      ...,\n",
       "                      [ 0.0284,  0.1107, -0.0165,  ...,  0.1472,  0.0201, -0.1424],\n",
       "                      [-0.1368, -0.0495, -0.0949,  ..., -0.1282,  0.1487, -0.2646],\n",
       "                      [ 0.0938, -0.1324, -0.1712,  ..., -0.0039,  0.0089,  0.0773]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_cross_attn.out_proj.bias',\n",
       "              tensor([ 0.0163, -0.0025,  0.0235,  0.0159, -0.0026,  0.0568, -0.0160,  0.0092,\n",
       "                      -0.0066, -0.0128, -0.0220,  0.0379, -0.0041,  0.0076, -0.0113,  0.0062,\n",
       "                       0.0081,  0.0792, -0.0017,  0.0205, -0.0088,  0.0324, -0.0396, -0.0125,\n",
       "                       0.0297,  0.0046,  0.0044,  0.0090,  0.0120,  0.0172,  0.0219,  0.0098],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm2.weight',\n",
       "              tensor([0.7858, 0.7950, 0.7464, 0.8015, 0.7683, 0.7387, 0.8309, 0.7627, 0.7193,\n",
       "                      0.7701, 0.7809, 0.8459, 0.7525, 0.6484, 0.8083, 0.6943, 0.8158, 0.4945,\n",
       "                      0.7840, 0.8133, 0.7403, 0.8109, 0.7642, 0.8151, 0.6742, 0.7693, 0.7012,\n",
       "                      0.7744, 0.7952, 0.7533, 0.7923, 0.8054], device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_norm2.bias',\n",
       "              tensor([ 0.0202, -0.0341,  0.0284,  0.0215,  0.0757, -0.0792, -0.0069,  0.0250,\n",
       "                      -0.0003, -0.0127, -0.0232,  0.0377, -0.0010,  0.0083,  0.0029,  0.0057,\n",
       "                      -0.0089, -0.2191,  0.0110,  0.0299, -0.0051,  0.0442, -0.0852, -0.0052,\n",
       "                       0.0492,  0.0516,  0.0203,  0.0128,  0.0205,  0.0218,  0.0295,  0.0007],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.0.weight',\n",
       "              tensor([[ 0.1942,  0.2160,  0.1148,  ...,  0.0137,  0.0289,  0.0358],\n",
       "                      [ 0.0188, -0.0980,  0.0354,  ..., -0.0228,  0.4109, -0.1035],\n",
       "                      [-0.0710,  0.1747,  0.1740,  ...,  0.0782, -0.0925,  0.1080],\n",
       "                      ...,\n",
       "                      [-0.0162, -0.0157,  0.1829,  ..., -0.0006,  0.2555, -0.0665],\n",
       "                      [ 0.0711,  0.0441,  0.0283,  ..., -0.0334,  0.0944,  0.0794],\n",
       "                      [-0.0986,  0.1661,  0.0513,  ..., -0.0824,  0.0121, -0.0574]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.0.bias',\n",
       "              tensor([-0.0240, -0.0292, -0.0263,  0.0306,  0.0498,  0.0252,  0.0610,  0.0037,\n",
       "                       0.0644, -0.1367, -0.0077, -0.1354, -0.0931,  0.0443,  0.1253, -0.0569,\n",
       "                      -0.1446, -0.0027,  0.1267, -0.1551, -0.1205, -0.0390, -0.0285, -0.0014,\n",
       "                       0.0334,  0.0069, -0.0385, -0.0859,  0.0188, -0.1648, -0.0221,  0.0062,\n",
       "                       0.0170, -0.0077, -0.0101, -0.0925, -0.1386,  0.0521, -0.1224,  0.0219,\n",
       "                      -0.0764, -0.1314, -0.1003,  0.0379,  0.0293,  0.1768, -0.0427, -0.2523,\n",
       "                      -0.1017,  0.1148, -0.1618, -0.0901, -0.0075,  0.0513,  0.0084,  0.0059,\n",
       "                      -0.1267, -0.1364, -0.0212,  0.0116, -0.0427, -0.1307,  0.0206,  0.0819],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.2.weight',\n",
       "              tensor([[-0.0442,  0.1170,  0.0550,  ..., -0.1747, -0.0362, -0.0230],\n",
       "                      [-0.0793,  0.0893, -0.1893,  ..., -0.0946, -0.0733,  0.0667],\n",
       "                      [-0.0721,  0.0736, -0.1248,  ..., -0.0706, -0.0309,  0.0725],\n",
       "                      ...,\n",
       "                      [-0.2553,  0.1058,  0.0040,  ..., -0.1037,  0.0523, -0.1094],\n",
       "                      [ 0.0513, -0.0059,  0.1422,  ...,  0.0536,  0.0377, -0.0824],\n",
       "                      [-0.1472,  0.0874, -0.1464,  ..., -0.1791, -0.0899, -0.0042]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layers.1.decoder_feedforward.2.bias',\n",
       "              tensor([ 0.1009, -0.0170, -0.0263,  0.0153,  0.0952, -0.0446,  0.0222,  0.0534,\n",
       "                       0.0219,  0.1093, -0.1124, -0.0366,  0.0827, -0.0580, -0.0814, -0.0536,\n",
       "                      -0.0058,  0.0522,  0.0957, -0.0217, -0.1060, -0.0175,  0.0440, -0.0032,\n",
       "                       0.0145,  0.0693,  0.0889, -0.0015, -0.0317, -0.0619, -0.0443, -0.0717],\n",
       "                     device='cuda:0')),\n",
       "             ('output_feedforward.0.weight',\n",
       "              tensor([[ 0.0548,  0.0093,  0.0439,  0.0545, -0.0268,  0.0051, -0.0650,  0.0004,\n",
       "                       -0.0184,  0.0295, -0.0631, -0.0004,  0.0301, -0.0123, -0.0618,  0.0046,\n",
       "                        0.0428,  0.0113, -0.0318,  0.0563, -0.0281, -0.0197,  0.0114, -0.0934,\n",
       "                        0.0057,  0.0342, -0.0334, -0.0191, -0.0342,  0.0094, -0.0450,  0.0125]],\n",
       "                     device='cuda:0')),\n",
       "             ('output_feedforward.0.bias', tensor([0.0580], device='cuda:0'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(\n",
    "    optimizer=optimizer,\n",
    "    model=trans_encoder_decoder_tf_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    ot_steps=20,\n",
    "    report_interval=5,\n",
    "    n_epochs=200,\n",
    "    list_train_loss=train_loss,\n",
    "    list_val_loss=val_loss,\n",
    "    device=device,\n",
    "    eps=1e-8,\n",
    "    scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22fa6546-4ebd-44d5-8316-21438df4d6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x525 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from proj_mod import visualization\n",
    "\n",
    "train_loss_cut = train_loss[10:]\n",
    "val_loss_cut = val_loss[10:]\n",
    "\n",
    "vis_dict={(\"decoder\",\"current as ground target\"):{\"train_loss\": train_loss_cut,\"val_loss\": val_loss_cut}}\n",
    "visualization.training_plots(vis_dict, fig_width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe6253",
   "metadata": {},
   "source": [
    "#### The above model has already beaten all (native) rnn based model, I think adding more layers of encoder and decoder might improve it, let's try. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f09188",
   "metadata": {},
   "source": [
    "We will keep using the dataloader and components of the above model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a9ec2",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434510c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_encoder_decoder_tf_model=training.encoder_decoder_teacherforcing(\n",
    "    pos_emb_model=pos_embedder,\n",
    "    output_feedforward=output_ff,\n",
    "    encoder_dropout=0.2,\n",
    "    decoder_dropout=0.2,\n",
    "    encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "    decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "    n_diff=n_diff,\n",
    "    encoder_layer_num=4, #Changed\n",
    "    decoder_layer_num=4, #Changed\n",
    "    input_scaler=10000,\n",
    "    ts_emb_dim=ts_emb_dim,\n",
    "    encoder_num_heads=4,\n",
    "    decoder_num_heads=4,\n",
    "    encoder_keep_mag=True,\n",
    "    decoder_keep_mag=True,\n",
    "    return_sum=True\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be4025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(trans_encoder_decoder_tf_model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode=\"min\",factor=0.5,patience=5,min_lr=1e-7)\n",
    "\n",
    "# Loss tracking\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75305284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "encoder_decoder_teacherforcing                               --\n",
       "â”œâ”€frozen_diff_conv: 1-1                                      --\n",
       "â”‚    â””â”€Conv1d: 2-1                                           (2)\n",
       "â”œâ”€pos_emb_cross_attn: 1-2                                    --\n",
       "â”‚    â””â”€Linear: 2-2                                           128\n",
       "â”‚    â””â”€Embedding: 2-3                                        1,920\n",
       "â”‚    â””â”€MultiheadAttention: 2-4                               3,168\n",
       "â”‚    â”‚    â””â”€NonDynamicallyQuantizableLinear: 3-1             1,056\n",
       "â”‚    â””â”€LayerNorm: 2-5                                        64\n",
       "â”œâ”€ModuleList: 1-3                                            --\n",
       "â”‚    â””â”€ts_encoder: 2-6                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-2                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-3                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-4                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-5                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-7                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-6                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-7                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-8                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-9                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-8                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-10                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-11                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-12                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-13                                  64\n",
       "â”‚    â””â”€ts_encoder: 2-9                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-14                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-15                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-16                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-17                                  64\n",
       "â”œâ”€ModuleList: 1-4                                            --\n",
       "â”‚    â””â”€ts_decoder: 2-10                                      --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-18                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-19                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-20                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-21                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-22                                 4,192\n",
       "â”‚    â””â”€ts_decoder: 2-11                                      --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-23                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-24                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-25                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-26                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-27                                 4,192\n",
       "â”‚    â””â”€ts_decoder: 2-12                                      --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-28                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-29                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-30                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-31                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-32                                 4,192\n",
       "â”‚    â””â”€ts_decoder: 2-13                                      --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-33                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-34                                  64\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-35                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-36                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-37                                 4,192\n",
       "â”œâ”€Sequential: 1-5                                            --\n",
       "â”‚    â””â”€Linear: 2-14                                          33\n",
       "=====================================================================================\n",
       "Total params: 91,619\n",
       "Trainable params: 91,617\n",
       "Non-trainable params: 2\n",
       "====================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(trans_encoder_decoder_tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd74f5",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0d49a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new best validation loss at epoch  1  with validation loss of  tensor(0.2409, device='cuda:0') .\n",
      "At  44.422447204589844  epoch  1 has training loss  tensor(0.3097, device='cuda:0')  and validation loss  tensor(0.2409, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  2  with validation loss of  tensor(0.2336, device='cuda:0') .\n",
      "A new best validation loss at epoch  4  with validation loss of  tensor(0.2336, device='cuda:0') .\n",
      "At  229.51333856582642  epoch  5 has training loss  tensor(0.2512, device='cuda:0')  and validation loss  tensor(0.2386, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  6  with validation loss of  tensor(0.2315, device='cuda:0') .\n",
      "A new best validation loss at epoch  8  with validation loss of  tensor(0.2313, device='cuda:0') .\n",
      "A new best validation loss at epoch  10  with validation loss of  tensor(0.2309, device='cuda:0') .\n",
      "At  460.97391963005066  epoch  10 has training loss  tensor(0.2481, device='cuda:0')  and validation loss  tensor(0.2309, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  12  with validation loss of  tensor(0.2308, device='cuda:0') .\n",
      "At  691.7925190925598  epoch  15 has training loss  tensor(0.2466, device='cuda:0')  and validation loss  tensor(0.2373, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  17  with validation loss of  tensor(0.2297, device='cuda:0') .\n",
      "At  922.9469921588898  epoch  20 has training loss  tensor(0.2462, device='cuda:0')  and validation loss  tensor(0.2339, device='cuda:0') .\n",
      "\n",
      "At epoch 23, learning rate has been updated from 0.001 to 0.0005, reloading previous best model weights from epoch 17 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "A new best validation loss at epoch  25  with validation loss of  tensor(0.2297, device='cuda:0') .\n",
      "At  1154.9313354492188  epoch  25 has training loss  tensor(0.2435, device='cuda:0')  and validation loss  tensor(0.2297, device='cuda:0') .\n",
      "\n",
      "At epoch 29, learning rate has been updated from 0.0005 to 0.00025, reloading previous best model weights from epoch 25 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  1386.9541459083557  epoch  30 has training loss  tensor(0.2421, device='cuda:0')  and validation loss  tensor(0.2300, device='cuda:0') .\n",
      "\n",
      "At  1619.2814273834229  epoch  35 has training loss  tensor(0.2417, device='cuda:0')  and validation loss  tensor(0.2299, device='cuda:0') .\n",
      "\n",
      "At epoch 35, learning rate has been updated from 0.00025 to 0.000125, reloading previous best model weights from epoch 25 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  1851.3628125190735  epoch  40 has training loss  tensor(0.2411, device='cuda:0')  and validation loss  tensor(0.2301, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  41  with validation loss of  tensor(0.2296, device='cuda:0') .\n",
      "A new best validation loss at epoch  45  with validation loss of  tensor(0.2295, device='cuda:0') .\n",
      "At  2083.4867866039276  epoch  45 has training loss  tensor(0.2408, device='cuda:0')  and validation loss  tensor(0.2295, device='cuda:0') .\n",
      "\n",
      "At  2315.502196788788  epoch  50 has training loss  tensor(0.2408, device='cuda:0')  and validation loss  tensor(0.2299, device='cuda:0') .\n",
      "\n",
      "At epoch 51, learning rate has been updated from 0.000125 to 6.25e-05, reloading previous best model weights from epoch 45 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  2548.260322570801  epoch  55 has training loss  tensor(0.2402, device='cuda:0')  and validation loss  tensor(0.2302, device='cuda:0') .\n",
      "\n",
      "At epoch 57, learning rate has been updated from 6.25e-05 to 3.125e-05, reloading previous best model weights from epoch 45 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  2780.677125453949  epoch  60 has training loss  tensor(0.2400, device='cuda:0')  and validation loss  tensor(0.2296, device='cuda:0') .\n",
      "\n",
      "At epoch 63, learning rate has been updated from 3.125e-05 to 1.5625e-05, reloading previous best model weights from epoch 45 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  3013.402885913849  epoch  65 has training loss  tensor(0.2398, device='cuda:0')  and validation loss  tensor(0.2303, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 45  with validation loss:  tensor(0.2295, device='cuda:0') .\n",
      " The total number of epoch trained is  65 .\n",
      " Training completed in:  3013.402885913849 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en4de4_weight_dict=training.reg_training_loop_rmspe(\n",
    "    optimizer=optimizer,\n",
    "    model=trans_encoder_decoder_tf_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    ot_steps=20,\n",
    "    report_interval=5,\n",
    "    n_epochs=200,\n",
    "    list_train_loss=train_loss,\n",
    "    list_val_loss=val_loss,\n",
    "    device=device,\n",
    "    eps=1e-8,\n",
    "    scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd6e72",
   "metadata": {},
   "source": [
    "## The model with above as base and adjusted with learned embedding of stock id by multiplication "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1117dcad",
   "metadata": {},
   "source": [
    "Since we are sure that the native encoder with decoder transformer beat the native rnn based models, we will adjust them with the stock id and, hopefully, get improve result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f90cc",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e645f",
   "metadata": {},
   "source": [
    "#### Load in emb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5233136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>RV</th>\n",
       "      <th>row_id</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>93-5</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>93-11</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>93-16</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>93-31</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>93-62</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>32751</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>104-32751</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>32753</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>104-32753</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>32763</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>104-32763</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>32767</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>104-32767</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_id        RV     row_id stock_id\n",
       "0            5  0.002185       93-5       93\n",
       "1           11  0.001205      93-11       93\n",
       "2           16  0.001461      93-16       93\n",
       "3           31  0.001693      93-31       93\n",
       "4           62  0.001296      93-62       93\n",
       "...        ...       ...        ...      ...\n",
       "428927   32751  0.002337  104-32751      104\n",
       "428928   32753  0.001500  104-32753      104\n",
       "428929   32758  0.002272  104-32758      104\n",
       "428930   32763  0.001949  104-32763      104\n",
       "428931   32767  0.001347  104-32767      104\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RV_tab=pd.read_csv(\"../processed_data/RV_by_row_id.csv\")\n",
    "RV_tab[\"stock_id\"]=RV_tab[\"row_id\"].apply(lambda x: x.split(\"-\")[0])\n",
    "RV_tab[\"time_id\"]=RV_tab[\"row_id\"].apply(lambda x: x.split(\"-\")[1])\n",
    "RV_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d81dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>RV</th>\n",
       "      <th>row_id</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>emb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>93-5</td>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>93-11</td>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>93-16</td>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>93-31</td>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>93-62</td>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>32751</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>104-32751</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>32753</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>104-32753</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>32763</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>104-32763</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>32767</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>104-32767</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_id        RV     row_id stock_id  emb_id\n",
       "0            5  0.002185       93-5       93     105\n",
       "1           11  0.001205      93-11       93     105\n",
       "2           16  0.001461      93-16       93     105\n",
       "3           31  0.001693      93-31       93     105\n",
       "4           62  0.001296      93-62       93     105\n",
       "...        ...       ...        ...      ...     ...\n",
       "428927   32751  0.002337  104-32751      104       7\n",
       "428928   32753  0.001500  104-32753      104       7\n",
       "428929   32758  0.002272  104-32758      104       7\n",
       "428930   32763  0.001949  104-32763      104       7\n",
       "428931   32767  0.001347  104-32767      104       7\n",
       "\n",
       "[428932 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates tabular data, most specifically 'emb_id'\n",
    "unique_ids = sorted(RV_tab['stock_id'].unique())\n",
    "id_to_emb = {stock_id: i for i, stock_id in enumerate(unique_ids)}\n",
    "RV_tab['emb_id'] = RV_tab['stock_id'].map(id_to_emb)\n",
    "RV_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49e989",
   "metadata": {},
   "source": [
    "#### Recreate datasets and dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af9fe134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)\n",
    "\n",
    "ts_place, id_place=train_dataset.featureplace[\"sub_int_RV\"], train_dataset.featureplace[\"emb_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3a68afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "# Loss tracking\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e901666",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "addb7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_encoder_decoder_tf_model=training.encoder_decoder_teacherforcing(\n",
    "    pos_emb_model=pos_embedder,\n",
    "    output_feedforward=output_ff,\n",
    "    encoder_dropout=0.2,\n",
    "    decoder_dropout=0.2,\n",
    "    encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "    decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "    n_diff=n_diff,\n",
    "    encoder_layer_num=4, #Changed\n",
    "    decoder_layer_num=4, #Changed\n",
    "    input_scaler=10000,\n",
    "    ts_emb_dim=ts_emb_dim,\n",
    "    encoder_num_heads=4,\n",
    "    decoder_num_heads=4,\n",
    "    encoder_keep_mag=True,\n",
    "    decoder_keep_mag=True,\n",
    "    return_sum=True\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba7e428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "id_learned_embedding_adj_rnn_mtpl                                 --\n",
       "â”œâ”€Embedding: 1-1                                                  896\n",
       "â”œâ”€encoder_decoder_teacherforcing: 1-2                             --\n",
       "â”‚    â””â”€frozen_diff_conv: 2-1                                      --\n",
       "â”‚    â”‚    â””â”€Conv1d: 3-1                                           (2)\n",
       "â”‚    â””â”€pos_emb_cross_attn: 2-2                                    --\n",
       "â”‚    â”‚    â””â”€Linear: 3-2                                           128\n",
       "â”‚    â”‚    â””â”€Embedding: 3-3                                        1,920\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-4                               4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-5                                        64\n",
       "â”‚    â””â”€ModuleList: 2-3                                            --\n",
       "â”‚    â”‚    â””â”€ts_encoder: 3-6                                       8,544\n",
       "â”‚    â”‚    â””â”€ts_encoder: 3-7                                       8,544\n",
       "â”‚    â”‚    â””â”€ts_encoder: 3-8                                       8,544\n",
       "â”‚    â”‚    â””â”€ts_encoder: 3-9                                       8,544\n",
       "â”‚    â””â”€ModuleList: 2-4                                            --\n",
       "â”‚    â”‚    â””â”€ts_decoder: 3-10                                      12,768\n",
       "â”‚    â”‚    â””â”€ts_decoder: 3-11                                      12,768\n",
       "â”‚    â”‚    â””â”€ts_decoder: 3-12                                      12,768\n",
       "â”‚    â”‚    â””â”€ts_decoder: 3-13                                      12,768\n",
       "â”‚    â””â”€Sequential: 2-5                                            --\n",
       "â”‚    â”‚    â””â”€Linear: 3-14                                          33\n",
       "â”œâ”€Sequential: 1-3                                                 --\n",
       "â”‚    â””â”€Linear: 2-6                                                288\n",
       "â”‚    â””â”€Tanh: 2-7                                                  --\n",
       "â”‚    â””â”€Linear: 2-8                                                528\n",
       "â”‚    â””â”€Tanh: 2-9                                                  --\n",
       "â”‚    â””â”€Linear: 2-10                                               136\n",
       "â”‚    â””â”€Tanh: 2-11                                                 --\n",
       "â”‚    â””â”€Linear: 2-12                                               9\n",
       "==========================================================================================\n",
       "Total params: 93,476\n",
       "Trainable params: 93,474\n",
       "Non-trainable params: 2\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set base model \n",
    "base_trans_model=trans_encoder_decoder_tf_model\n",
    "\n",
    "#Create hidden layer for stock id learned embedding \n",
    "from collections import OrderedDict\n",
    "\n",
    "id_emb_dim=8\n",
    "\n",
    "id_hidden_dict=OrderedDict([(\"linear1\", nn.Linear(in_features=id_emb_dim, out_features=32),),\n",
    "                            (\"tanh1\", nn.Tanh()),\n",
    "                            (\"linear2\", nn.Linear(in_features=32, out_features=16)),\n",
    "                            (\"tanh2\", nn.Tanh()),\n",
    "                            (\"linear3\", nn.Linear(in_features=16, out_features=8)),\n",
    "                            (\"tanh3\", nn.Tanh()),\n",
    "                            (\"linear4\", nn.Linear(in_features=8,out_features=1))])\n",
    "\n",
    "id_hidden_layers=nn.Sequential(id_hidden_dict).to(device=device)\n",
    "\n",
    "#Create the adjustment by multiplication model (notice training.id_learned_embedding_adj_rnn_mtpl still works, we are just using the transformer model in place of the rnn based model). \n",
    "transformer_adjusted_model=training.id_learned_embedding_adj_rnn_mtpl(ts_place=ts_place,id_place=id_place, rnn_model=base_trans_model,id_hidden_model=id_hidden_layers,id_input_num=112,emb_dim=id_emb_dim).to(device)\n",
    "\n",
    "#Create the optimizer and the scheduler \n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(transformer_adjusted_model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode=\"min\",factor=0.5,patience=5,min_lr=1e-7)\n",
    "\n",
    "#Show summary\n",
    "from torchinfo import summary\n",
    "summary(transformer_adjusted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50365129",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13af2b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new best validation loss at epoch  1  with validation loss of  tensor(0.2349, device='cuda:0') .\n",
      "At  44.39342474937439  epoch  1 has training loss  tensor(0.2625, device='cuda:0')  and validation loss  tensor(0.2349, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  2  with validation loss of  tensor(0.2250, device='cuda:0') .\n",
      "A new best validation loss at epoch  4  with validation loss of  tensor(0.2238, device='cuda:0') .\n",
      "At  229.07297539710999  epoch  5 has training loss  tensor(0.2419, device='cuda:0')  and validation loss  tensor(0.2339, device='cuda:0') .\n",
      "\n",
      "At  459.20654702186584  epoch  10 has training loss  tensor(0.2416, device='cuda:0')  and validation loss  tensor(0.2243, device='cuda:0') .\n",
      "\n",
      "At epoch 10, learning rate has been updated from 0.001 to 0.0005, reloading previous best model weights from epoch 4 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "A new best validation loss at epoch  11  with validation loss of  tensor(0.2235, device='cuda:0') .\n",
      "At  695.7841424942017  epoch  15 has training loss  tensor(0.2393, device='cuda:0')  and validation loss  tensor(0.2236, device='cuda:0') .\n",
      "\n",
      "At epoch 17, learning rate has been updated from 0.0005 to 0.00025, reloading previous best model weights from epoch 11 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "A new best validation loss at epoch  20  with validation loss of  tensor(0.2234, device='cuda:0') .\n",
      "At  930.1401093006134  epoch  20 has training loss  tensor(0.2376, device='cuda:0')  and validation loss  tensor(0.2234, device='cuda:0') .\n",
      "\n",
      "At  1162.338841676712  epoch  25 has training loss  tensor(0.2369, device='cuda:0')  and validation loss  tensor(0.2282, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  26  with validation loss of  tensor(0.2229, device='cuda:0') .\n",
      "At  1394.2949941158295  epoch  30 has training loss  tensor(0.2367, device='cuda:0')  and validation loss  tensor(0.2231, device='cuda:0') .\n",
      "\n",
      "At epoch 32, learning rate has been updated from 0.00025 to 0.000125, reloading previous best model weights from epoch 26 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  1626.539787530899  epoch  35 has training loss  tensor(0.2359, device='cuda:0')  and validation loss  tensor(0.2243, device='cuda:0') .\n",
      "\n",
      "At epoch 38, learning rate has been updated from 0.000125 to 6.25e-05, reloading previous best model weights from epoch 26 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  1859.5915222167969  epoch  40 has training loss  tensor(0.2355, device='cuda:0')  and validation loss  tensor(0.2238, device='cuda:0') .\n",
      "\n",
      "At epoch 44, learning rate has been updated from 6.25e-05 to 3.125e-05, reloading previous best model weights from epoch 26 ...\n",
      "\n",
      "Previous best model weights reloaded, training continues ... \n",
      "At  2092.046860933304  epoch  45 has training loss  tensor(0.2352, device='cuda:0')  and validation loss  tensor(0.2234, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 26  with validation loss:  tensor(0.2229, device='cuda:0') .\n",
      " The total number of epoch trained is  46 .\n",
      " Training completed in:  2138.5334537029266 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer_adjusted_weight_dict=training.reg_training_loop_rmspe(\n",
    "    optimizer=optimizer,\n",
    "    model=transformer_adjusted_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    ot_steps=20,\n",
    "    report_interval=5,\n",
    "    n_epochs=200,\n",
    "    list_train_loss=train_loss,\n",
    "    list_val_loss=val_loss,\n",
    "    device=device,\n",
    "    eps=1e-8,\n",
    "    scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04d58926-45d4-4c34-bc53-8c639bc9c357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x525 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from proj_mod import visualization\n",
    "\n",
    "train_loss_cut = train_loss[10:]\n",
    "val_loss_cut = val_loss[10:]\n",
    "\n",
    "vis_dict={(\"decoder\",\"current as ground target\"):{\"train_loss\": train_loss_cut,\"val_loss\": val_loss_cut}}\n",
    "visualization.training_plots(vis_dict, fig_width=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
