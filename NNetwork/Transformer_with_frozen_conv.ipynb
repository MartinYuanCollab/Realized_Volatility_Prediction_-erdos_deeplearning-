{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34faab65",
   "metadata": {},
   "source": [
    "# In this notebook, we attempt in creating an attention based NN to predict the target on the timeseries alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1623fe",
   "metadata": {},
   "source": [
    "We first create an example, then we will generalize it and include it into training.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110fa3d",
   "metadata": {},
   "source": [
    "# Import and preparations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ec0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing, visualization\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);\n",
    "importlib.reload(visualization);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d36d44-b3cb-40e6-bbc6-a36c15396f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3.0\n"
     ]
    }
   ],
   "source": [
    "#Only run this cell if needed. AMD gpus might need this. Martin, I will remember this. \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")\n",
    "\n",
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9776742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a37b30",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ffb2f",
   "metadata": {},
   "source": [
    "### Load time id order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f295403",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24968e95",
   "metadata": {},
   "source": [
    "### Load timeseries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce645bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c789a9",
   "metadata": {},
   "source": [
    "### Load target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdfdf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")\n",
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)\n",
    "df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c116a84",
   "metadata": {},
   "source": [
    "### Create datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7a56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11addc1e",
   "metadata": {},
   "source": [
    "#### Below is just a reminder of how expand and embedding works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2e36e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed=nn.Embedding(num_embeddings=4,embedding_dim=2)\n",
    "out=embed(torch.tensor([[0,1,2,3],[0,1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7c02435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0153, -0.1476],\n",
       "         [ 0.1772,  0.3560],\n",
       "         [ 0.7680, -1.3964],\n",
       "         [-0.3542, -0.3484]],\n",
       "\n",
       "        [[-1.0153, -0.1476],\n",
       "         [ 0.1772,  0.3560],\n",
       "         [ 0.7680, -1.3964],\n",
       "         [-0.3542, -0.3484]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3782818a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4235233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,1,2,3]).expand(2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2c8f0",
   "metadata": {},
   "source": [
    "# Create example (encoder based only) transformer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e557279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ts_encoder_example(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_attn=nn.MultiheadAttention(embed_dim=32,num_heads=4,dropout=0.1,batch_first=True)\n",
    "        self.encoder_norm1=nn.LayerNorm(32)\n",
    "        self.encoder_feedforward=nn.Sequential(\n",
    "            nn.Linear(in_features=32,out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64,out_features=32)\n",
    "        )\n",
    "        self.encoder_norm2=nn.LayerNorm(32)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        attn,_=self.encoder_attn(x,x,x)\n",
    "        x=self.encoder_norm1(x+attn)\n",
    "        attn=self.encoder_feedforward(x)\n",
    "        return self.encoder_norm2(x+attn)\n",
    "        \n",
    "\n",
    "class ts_trans_example(nn.Module): \n",
    "    # An example where only encoder is used, the logic behind this is that we only want one value output, it might not be needed to add in decoders (which )\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #Frozen conv \n",
    "        self.frozen_conv=training.frozen_diff_conv(n_diff=2) \n",
    "        #Position embedding \n",
    "        self.pos_emb=nn.Embedding(num_embeddings=60,embedding_dim=32) # 60 is the length of our (default) timeseries. \n",
    "        self.ts_proj=nn.Linear(in_features=3,out_features=32)\n",
    "        self.pos_attn=nn.MultiheadAttention(embed_dim=32,batch_first=True,dropout=0.1,num_heads=4)\n",
    "        self.pos_norm=nn.LayerNorm(32) \n",
    "        #Encoder stacking \n",
    "        self.encoder_layers=nn.ModuleList([\n",
    "            ts_encoder_example()\n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        #Final feedforward \n",
    "        self.final_linear=nn.Linear(in_features=32,out_features=1)\n",
    "        \n",
    "        #scaler\n",
    "        self.input_scaler=10000\n",
    "        \n",
    "    def forward(self,x): \n",
    "        #Create and reshape the timeseries tensor \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1)\n",
    "        x=self.frozen_conv(x)\n",
    "        x=x.permute(0,2,1) \n",
    "        # print(x.shape)\n",
    "        x=self.ts_proj(x) # (N, 60, 32) 60 is the timeseries length \n",
    "        #Adding in position for positional impact \n",
    "        pos_id=torch.arange(60, device=x.device).expand(x.shape[0],60)\n",
    "        pos_emb=self.pos_emb(pos_id)\n",
    "        pos,_=self.pos_attn(x,pos_emb,pos_emb)\n",
    "        x=x+pos\n",
    "        x=self.pos_norm(x)\n",
    "        #Run though the encoder layers \n",
    "        for layer in self.encoder_layers: \n",
    "            x=layer(x)\n",
    "        x=self.final_linear(x)\n",
    "        return torch.sum(x,dim=1)/self.input_scaler # (N,1)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad642fb",
   "metadata": {},
   "source": [
    "### Create loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e5e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "# Loss tracking\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7c045",
   "metadata": {},
   "source": [
    "### Init model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f07f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_example_mod=ts_trans_example().to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(trans_example_mod.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c3d1939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ts_trans_example                                             --\n",
       "â”œâ”€frozen_diff_conv: 1-1                                      --\n",
       "â”‚    â””â”€Conv1d: 2-1                                           (2)\n",
       "â”œâ”€Embedding: 1-2                                             1,920\n",
       "â”œâ”€Linear: 1-3                                                128\n",
       "â”œâ”€MultiheadAttention: 1-4                                    3,168\n",
       "â”‚    â””â”€NonDynamicallyQuantizableLinear: 2-2                  1,056\n",
       "â”œâ”€LayerNorm: 1-5                                             64\n",
       "â”œâ”€ModuleList: 1-6                                            --\n",
       "â”‚    â””â”€ts_encoder_example: 2-3                               --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-1                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-2                                   64\n",
       "â”‚    â”‚    â””â”€Sequential: 3-3                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-4                                   64\n",
       "â”‚    â””â”€ts_encoder_example: 2-4                               --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-5                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-6                                   64\n",
       "â”‚    â”‚    â””â”€Sequential: 3-7                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-8                                   64\n",
       "â”‚    â””â”€ts_encoder_example: 2-5                               --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-9                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-10                                  64\n",
       "â”‚    â”‚    â””â”€Sequential: 3-11                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-12                                  64\n",
       "â”‚    â””â”€ts_encoder_example: 2-6                               --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-13                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-14                                  64\n",
       "â”‚    â”‚    â””â”€Sequential: 3-15                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-16                                  64\n",
       "â”œâ”€Linear: 1-7                                                33\n",
       "=====================================================================================\n",
       "Total params: 40,547\n",
       "Trainable params: 40,545\n",
       "Non-trainable params: 2\n",
       "====================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(trans_example_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579fea31",
   "metadata": {},
   "source": [
    "Oh fucks that is a shit ton of tranable parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1a9fd",
   "metadata": {},
   "source": [
    "### Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46acbe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new best validation loss at epoch  1  with validation loss of  tensor(0.6353, device='cuda:0')\n",
      "At  18.591132164001465  epoch  1 has training loss  tensor(1.0087, device='cuda:0')  and validation loss  tensor(0.6353, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  2  with validation loss of  tensor(0.4699, device='cuda:0')\n",
      "A new best validation loss at epoch  3  with validation loss of  tensor(0.4152, device='cuda:0')\n",
      "A new best validation loss at epoch  4  with validation loss of  tensor(0.3846, device='cuda:0')\n",
      "A new best validation loss at epoch  5  with validation loss of  tensor(0.3679, device='cuda:0')\n",
      "At  96.74080228805542  epoch  5 has training loss  tensor(0.3748, device='cuda:0')  and validation loss  tensor(0.3679, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  6  with validation loss of  tensor(0.3545, device='cuda:0')\n",
      "A new best validation loss at epoch  7  with validation loss of  tensor(0.3415, device='cuda:0')\n",
      "A new best validation loss at epoch  8  with validation loss of  tensor(0.3282, device='cuda:0')\n",
      "A new best validation loss at epoch  9  with validation loss of  tensor(0.3152, device='cuda:0')\n",
      "A new best validation loss at epoch  10  with validation loss of  tensor(0.3032, device='cuda:0')\n",
      "At  194.41964173316956  epoch  10 has training loss  tensor(0.3117, device='cuda:0')  and validation loss  tensor(0.3032, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  11  with validation loss of  tensor(0.2940, device='cuda:0')\n",
      "A new best validation loss at epoch  12  with validation loss of  tensor(0.2865, device='cuda:0')\n",
      "A new best validation loss at epoch  13  with validation loss of  tensor(0.2807, device='cuda:0')\n",
      "A new best validation loss at epoch  14  with validation loss of  tensor(0.2762, device='cuda:0')\n",
      "A new best validation loss at epoch  15  with validation loss of  tensor(0.2726, device='cuda:0')\n",
      "At  291.5296456813812  epoch  15 has training loss  tensor(0.2840, device='cuda:0')  and validation loss  tensor(0.2726, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  16  with validation loss of  tensor(0.2698, device='cuda:0')\n",
      "A new best validation loss at epoch  17  with validation loss of  tensor(0.2665, device='cuda:0')\n",
      "A new best validation loss at epoch  18  with validation loss of  tensor(0.2643, device='cuda:0')\n",
      "A new best validation loss at epoch  19  with validation loss of  tensor(0.2619, device='cuda:0')\n",
      "A new best validation loss at epoch  20  with validation loss of  tensor(0.2602, device='cuda:0')\n",
      "At  388.1509554386139  epoch  20 has training loss  tensor(0.2728, device='cuda:0')  and validation loss  tensor(0.2602, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  21  with validation loss of  tensor(0.2586, device='cuda:0')\n",
      "A new best validation loss at epoch  22  with validation loss of  tensor(0.2570, device='cuda:0')\n",
      "A new best validation loss at epoch  23  with validation loss of  tensor(0.2554, device='cuda:0')\n",
      "A new best validation loss at epoch  24  with validation loss of  tensor(0.2544, device='cuda:0')\n",
      "A new best validation loss at epoch  25  with validation loss of  tensor(0.2532, device='cuda:0')\n",
      "At  486.0998537540436  epoch  25 has training loss  tensor(0.2665, device='cuda:0')  and validation loss  tensor(0.2532, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  26  with validation loss of  tensor(0.2523, device='cuda:0')\n",
      "A new best validation loss at epoch  27  with validation loss of  tensor(0.2511, device='cuda:0')\n",
      "A new best validation loss at epoch  28  with validation loss of  tensor(0.2507, device='cuda:0')\n",
      "A new best validation loss at epoch  29  with validation loss of  tensor(0.2497, device='cuda:0')\n",
      "A new best validation loss at epoch  30  with validation loss of  tensor(0.2491, device='cuda:0')\n",
      "At  584.3392162322998  epoch  30 has training loss  tensor(0.2626, device='cuda:0')  and validation loss  tensor(0.2491, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  31  with validation loss of  tensor(0.2483, device='cuda:0')\n",
      "A new best validation loss at epoch  32  with validation loss of  tensor(0.2478, device='cuda:0')\n",
      "A new best validation loss at epoch  33  with validation loss of  tensor(0.2471, device='cuda:0')\n",
      "A new best validation loss at epoch  34  with validation loss of  tensor(0.2466, device='cuda:0')\n",
      "A new best validation loss at epoch  35  with validation loss of  tensor(0.2462, device='cuda:0')\n",
      "At  682.0649039745331  epoch  35 has training loss  tensor(0.2602, device='cuda:0')  and validation loss  tensor(0.2462, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  36  with validation loss of  tensor(0.2458, device='cuda:0')\n",
      "A new best validation loss at epoch  37  with validation loss of  tensor(0.2454, device='cuda:0')\n",
      "A new best validation loss at epoch  38  with validation loss of  tensor(0.2448, device='cuda:0')\n",
      "A new best validation loss at epoch  40  with validation loss of  tensor(0.2443, device='cuda:0')\n",
      "At  779.2691872119904  epoch  40 has training loss  tensor(0.2586, device='cuda:0')  and validation loss  tensor(0.2443, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  41  with validation loss of  tensor(0.2442, device='cuda:0')\n",
      "A new best validation loss at epoch  42  with validation loss of  tensor(0.2438, device='cuda:0')\n",
      "A new best validation loss at epoch  43  with validation loss of  tensor(0.2435, device='cuda:0')\n",
      "A new best validation loss at epoch  44  with validation loss of  tensor(0.2433, device='cuda:0')\n",
      "A new best validation loss at epoch  45  with validation loss of  tensor(0.2431, device='cuda:0')\n",
      "At  876.7823143005371  epoch  45 has training loss  tensor(0.2574, device='cuda:0')  and validation loss  tensor(0.2431, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  46  with validation loss of  tensor(0.2428, device='cuda:0')\n",
      "A new best validation loss at epoch  47  with validation loss of  tensor(0.2425, device='cuda:0')\n",
      "A new best validation loss at epoch  48  with validation loss of  tensor(0.2423, device='cuda:0')\n",
      "A new best validation loss at epoch  50  with validation loss of  tensor(0.2422, device='cuda:0')\n",
      "At  975.1328725814819  epoch  50 has training loss  tensor(0.2565, device='cuda:0')  and validation loss  tensor(0.2422, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  51  with validation loss of  tensor(0.2418, device='cuda:0')\n",
      "A new best validation loss at epoch  52  with validation loss of  tensor(0.2417, device='cuda:0')\n",
      "A new best validation loss at epoch  53  with validation loss of  tensor(0.2413, device='cuda:0')\n",
      "A new best validation loss at epoch  54  with validation loss of  tensor(0.2413, device='cuda:0')\n",
      "A new best validation loss at epoch  55  with validation loss of  tensor(0.2410, device='cuda:0')\n",
      "At  1073.3780179023743  epoch  55 has training loss  tensor(0.2559, device='cuda:0')  and validation loss  tensor(0.2410, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  58  with validation loss of  tensor(0.2406, device='cuda:0')\n",
      "A new best validation loss at epoch  59  with validation loss of  tensor(0.2404, device='cuda:0')\n",
      "A new best validation loss at epoch  60  with validation loss of  tensor(0.2403, device='cuda:0')\n",
      "At  1171.6819303035736  epoch  60 has training loss  tensor(0.2554, device='cuda:0')  and validation loss  tensor(0.2403, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  63  with validation loss of  tensor(0.2400, device='cuda:0')\n",
      "A new best validation loss at epoch  65  with validation loss of  tensor(0.2397, device='cuda:0')\n",
      "At  1268.9588356018066  epoch  65 has training loss  tensor(0.2549, device='cuda:0')  and validation loss  tensor(0.2397, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  66  with validation loss of  tensor(0.2396, device='cuda:0')\n",
      "A new best validation loss at epoch  68  with validation loss of  tensor(0.2395, device='cuda:0')\n",
      "A new best validation loss at epoch  69  with validation loss of  tensor(0.2394, device='cuda:0')\n",
      "At  1366.3887729644775  epoch  70 has training loss  tensor(0.2545, device='cuda:0')  and validation loss  tensor(0.2396, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  71  with validation loss of  tensor(0.2392, device='cuda:0')\n",
      "A new best validation loss at epoch  72  with validation loss of  tensor(0.2390, device='cuda:0')\n",
      "A new best validation loss at epoch  75  with validation loss of  tensor(0.2388, device='cuda:0')\n",
      "At  1464.214762210846  epoch  75 has training loss  tensor(0.2542, device='cuda:0')  and validation loss  tensor(0.2388, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  77  with validation loss of  tensor(0.2386, device='cuda:0')\n",
      "At  1562.1925790309906  epoch  80 has training loss  tensor(0.2539, device='cuda:0')  and validation loss  tensor(0.2389, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  81  with validation loss of  tensor(0.2385, device='cuda:0')\n",
      "A new best validation loss at epoch  83  with validation loss of  tensor(0.2383, device='cuda:0')\n",
      "At  1660.1552033424377  epoch  85 has training loss  tensor(0.2537, device='cuda:0')  and validation loss  tensor(0.2384, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  87  with validation loss of  tensor(0.2380, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreg_training_loop_rmspe\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrans_example_mod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mot_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreport_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlist_train_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlist_val_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:170\u001b[39m, in \u001b[36mreg_training_loop_rmspe\u001b[39m\u001b[34m(optimizer, model, train_loader, val_loader, device, ot_steps, recall_best, eps, list_train_loss, list_val_loss, report_interval, n_epochs, scaler, norm_train_target, train_target)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m#Update using optimizer according to loss of the batch\u001b[39;00m\n\u001b[32m    169\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mloss_step\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m optimizer.step()\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# #Create variables for training dataset target mean and std \u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# train_target_mean=None\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# train_target_std=None            \u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m#Update the sum of sqaure (without grad) \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/deep_learning_3_11_8/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/deep_learning_3_11_8/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/deep_learning_3_11_8/lib/python3.11/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=trans_example_mod,train_loader=train_loader,val_loader=test_loader,ot_steps=20,report_interval=5,n_epochs=200,list_train_loss=train_loss,list_val_loss=val_loss,device=device,eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49bef0a3-7443-4a5d-bd8d-0427f9ab5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_loss, \"train_loss_trans.pt\")\n",
    "# torch.save(val_loss, \"val_loss_trans.pt\")\n",
    "\n",
    "train_loss = torch.load(\"train_loss_trans.pt\")\n",
    "val_loss = torch.load(\"val_loss_trans.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f82814f-312e-4216-b0f0-8defde6f9f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1125 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from proj_mod import visualization\n",
    "\n",
    "train_loss_cut = train_loss[10:]\n",
    "val_loss_cut = val_loss[10:]\n",
    "\n",
    "vis_dict={(\"transformer\",\"model\"):{\"train_loss\": train_loss_cut,\"val_loss\": val_loss_cut}}\n",
    "visualization.training_plots(vis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebff02c",
   "metadata": {},
   "source": [
    "# A Transformer (encoder only) model that we can play with. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d378155",
   "metadata": {},
   "source": [
    "### Create loaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234f856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "# Loss tracking\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0276d",
   "metadata": {},
   "source": [
    "### * A model that \"do not keep magnitude signal\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd466b14",
   "metadata": {},
   "source": [
    "#### Create sub models and list needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c7a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedder=training.pos_emb_cross_attn(length=60,ts_dim=3,emb_dim=32,dropout=0.2,num_heads=4).to(device=device)\n",
    "ts_encoder_ff_layer=[\n",
    "    nn.Linear(in_features=32,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=32)\n",
    "]\n",
    "# ts_encoder=training.ts_encoder(ts_dim=32, dropout=0.2, num_heads=4, feedforward_layers=ts_encoder_ff_layer).to(device=device)\n",
    "output_ff=nn.Sequential(\n",
    "    nn.Linear(in_features=32,out_features=1)\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd732f40",
   "metadata": {},
   "source": [
    "#### Create the full model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b2afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_encoder_model=training.encoder_ensemble(pos_emb_model=pos_embedder,output_feedforward=output_ff,n_diff=2,encoder_layer_num=4,input_scaler=10000,encoder_dropout=0.2,encoder_feedforward_list=ts_encoder_ff_layer,encoder_num_heads=4,ts_emb_dim=32).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a258bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(trans_encoder_model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168f22d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "encoder_ensemble                                             --\n",
       "â”œâ”€frozen_diff_conv: 1-1                                      --\n",
       "â”‚    â””â”€Conv1d: 2-1                                           (2)\n",
       "â”œâ”€pos_emb_cross_attn: 1-2                                    --\n",
       "â”‚    â””â”€Linear: 2-2                                           128\n",
       "â”‚    â””â”€Embedding: 2-3                                        1,920\n",
       "â”‚    â””â”€MultiheadAttention: 2-4                               3,168\n",
       "â”‚    â”‚    â””â”€NonDynamicallyQuantizableLinear: 3-1             1,056\n",
       "â”‚    â””â”€LayerNorm: 2-5                                        64\n",
       "â”œâ”€ModuleList: 1-3                                            --\n",
       "â”‚    â””â”€ts_encoder: 2-6                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-2                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-3                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-4                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-5                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-7                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-6                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-7                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-8                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-9                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-8                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-10                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-11                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-12                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-13                                  64\n",
       "â”‚    â””â”€ts_encoder: 2-9                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-14                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-15                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-16                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-17                                  64\n",
       "â”œâ”€Sequential: 1-4                                            --\n",
       "â”‚    â””â”€Linear: 2-10                                          33\n",
       "=====================================================================================\n",
       "Total params: 40,547\n",
       "Trainable params: 40,545\n",
       "Non-trainable params: 2\n",
       "====================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(trans_encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef42732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new best validation loss at epoch  1  with validation loss of  tensor(0.5454, device='cuda:0')\n",
      "At  18.762203693389893  epoch  1 has training loss  tensor(0.6175, device='cuda:0')  and validation loss  tensor(0.5454, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  2  with validation loss of  tensor(0.4970, device='cuda:0')\n",
      "A new best validation loss at epoch  3  with validation loss of  tensor(0.4600, device='cuda:0')\n",
      "A new best validation loss at epoch  4  with validation loss of  tensor(0.4301, device='cuda:0')\n",
      "A new best validation loss at epoch  5  with validation loss of  tensor(0.4061, device='cuda:0')\n",
      "At  98.85857105255127  epoch  5 has training loss  tensor(0.4164, device='cuda:0')  and validation loss  tensor(0.4061, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  6  with validation loss of  tensor(0.3867, device='cuda:0')\n",
      "A new best validation loss at epoch  7  with validation loss of  tensor(0.3710, device='cuda:0')\n",
      "A new best validation loss at epoch  8  with validation loss of  tensor(0.3572, device='cuda:0')\n",
      "A new best validation loss at epoch  9  with validation loss of  tensor(0.3447, device='cuda:0')\n",
      "A new best validation loss at epoch  10  with validation loss of  tensor(0.3329, device='cuda:0')\n",
      "At  197.73416996002197  epoch  10 has training loss  tensor(0.3400, device='cuda:0')  and validation loss  tensor(0.3329, device='cuda:0') .\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreg_training_loop_rmspe\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrans_encoder_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mot_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreport_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlist_train_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlist_val_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:192\u001b[39m, in \u001b[36mreg_training_loop_rmspe\u001b[39m\u001b[34m(optimizer, model, train_loader, val_loader, device, ot_steps, recall_best, eps, list_train_loss, list_val_loss, report_interval, n_epochs, scaler, norm_train_target, train_target)\u001b[39m\n\u001b[32m    190\u001b[39m     epoch_train_loss=torch.sqrt(sum_of_sqaure_train/total_data_count)\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m#Calculate the validation loss of this epoch (without grad, citing another function)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m epoch_val_loss=\u001b[43mreg_validator_rmspe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnorm_train_target\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm_train_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_target_mean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_target_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_target_std\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_target_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m#Update the best validation loss and the epoch that it occurred     \u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((epoch==\u001b[32m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (epoch_val_loss<best_val_loss)): \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:87\u001b[39m, in \u001b[36mreg_validator_rmspe\u001b[39m\u001b[34m(model, val_loader, device, eps, scaler, norm_train_target, train_target_mean, train_target_std)\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m*\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaler\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m*\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaler\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/deep_learning_3_11_8/lib/python3.11/site-packages/torch/utils/data/dataloader.py:495\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/deep_learning_3_11_8/lib/python3.11/site-packages/torch/utils/data/dataloader.py:428\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    427\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/deep_learning_3_11_8/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1173\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1166\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1171\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1172\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1173\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1175\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/context.py:281\u001b[39m, in \u001b[36mForkProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_fork\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/popen_fork.py:75\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     73\u001b[39m         os._exit(code)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     os.close(child_w)\n\u001b[32m     76\u001b[39m     os.close(child_r)\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mself\u001b[39m.finalizer = util.Finalize(\u001b[38;5;28mself\u001b[39m, util.close_fds,\n\u001b[32m     78\u001b[39m                                    (parent_r, parent_w,))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=trans_encoder_model,train_loader=train_loader,val_loader=test_loader,ot_steps=20,report_interval=5,n_epochs=200,list_train_loss=train_loss,list_val_loss=val_loss,device=device,eps=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd7cf9",
   "metadata": {},
   "source": [
    "### * A model that \"keeps some magnitude signal\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbd0f6",
   "metadata": {},
   "source": [
    "#### Create sub models and list needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c3e7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedder=training.pos_emb_cross_attn(length=60,ts_dim=3,emb_dim=32,dropout=0.2,num_heads=4,keep_mag=True).to(device=device)\n",
    "ts_encoder_ff_layer=[\n",
    "    nn.Linear(in_features=32,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=32)\n",
    "]\n",
    "# ts_encoder=training.ts_encoder(ts_dim=32, dropout=0.2, num_heads=4, feedforward_layers=ts_encoder_ff_layer).to(device=device)\n",
    "output_ff=nn.Sequential(\n",
    "    nn.Linear(in_features=32,out_features=1)\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce6114",
   "metadata": {},
   "source": [
    "#### Create the full model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9de086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_encoder_model=training.encoder_ensemble(pos_emb_model=pos_embedder,output_feedforward=output_ff,n_diff=2,encoder_layer_num=4,input_scaler=10000,encoder_dropout=0.2,encoder_feedforward_list=ts_encoder_ff_layer,encoder_num_heads=4,ts_emb_dim=32,encoder_keep_mag=True).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66144e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(trans_encoder_model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e95f5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "encoder_ensemble                                             --\n",
       "â”œâ”€frozen_diff_conv: 1-1                                      --\n",
       "â”‚    â””â”€Conv1d: 2-1                                           (2)\n",
       "â”œâ”€pos_emb_cross_attn: 1-2                                    --\n",
       "â”‚    â””â”€Linear: 2-2                                           128\n",
       "â”‚    â””â”€Embedding: 2-3                                        1,920\n",
       "â”‚    â””â”€MultiheadAttention: 2-4                               3,168\n",
       "â”‚    â”‚    â””â”€NonDynamicallyQuantizableLinear: 3-1             1,056\n",
       "â”‚    â””â”€LayerNorm: 2-5                                        64\n",
       "â”œâ”€ModuleList: 1-3                                            --\n",
       "â”‚    â””â”€ts_encoder: 2-6                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-2                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-3                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-4                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-5                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-7                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-6                          4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-7                                   64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-8                                  4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-9                                   64\n",
       "â”‚    â””â”€ts_encoder: 2-8                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-10                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-11                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-12                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-13                                  64\n",
       "â”‚    â””â”€ts_encoder: 2-9                                       --\n",
       "â”‚    â”‚    â””â”€MultiheadAttention: 3-14                         4,224\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-15                                  64\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-16                                 4,192\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-17                                  64\n",
       "â”œâ”€Sequential: 1-4                                            --\n",
       "â”‚    â””â”€Linear: 2-10                                          33\n",
       "=====================================================================================\n",
       "Total params: 40,547\n",
       "Trainable params: 40,545\n",
       "Non-trainable params: 2\n",
       "====================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(trans_encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88521b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=trans_encoder_model,train_loader=train_loader,val_loader=test_loader,ot_steps=20,report_interval=5,n_epochs=200,list_train_loss=train_loss,list_val_loss=val_loss,device=device,eps=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90118845",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
