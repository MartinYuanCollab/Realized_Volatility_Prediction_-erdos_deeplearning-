{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34faab65",
   "metadata": {},
   "source": [
    "# In this notebook, we attempt in creating an attention based NN to predict the target on the timeseries alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1623fe",
   "metadata": {},
   "source": [
    "We first create an example, then we will generalize it and include it into training.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110fa3d",
   "metadata": {},
   "source": [
    "# Import and preparations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ec0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing, visualization\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);\n",
    "importlib.reload(visualization);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e0968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3.0\n"
     ]
    }
   ],
   "source": [
    "#Only run this cell if needed. AMD gpus might need this. \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")\n",
    "\n",
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9776742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a37b30",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ffb2f",
   "metadata": {},
   "source": [
    "### Load time id order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f295403",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24968e95",
   "metadata": {},
   "source": [
    "### Load timeseries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce645bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c789a9",
   "metadata": {},
   "source": [
    "### Load target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfdfdf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")\n",
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)\n",
    "df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c116a84",
   "metadata": {},
   "source": [
    "### Create datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7a56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e36e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed=nn.Embedding(num_embeddings=4,embedding_dim=2)\n",
    "out=embed(torch.tensor([[0,1,2,3],[0,1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7c02435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1853, -1.0454],\n",
       "         [-0.4169, -0.8853],\n",
       "         [ 2.0273, -0.7891],\n",
       "         [ 0.1283,  0.6013]],\n",
       "\n",
       "        [[ 0.1853, -1.0454],\n",
       "         [-0.4169, -0.8853],\n",
       "         [ 2.0273, -0.7891],\n",
       "         [ 0.1283,  0.6013]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3782818a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4235233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 3]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,1,2,3]).expand(2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2c8f0",
   "metadata": {},
   "source": [
    "# Create example transformer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e557279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ts_encoder_example(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_attn=nn.MultiheadAttention(embed_dim=32,num_heads=4,dropout=0.1,batch_first=True)\n",
    "        self.encoder_norm1=nn.LayerNorm(32)\n",
    "        self.encoder_feedforward=nn.Sequential(\n",
    "            nn.Linear(in_features=32,out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64,out_features=32)\n",
    "        )\n",
    "        self.encoder_norm2=nn.LayerNorm(32)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        attn,_=self.encoder_attn(x,x,x)\n",
    "        x=self.encoder_norm1(x+attn)\n",
    "        attn=self.encoder_feedforward(x)\n",
    "        return self.encoder_norm2(x+attn)\n",
    "        \n",
    "\n",
    "class ts_trans_example(nn.Module): \n",
    "    # An example where only encoder is used, the logic behind this is that we only want one value output, it might not be needed to add in decoders (which )\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #Frozen conv \n",
    "        self.frozen_conv=training.frozen_diff_conv(n_diff=2) \n",
    "        #Position embedding \n",
    "        self.pos_emb=nn.Embedding(num_embeddings=60,embedding_dim=32) # 60 is the length of our (default) timeseries. \n",
    "        self.ts_proj=nn.Linear(in_features=2,out_features=32)\n",
    "        self.pos_attn=nn.MultiheadAttention(embed_dim=32,batch_first=True,dropout=0.1,num_heads=4)\n",
    "        self.pos_norm=nn.LayerNorm(32) \n",
    "        #Encoder stacking \n",
    "        self.encoder_layers=nn.ModuleList([\n",
    "            ts_encoder_example()\n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        #Final feedforward \n",
    "        self.final_linear=nn.Linear(in_features=32,out_features=1)\n",
    "        \n",
    "        #scaler\n",
    "        self.input_scaler=10000\n",
    "        \n",
    "    def forward(self,x): \n",
    "        #Create and reshape the timeseries tensor \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1)\n",
    "        x=self.frozen_conv(x)\n",
    "        x=x.permute(0,2,1) \n",
    "        x=self.ts_proj(x) # (N, 60, 32) 60 is the timeseries length \n",
    "        #Adding in position for positional impact \n",
    "        pos_id=torch.arange(60, device=x.device).expand(x.shape[0],60)\n",
    "        x=x+self.pos_emb(pos_id)\n",
    "        #Run though the encoder layers \n",
    "        for layer in self.encoder_layers: \n",
    "            x=layer(x)\n",
    "        return torch.sum(x,dim=1) # (N,1)\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
