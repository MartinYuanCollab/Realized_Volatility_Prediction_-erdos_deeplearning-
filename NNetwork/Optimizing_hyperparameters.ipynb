{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fe5209-9b7a-4bf1-a9e3-1d03e8d5bfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing, visualization\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);\n",
    "importlib.reload(visualization);\n",
    "\n",
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1490c-2d0f-40b2-8533-024806d7777b",
   "metadata": {},
   "source": [
    "# Functions to optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539792c2-db63-4596-8515-c9f8ed060baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/.deeplearningcourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device, eps=0):\n",
    "    model.train()\n",
    "    loss_fn = training.RMSPELoss(eps=eps) \n",
    "    total_data_count=len(dataloader.dataset)\n",
    "    sum_of_squares=0.0\n",
    "    for batch in dataloader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            sum_of_squares+=torch.sum(torch.square((pred-y)/(y+eps)))\n",
    "    with torch.no_grad():\n",
    "        rmspe=torch.sqrt(sum_of_squares/total_data_count)\n",
    "    return rmspe.item()\n",
    "\n",
    "def validate(model, dataloader, device, eps=0):\n",
    "    model.eval()\n",
    "    sum_of_squares = 0.0\n",
    "    total_data_count=len(dataloader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            sum_of_squares += torch.sum(torch.square((pred - y) / (y + eps)))\n",
    "        rmspe = torch.sqrt(sum_of_squares / total_data_count)\n",
    "    return rmspe.item()\n",
    "\n",
    "def objective(trial, define_model): \n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "    model = define_model(trial).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode=\"min\",factor=0.5,patience=5,min_lr=1e-7)\n",
    "\n",
    "    eps = 1e-5\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    max_epochs = 10\n",
    "\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device, eps)\n",
    "        val_loss = validate(model, test_loader, device, eps)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        trial.report(val_loss, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        if val_loss < best_val_loss - 1e-4:  # added minimum delta threshold\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0          # reset counter on improvement\n",
    "        else:\n",
    "            patience_counter += 1         # increment if no improvement\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                break  \n",
    "    \n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdd271-35a6-478e-8868-dde35c850e12",
   "metadata": {},
   "source": [
    "# Usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7f282-bf8e-425e-875a-8ca3dbc6b94c",
   "metadata": {},
   "source": [
    "## Needed by both models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fa322-1387-49ad-870f-0b38cc6b91ee",
   "metadata": {},
   "source": [
    "### Data and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c76a40-8952-418f-ac99-22e0aeb506c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")\n",
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")\n",
    "\n",
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")\n",
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)\n",
    "\n",
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d19a2-70f1-4e62-a3f9-5ecf25b41ccf",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c2697f-5a42-4dc5-8787-67567bf6aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_emb_dim=32\n",
    "n_diff=2\n",
    "ts_dim=n_diff+1\n",
    "\n",
    "pos_embedder=training.pos_emb_cross_attn(length=60,ts_dim=ts_dim,emb_dim=ts_emb_dim,dropout=0.2,num_heads=4,keep_mag=True).to(device=device)\n",
    "\n",
    "ts_encoder_ff_layer=[\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "]\n",
    "\n",
    "ts_decoder_ff_layer=[\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64,out_features=ts_emb_dim)\n",
    "]\n",
    "\n",
    "output_ff=nn.Sequential(\n",
    "    nn.Linear(in_features=ts_emb_dim,out_features=1)\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714224a-d919-4377-aa82-eea120e6b925",
   "metadata": {},
   "source": [
    "## Encoder-decoder model without id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5072d-9dd3-46e7-82bb-2942055e38c5",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a26788f-db1a-4fbf-9501-679ffcc446ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:396: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:396: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b262fac-e3ef-427a-86ec-8930434321d0",
   "metadata": {},
   "source": [
    "### Model definition and optimization of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b25956-adf3-4ae7-84cf-12af5f60b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-05 11:36:25,325] A new study created in memory with name: no-name-bc692c32-10ab-4582-aa9a-cc86bb084c2a\n",
      "[I 2025-08-05 11:41:09,291] Trial 0 finished with value: 0.2353174388408661 and parameters: {'lr': 1.2367443736920106e-05, 'encoder_layer_num': 3, 'decoder_layer_num': 4, 'dropout': 0.0}. Best is trial 0 with value: 0.2353174388408661.\n",
      "[I 2025-08-05 11:44:15,487] Trial 1 finished with value: 0.23198272287845612 and parameters: {'lr': 0.004276910308898425, 'encoder_layer_num': 4, 'decoder_layer_num': 5, 'dropout': 0.4}. Best is trial 1 with value: 0.23198272287845612.\n",
      "[I 2025-08-05 11:48:36,632] Trial 2 finished with value: 0.22980597615242004 and parameters: {'lr': 6.770198040031588e-05, 'encoder_layer_num': 5, 'decoder_layer_num': 2, 'dropout': 0.2}. Best is trial 2 with value: 0.22980597615242004.\n",
      "[I 2025-08-05 11:50:42,074] Trial 3 finished with value: 0.2298048883676529 and parameters: {'lr': 0.00033859534123581957, 'encoder_layer_num': 2, 'decoder_layer_num': 2, 'dropout': 0.2}. Best is trial 3 with value: 0.2298048883676529.\n",
      "[I 2025-08-05 11:53:29,875] Trial 4 finished with value: 0.23031026124954224 and parameters: {'lr': 0.0014978978558606128, 'encoder_layer_num': 4, 'decoder_layer_num': 3, 'dropout': 0.30000000000000004}. Best is trial 3 with value: 0.2298048883676529.\n",
      "[I 2025-08-05 11:58:30,679] Trial 5 finished with value: 0.22986948490142822 and parameters: {'lr': 0.0003793585742511079, 'encoder_layer_num': 6, 'decoder_layer_num': 3, 'dropout': 0.5}. Best is trial 3 with value: 0.2298048883676529.\n",
      "[I 2025-08-05 12:04:48,948] Trial 6 finished with value: 0.2295791655778885 and parameters: {'lr': 0.0001280241509721382, 'encoder_layer_num': 6, 'decoder_layer_num': 6, 'dropout': 0.4}. Best is trial 6 with value: 0.2295791655778885.\n",
      "[I 2025-08-05 12:08:19,292] Trial 7 finished with value: 0.22948089241981506 and parameters: {'lr': 0.00016576207579184932, 'encoder_layer_num': 4, 'decoder_layer_num': 2, 'dropout': 0.2}. Best is trial 7 with value: 0.22948089241981506.\n",
      "[I 2025-08-05 12:11:54,260] Trial 8 finished with value: 0.2296263724565506 and parameters: {'lr': 0.00032103631579741146, 'encoder_layer_num': 5, 'decoder_layer_num': 3, 'dropout': 0.2}. Best is trial 7 with value: 0.22948089241981506.\n",
      "[I 2025-08-05 12:12:26,895] Trial 9 pruned. \n",
      "[I 2025-08-05 12:12:44,315] Trial 10 pruned. \n",
      "[I 2025-08-05 12:18:15,385] Trial 11 finished with value: 0.22981137037277222 and parameters: {'lr': 8.774067851762331e-05, 'encoder_layer_num': 6, 'decoder_layer_num': 6, 'dropout': 0.4}. Best is trial 7 with value: 0.22948089241981506.\n",
      "[I 2025-08-05 12:25:41,179] Trial 12 finished with value: 0.2290985882282257 and parameters: {'lr': 0.00011506673504111632, 'encoder_layer_num': 5, 'decoder_layer_num': 6, 'dropout': 0.4}. Best is trial 12 with value: 0.2290985882282257.\n",
      "[I 2025-08-05 12:27:41,212] Trial 13 pruned. \n",
      "[I 2025-08-05 12:28:15,737] Trial 14 pruned. \n",
      "[I 2025-08-05 12:30:29,466] Trial 15 pruned. \n",
      "[I 2025-08-05 12:30:59,386] Trial 16 pruned. \n",
      "[I 2025-08-05 12:31:39,382] Trial 17 pruned. \n",
      "[I 2025-08-05 12:33:03,299] Trial 18 pruned. \n",
      "[I 2025-08-05 12:33:44,830] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.2290985882282257\n",
      "    lr: 0.00011506673504111632\n",
      "    encoder_layer_num: 5\n",
      "    decoder_layer_num: 6\n",
      "    dropout: 0.4\n"
     ]
    }
   ],
   "source": [
    "def define_model_encdec(trial):\n",
    "    encoder_layers = trial.suggest_int(\"encoder_layer_num\", 2, 6)\n",
    "    decoder_layers = trial.suggest_int(\"decoder_layer_num\", 2, 6)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)   \n",
    "\n",
    "    return training.encoder_decoder_teacherforcing(\n",
    "        pos_emb_model=pos_embedder,\n",
    "        output_feedforward=output_ff,\n",
    "        encoder_dropout=dropout,\n",
    "        decoder_dropout=dropout,\n",
    "        encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "        decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "        n_diff=n_diff,\n",
    "        encoder_layer_num=encoder_layers,\n",
    "        decoder_layer_num=decoder_layers,\n",
    "        input_scaler=10000,\n",
    "        ts_emb_dim=ts_emb_dim,\n",
    "        encoder_num_heads=4,\n",
    "        decoder_num_heads=4,\n",
    "        encoder_keep_mag=True,\n",
    "        decoder_keep_mag=True,\n",
    "        return_sum=True\n",
    "    )\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lambda trial: objective(trial, define_model_encdec), n_trials=20)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb7b10-8567-4bd0-8d86-919d267e4a8f",
   "metadata": {},
   "source": [
    "## Encoder-decoder model with id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1503cc-5b51-40e1-923b-c3b8438d1062",
   "metadata": {},
   "source": [
    "### Data and dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc674a4-90e7-447c-94a1-c70c940232a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RV_tab=pd.read_csv(\"../processed_data/RV_by_row_id.csv\")\n",
    "RV_tab[\"stock_id\"]=RV_tab[\"row_id\"].apply(lambda x: x.split(\"-\")[0])\n",
    "RV_tab[\"time_id\"]=RV_tab[\"row_id\"].apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "# Creates tabular data, most specifically 'emb_id'\n",
    "unique_ids = sorted(RV_tab['stock_id'].unique())\n",
    "id_to_emb = {stock_id: i for i, stock_id in enumerate(unique_ids)}\n",
    "RV_tab['emb_id'] = RV_tab['stock_id'].map(id_to_emb)\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)\n",
    "\n",
    "ts_place, id_place=train_dataset.featureplace[\"sub_int_RV\"], train_dataset.featureplace[\"emb_id\"]\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2d058-add2-444a-aeab-7ceb2e27265d",
   "metadata": {},
   "source": [
    "### Model definition and optimization of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede89be4-7de1-46ef-b60a-9ecdfd0b44af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-05 12:40:02,324] A new study created in memory with name: no-name-74a62b8d-d5af-487c-921e-7c55b16d7c3a\n",
      "[I 2025-08-05 12:46:33,036] Trial 0 finished with value: 0.9882119297981262 and parameters: {'lr': 8.252949955028464e-05, 'encoder_layer_num': 5, 'decoder_layer_num': 4, 'dropout': 0.4}. Best is trial 0 with value: 0.9882119297981262.\n",
      "[I 2025-08-05 12:53:34,941] Trial 1 finished with value: 0.5642998218536377 and parameters: {'lr': 0.008981699831132471, 'encoder_layer_num': 6, 'decoder_layer_num': 4, 'dropout': 0.1}. Best is trial 1 with value: 0.5642998218536377.\n",
      "[I 2025-08-05 13:01:00,244] Trial 2 finished with value: 0.2239001989364624 and parameters: {'lr': 0.0012781920969917263, 'encoder_layer_num': 3, 'decoder_layer_num': 6, 'dropout': 0.1}. Best is trial 2 with value: 0.2239001989364624.\n",
      "[I 2025-08-05 13:06:08,455] Trial 3 finished with value: 0.2566831111907959 and parameters: {'lr': 8.432537854406163e-05, 'encoder_layer_num': 2, 'decoder_layer_num': 4, 'dropout': 0.1}. Best is trial 2 with value: 0.2239001989364624.\n",
      "[I 2025-08-05 13:09:10,244] Trial 4 finished with value: 0.22316862642765045 and parameters: {'lr': 0.004875305744648907, 'encoder_layer_num': 2, 'decoder_layer_num': 2, 'dropout': 0.30000000000000004}. Best is trial 4 with value: 0.22316862642765045.\n",
      "[I 2025-08-05 13:14:53,404] Trial 5 finished with value: 0.22382040321826935 and parameters: {'lr': 0.0001875165672495711, 'encoder_layer_num': 2, 'decoder_layer_num': 5, 'dropout': 0.0}. Best is trial 4 with value: 0.22316862642765045.\n",
      "[I 2025-08-05 13:19:38,453] Trial 6 finished with value: 0.2323303371667862 and parameters: {'lr': 4.2108711485005315e-05, 'encoder_layer_num': 4, 'decoder_layer_num': 3, 'dropout': 0.2}. Best is trial 4 with value: 0.22316862642765045.\n",
      "[I 2025-08-05 13:23:31,535] Trial 7 finished with value: 0.2282407432794571 and parameters: {'lr': 5.928921117247555e-05, 'encoder_layer_num': 3, 'decoder_layer_num': 2, 'dropout': 0.1}. Best is trial 4 with value: 0.22316862642765045.\n",
      "[I 2025-08-05 13:24:09,380] Trial 8 pruned. \n",
      "[I 2025-08-05 13:28:54,995] Trial 9 finished with value: 0.23037922382354736 and parameters: {'lr': 1.6667696848225213e-05, 'encoder_layer_num': 3, 'decoder_layer_num': 3, 'dropout': 0.4}. Best is trial 4 with value: 0.22316862642765045.\n",
      "[I 2025-08-05 13:31:06,707] Trial 10 finished with value: 0.22450891137123108 and parameters: {'lr': 0.0017922529544634072, 'encoder_layer_num': 4, 'decoder_layer_num': 2, 'dropout': 0.5}. Best is trial 4 with value: 0.22316862642765045.\n",
      "[I 2025-08-05 13:35:14,696] Trial 11 finished with value: 0.2228439897298813 and parameters: {'lr': 0.0006252038799750985, 'encoder_layer_num': 2, 'decoder_layer_num': 6, 'dropout': 0.30000000000000004}. Best is trial 11 with value: 0.2228439897298813.\n",
      "[I 2025-08-05 13:38:41,332] Trial 12 finished with value: 0.2238064557313919 and parameters: {'lr': 0.0011018179261685398, 'encoder_layer_num': 2, 'decoder_layer_num': 6, 'dropout': 0.30000000000000004}. Best is trial 11 with value: 0.2228439897298813.\n",
      "[I 2025-08-05 13:41:04,584] Trial 13 finished with value: 0.22634896636009216 and parameters: {'lr': 0.009371737277219532, 'encoder_layer_num': 2, 'decoder_layer_num': 5, 'dropout': 0.30000000000000004}. Best is trial 11 with value: 0.2228439897298813.\n",
      "[I 2025-08-05 13:41:42,996] Trial 14 pruned. \n",
      "[I 2025-08-05 13:42:09,121] Trial 15 pruned. \n",
      "[I 2025-08-05 13:42:49,520] Trial 16 pruned. \n",
      "[I 2025-08-05 13:43:24,017] Trial 17 pruned. \n",
      "[I 2025-08-05 13:44:02,304] Trial 18 pruned. \n",
      "[I 2025-08-05 13:44:42,771] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.2228439897298813\n",
      "    lr: 0.0006252038799750985\n",
      "    encoder_layer_num: 2\n",
      "    decoder_layer_num: 6\n",
      "    dropout: 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def define_model_encdec_id(trial):\n",
    "    encoder_layers = trial.suggest_int(\"encoder_layer_num\", 2, 6)\n",
    "    decoder_layers = trial.suggest_int(\"decoder_layer_num\", 2, 6)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)   \n",
    "\n",
    "    base_model =training.encoder_decoder_teacherforcing(\n",
    "        pos_emb_model=pos_embedder,\n",
    "        output_feedforward=output_ff,\n",
    "        encoder_dropout=dropout,\n",
    "        decoder_dropout=dropout,\n",
    "        encoder_feedforward_list=ts_encoder_ff_layer,\n",
    "        decoder_feedforward_list=ts_decoder_ff_layer,\n",
    "        n_diff=n_diff,\n",
    "        encoder_layer_num=encoder_layers,\n",
    "        decoder_layer_num=decoder_layers, \n",
    "        input_scaler=10000,\n",
    "        ts_emb_dim=ts_emb_dim,\n",
    "        encoder_num_heads=4,\n",
    "        decoder_num_heads=4,\n",
    "        encoder_keep_mag=True,\n",
    "        decoder_keep_mag=True,\n",
    "        return_sum=True\n",
    "    )\n",
    "\n",
    "    id_emb_dim=8\n",
    "    id_hidden_dict=OrderedDict([(\"linear1\", nn.Linear(in_features=id_emb_dim, out_features=32),),\n",
    "                                (\"tanh1\", nn.Tanh()),\n",
    "                                (\"linear2\", nn.Linear(in_features=32, out_features=16)),\n",
    "                                (\"tanh2\", nn.Tanh()),\n",
    "                                (\"linear3\", nn.Linear(in_features=16, out_features=8)),\n",
    "                                (\"tanh3\", nn.Tanh()),\n",
    "                                (\"linear4\", nn.Linear(in_features=8,out_features=1))])\n",
    "    id_hidden_layers=nn.Sequential(id_hidden_dict).to(device=device)\n",
    "\n",
    "    return training.id_learned_embedding_adj_rnn_mtpl(ts_place=ts_place,\n",
    "                                             id_place=id_place, \n",
    "                                             rnn_model=base_model,\n",
    "                                             id_hidden_model=id_hidden_layers,\n",
    "                                             id_input_num=112,\n",
    "                                             emb_dim=id_emb_dim)\n",
    "\n",
    "study2 = optuna.create_study(direction=\"minimize\")\n",
    "study2.optimize(lambda trial: objective(trial, define_model_encdec_id), n_trials=20)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study2.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebcbab-caec-4505-aaa5-90ec858e842a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
