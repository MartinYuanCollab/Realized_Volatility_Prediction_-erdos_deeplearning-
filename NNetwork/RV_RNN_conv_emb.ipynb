{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65a16d21-b77b-4260-85a5-3574e3e96fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72b5b704-b5b8-472e-8e23-5c28d500d5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026544e5-3fbb-4f96-849c-7173c74c2879",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "156cccfa-087a-4bd1-92cb-17e4fc0289bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17acd886-a658-4d34-872d-bd85d101c481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">sub_int_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-1000</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.818799e-07</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2.313288e-04</td>\n",
       "      <td>1.060893e-05</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10000</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>3.154886e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>4.375100e-04</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>2.552987e-03</td>\n",
       "      <td>5.364106e-04</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10017</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>6.771948e-05</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>3.104404e-03</td>\n",
       "      <td>1.224910e-03</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10030</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.586782e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>4.842470e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9972</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.503467e-04</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>9.916624e-05</td>\n",
       "      <td>1.809852e-04</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9973</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>9.650211e-04</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>1.862600e-03</td>\n",
       "      <td>7.668418e-04</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9976</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>7.203531e-04</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5.946683e-04</td>\n",
       "      <td>1.509652e-04</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9988</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.957402e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.440137e-04</td>\n",
       "      <td>3.200939e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9993</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.798617e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>2.728767e-04</td>\n",
       "      <td>2.108380e-04</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sub_int_RV                                                        \\\n",
       "sub_int_num         1         2         3         4         5             6    \n",
       "row_id                                                                         \n",
       "0-1000        0.000341  0.000000  0.000023  0.000000  0.000170  3.818799e-07   \n",
       "0-10000       0.000290  0.000191  0.000087  0.000193  0.000241  3.154886e-04   \n",
       "0-10005       0.000000  0.000000  0.001554  0.002177  0.002303  4.375100e-04   \n",
       "0-10017       0.000142  0.000142  0.001464  0.001086  0.000068  6.771948e-05   \n",
       "0-10030       0.000327  0.000058  0.000293  0.000842  0.000120  2.586782e-04   \n",
       "...                ...       ...       ...       ...       ...           ...   \n",
       "99-9972       0.000197  0.000181  0.000171  0.000172  0.000369  2.503467e-04   \n",
       "99-9973       0.000821  0.000346  0.000691  0.001591  0.000863  9.650211e-04   \n",
       "99-9976       0.000569  0.001101  0.001002  0.000430  0.000797  7.203531e-04   \n",
       "99-9988       0.000040  0.000069  0.000123  0.000056  0.000016  1.957402e-04   \n",
       "99-9993       0.000249  0.000179  0.000155  0.000025  0.000325  1.798617e-04   \n",
       "\n",
       "                                                     ...                      \\\n",
       "sub_int_num        7         8         9         10  ...        51        52   \n",
       "row_id                                               ...                       \n",
       "0-1000       0.000089  0.000552  0.000012  0.000000  ...  0.000265  0.000000   \n",
       "0-10000      0.000000  0.000247  0.000265  0.000000  ...  0.000202  0.000375   \n",
       "0-10005      0.000617  0.001199  0.002306  0.001215  ...  0.000000  0.000486   \n",
       "0-10017      0.000899  0.000064  0.000593  0.000451  ...  0.000029  0.000000   \n",
       "0-10030      0.000221  0.000436  0.000099  0.000008  ...  0.000410  0.000437   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "99-9972      0.000349  0.000356  0.000390  0.000050  ...  0.000075  0.000185   \n",
       "99-9973      0.000504  0.001925  0.000641  0.000382  ...  0.001081  0.001095   \n",
       "99-9976      0.000586  0.000538  0.000570  0.000781  ...  0.000508  0.000406   \n",
       "99-9988      0.000071  0.000095  0.000063  0.000030  ...  0.000034  0.000176   \n",
       "99-9993      0.000080  0.000125  0.000126  0.000205  ...  0.000099  0.000370   \n",
       "\n",
       "                                                                   \\\n",
       "sub_int_num        53        54        55        56            57   \n",
       "row_id                                                              \n",
       "0-1000       0.000214  0.000003  0.000000  0.000118  2.313288e-04   \n",
       "0-10000      0.000616  0.000564  0.000000  0.000023  3.777703e-08   \n",
       "0-10005      0.000050  0.001761  0.001617  0.001801  2.552987e-03   \n",
       "0-10017      0.001293  0.002092  0.000994  0.000848  3.104404e-03   \n",
       "0-10030      0.000004  0.000215  0.000457  0.000183  4.842470e-04   \n",
       "...               ...       ...       ...       ...           ...   \n",
       "99-9972      0.000314  0.000318  0.000115  0.000143  9.916624e-05   \n",
       "99-9973      0.000425  0.000789  0.001295  0.000596  1.862600e-03   \n",
       "99-9976      0.000662  0.000338  0.000710  0.000179  5.946683e-04   \n",
       "99-9988      0.000140  0.000129  0.000175  0.000019  1.440137e-04   \n",
       "99-9993      0.000929  0.000328  0.000251  0.000204  2.728767e-04   \n",
       "\n",
       "                                               \n",
       "sub_int_num            58        59        60  \n",
       "row_id                                         \n",
       "0-1000       1.060893e-05  0.000111  0.000288  \n",
       "0-10000      3.777703e-08  0.000020  0.000310  \n",
       "0-10005      5.364106e-04  0.000872  0.000000  \n",
       "0-10017      1.224910e-03  0.001316  0.003287  \n",
       "0-10030      0.000000e+00  0.000756  0.000005  \n",
       "...                   ...       ...       ...  \n",
       "99-9972      1.809852e-04  0.000334  0.000089  \n",
       "99-9973      7.668418e-04  0.001035  0.002115  \n",
       "99-9976      1.509652e-04  0.000388  0.000403  \n",
       "99-9988      3.200939e-05  0.000041  0.000007  \n",
       "99-9993      2.108380e-04  0.000126  0.000353  \n",
       "\n",
       "[428932 rows x 60 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")\n",
    "df_RV_ts.pivot(index=\"row_id\",columns=[\"sub_int_num\"],values=[\"sub_int_RV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5dc0776-c9ab-495c-bc06-4b2feadeb2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>RV</th>\n",
       "      <th>row_id</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>93-5</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>93-11</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>93-16</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>93-31</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>93-62</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>32751</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>104-32751</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>32753</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>104-32753</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>32763</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>104-32763</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>32767</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>104-32767</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_id        RV     row_id  stock_id\n",
       "0             5  0.002185       93-5        93\n",
       "1            11  0.001205      93-11        93\n",
       "2            16  0.001461      93-16        93\n",
       "3            31  0.001693      93-31        93\n",
       "4            62  0.001296      93-62        93\n",
       "...         ...       ...        ...       ...\n",
       "428927    32751  0.002337  104-32751       104\n",
       "428928    32753  0.001500  104-32753       104\n",
       "428929    32758  0.002272  104-32758       104\n",
       "428930    32763  0.001949  104-32763       104\n",
       "428931    32767  0.001347  104-32767       104\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RV_tab=pd.read_csv(\"../processed_data/RV_by_row_id.csv\")\n",
    "RV_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dfbf1d50-d30d-4610-b0dc-c6eb088dea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>RV</th>\n",
       "      <th>row_id</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>emb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>93-5</td>\n",
       "      <td>93</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>93-11</td>\n",
       "      <td>93</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>93-16</td>\n",
       "      <td>93</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>93-31</td>\n",
       "      <td>93</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>93-62</td>\n",
       "      <td>93</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>32751</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>104-32751</td>\n",
       "      <td>104</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>32753</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>104-32753</td>\n",
       "      <td>104</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>104</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>32763</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>104-32763</td>\n",
       "      <td>104</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>32767</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>104-32767</td>\n",
       "      <td>104</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_id        RV     row_id  stock_id  emb_id\n",
       "0             5  0.002185       93-5        93      81\n",
       "1            11  0.001205      93-11        93      81\n",
       "2            16  0.001461      93-16        93      81\n",
       "3            31  0.001693      93-31        93      81\n",
       "4            62  0.001296      93-62        93      81\n",
       "...         ...       ...        ...       ...     ...\n",
       "428927    32751  0.002337  104-32751       104      92\n",
       "428928    32753  0.001500  104-32753       104      92\n",
       "428929    32758  0.002272  104-32758       104      92\n",
       "428930    32763  0.001949  104-32763       104      92\n",
       "428931    32767  0.001347  104-32767       104      92\n",
       "\n",
       "[428932 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates tabular data, most specifically 'emb_id'\n",
    "unique_ids = sorted(RV_tab['stock_id'].unique())\n",
    "id_to_emb = {stock_id: i for i, stock_id in enumerate(unique_ids)}\n",
    "RV_tab['emb_id'] = RV_tab['stock_id'].map(id_to_emb)\n",
    "RV_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "433a2915-86ad-446e-9f78-297772c3b159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")\n",
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)\n",
    "df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d07d4-c09c-427f-a9b1-961f7b9e3a3f",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "738421e2-8fa4-49bc-8d85-0ecfadd7399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],tab_features=[\"emb_id\"],df_ts_feat=df_RV_ts,df_tab_feat=RV_tab,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "64c3c915-d7c5-4dd7-a3a0-00fdc0792a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.6594e-04, 1.5794e-04, 2.6052e-04, 2.0006e-04, 4.6036e-04, 4.1584e-04,\n",
       "         9.8932e-04, 4.7264e-04, 2.1441e-04, 2.9363e-05, 2.4447e-04, 2.9892e-04,\n",
       "         7.5965e-04, 6.9540e-04, 6.2064e-05, 9.8745e-04, 1.1972e-03, 5.2220e-04,\n",
       "         1.2480e-04, 3.2021e-04, 2.0767e-04, 2.9159e-04, 1.3637e-04, 5.0568e-04,\n",
       "         7.6126e-04, 5.4608e-05, 5.1065e-04, 5.1155e-04, 1.2982e-04, 1.5398e-04,\n",
       "         6.1349e-04, 8.6339e-04, 4.7770e-04, 6.8327e-04, 5.8174e-04, 1.9467e-05,\n",
       "         2.8003e-04, 3.1872e-04, 6.9253e-04, 8.4858e-05, 5.5608e-04, 1.2923e-03,\n",
       "         7.3301e-04, 3.3100e-04, 3.8636e-04, 1.3472e-04, 4.8604e-04, 2.2667e-04,\n",
       "         5.7036e-04, 2.3896e-04, 6.0563e-04, 2.2564e-04, 4.4306e-04, 1.6629e-04,\n",
       "         2.7551e-04, 3.5369e-04, 3.3014e-04, 4.8192e-04, 5.2923e-04, 3.0226e-04,\n",
       "         9.0000e+01]),\n",
       " tensor([0.0053]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2458e91-f6b4-44d3-a38d-333d9e443748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'102-4084'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.get_row_id(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d0d8531-ad83-4358-9804-8cc3a22eeee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The assigned 'emb_id' looks good\n",
    "id_to_emb.get(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa80b7bd-eaec-49cb-8946-0415ead8b3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345167</th>\n",
       "      <td>102</td>\n",
       "      <td>4084</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>102-4084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target    row_id\n",
       "345167       102     4084  0.005318  102-4084"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target looks good too\n",
    "df_target[df_target[\"row_id\"]==\"102-4084\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd00a95a-0573-4a1a-aa1e-b1f5f1124798",
   "metadata": {},
   "source": [
    "## A little bit of Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70b6eaea-fdeb-4fc9-99b6-6773adac8fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 2,  4,  6,  8, 10, 12, 14, 16],\n",
       "        [ 3,  6,  9, 12, 15, 18, 21, 24],\n",
       "        [ 4,  8, 12, 16, 20, 24, 28, 32],\n",
       "        [ 5, 10, 15, 20, 25, 30, 35, 40],\n",
       "        [ 6, 12, 18, 24, 30, 36, 42, 48],\n",
       "        [ 7, 14, 21, 28, 35, 42, 49, 56],\n",
       "        [ 8, 16, 24, 32, 40, 48, 56, 64],\n",
       "        [ 9, 18, 27, 36, 45, 54, 63, 72],\n",
       "        [10, 20, 30, 40, 50, 60, 70, 80]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor is unrelated to anything. This part is just to illustrate how Pytorch works\n",
    "row_indices = torch.arange(1,11).unsqueeze(1)\n",
    "column_indices = torch.arange(1,9).unsqueeze(0)\n",
    "ref_tensor = row_indices*column_indices\n",
    "ref_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e2f36b1-f76f-495c-b739-88fd244a0dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  ...,  6,  7,  8],\n",
       "         [ 1,  2,  3,  ...,  6,  7,  8],\n",
       "         [ 1,  2,  3,  ...,  6,  7,  8],\n",
       "         ...,\n",
       "         [ 1,  2,  3,  ...,  6,  7,  8],\n",
       "         [ 1,  2,  3,  ...,  6,  7,  8],\n",
       "         [ 1,  2,  3,  ...,  6,  7,  8]],\n",
       "\n",
       "        [[ 2,  4,  6,  ..., 12, 14, 16],\n",
       "         [ 2,  4,  6,  ..., 12, 14, 16],\n",
       "         [ 2,  4,  6,  ..., 12, 14, 16],\n",
       "         ...,\n",
       "         [ 2,  4,  6,  ..., 12, 14, 16],\n",
       "         [ 2,  4,  6,  ..., 12, 14, 16],\n",
       "         [ 2,  4,  6,  ..., 12, 14, 16]],\n",
       "\n",
       "        [[ 3,  6,  9,  ..., 18, 21, 24],\n",
       "         [ 3,  6,  9,  ..., 18, 21, 24],\n",
       "         [ 3,  6,  9,  ..., 18, 21, 24],\n",
       "         ...,\n",
       "         [ 3,  6,  9,  ..., 18, 21, 24],\n",
       "         [ 3,  6,  9,  ..., 18, 21, 24],\n",
       "         [ 3,  6,  9,  ..., 18, 21, 24]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 8, 16, 24,  ..., 48, 56, 64],\n",
       "         [ 8, 16, 24,  ..., 48, 56, 64],\n",
       "         [ 8, 16, 24,  ..., 48, 56, 64],\n",
       "         ...,\n",
       "         [ 8, 16, 24,  ..., 48, 56, 64],\n",
       "         [ 8, 16, 24,  ..., 48, 56, 64],\n",
       "         [ 8, 16, 24,  ..., 48, 56, 64]],\n",
       "\n",
       "        [[ 9, 18, 27,  ..., 54, 63, 72],\n",
       "         [ 9, 18, 27,  ..., 54, 63, 72],\n",
       "         [ 9, 18, 27,  ..., 54, 63, 72],\n",
       "         ...,\n",
       "         [ 9, 18, 27,  ..., 54, 63, 72],\n",
       "         [ 9, 18, 27,  ..., 54, 63, 72],\n",
       "         [ 9, 18, 27,  ..., 54, 63, 72]],\n",
       "\n",
       "        [[10, 20, 30,  ..., 60, 70, 80],\n",
       "         [10, 20, 30,  ..., 60, 70, 80],\n",
       "         [10, 20, 30,  ..., 60, 70, 80],\n",
       "         ...,\n",
       "         [10, 20, 30,  ..., 60, 70, 80],\n",
       "         [10, 20, 30,  ..., 60, 70, 80],\n",
       "         [10, 20, 30,  ..., 60, 70, 80]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_tensor.unsqueeze(1).expand(-1,20,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8780299-d0fa-4138-9459-daa59d9e35ae",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d4dfde6b-7087-43b2-b911-a1cc7c45db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: The splitting of x, as of now, only works for this particular dataset, doing the splitting using the capabilites of RV_Dataset remains to be done.\n",
    "# Maybe the dataset should have an internal variable that tells us how many differet stocks there are in order to pass that to this model directly....?\n",
    "# Is there a way to reuse RV_RNN_conv in RV_RNN_conv to avoid code duplication?\n",
    "\n",
    "\n",
    "class RV_RNN_conv_emb(nn.Module):        \n",
    "    #Created 07/02/25 see RNN_with_frozen_conv.ipynb for documentation. \n",
    "    #Modified 07/08/25 Added LSTM and GRU options\n",
    "    #NEW n_stocks, stock_emb_dim\n",
    "    def __init__(self,n_diff,rnn_num_layer,rnn_drop_out,rnn_type=\"rnn\",rnn_act=\"tanh\",proj_dim=32,rnn_hidden_size=32,input_scaler=10000, n_stocks=112, stock_emb_dim=8):\n",
    "        \"\"\"\n",
    "        :param n_diff: Decides how many derivative features is wanted in the time series. \n",
    "        :param rnn_num_layer: num_layer parameter for rnn. \n",
    "        :param rnn_drop_out: dropout parameter for rnn. \n",
    "        :param rnn_act: Defaulted to \"tanh\". Nonlinearity parameter for rnn. \n",
    "        :param proj_dim: Defaulted to 32. Decided the dimension of projection before feeding into rnn. \n",
    "        :param rnn_hidden_size: Defaulted to 32. The hidden_size parameter for rnn. \n",
    "        :param input_scaler: Defaulted to 10000. Set a scaling to input, a lot of timeseries values of our data are extremely close to zero. \n",
    "        :param rnn_type: 'rnn', 'lstm', or 'gru'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_scaler=input_scaler\n",
    "        self.frozen_conv=training.frozen_diff_conv(n_diff=n_diff)\n",
    "        self.linear_proj_input=nn.Linear(n_diff+1,proj_dim)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        # NEW\n",
    "        self.stock_embedding = nn.Embedding(num_embeddings=n_stocks, embedding_dim=stock_emb_dim)\n",
    "        rnn_input_size = proj_dim + stock_emb_dim\n",
    "        \n",
    "        if rnn_type == \"rnn\":\n",
    "            # CHANGED rnn_input_size\n",
    "            self.RNN_layer=nn.RNN(input_size=rnn_input_size,\n",
    "                                  hidden_size=rnn_hidden_size,\n",
    "                                  num_layers=rnn_num_layer,\n",
    "                                  nonlinearity=rnn_act,\n",
    "                                  batch_first=True,\n",
    "                                  dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='lstm'\")\n",
    "            # CHANGED rnn_input_size\n",
    "            self.RNN_layer = nn.LSTM(input_size=rnn_input_size,\n",
    "                                     hidden_size=rnn_hidden_size,\n",
    "                                     num_layers=rnn_num_layer,\n",
    "                                     batch_first=True,\n",
    "                                     dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"gru\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='gru'\")\n",
    "            # CHANGED rnn_input_size\n",
    "            self.RNN_layer = nn.GRU(input_size=rnn_input_size,\n",
    "                                    hidden_size=rnn_hidden_size,\n",
    "                                    num_layers=rnn_num_layer,\n",
    "                                    batch_first=True,\n",
    "                                    dropout=rnn_drop_out)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported rnn_type: {rnn_type}\")\n",
    "        \n",
    "        self.linear_post_rnn=nn.Linear(rnn_hidden_size,1)\n",
    "        self.frozen_list=[\"frozen_conv\"] \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # NEW\n",
    "        # Expected shape of x originally: (N, L + 1), where N is the batch number\n",
    "        x, emb_id = x[:, :-1], x[:, -1].long() # (N,L) and (N,) respectively\n",
    "        \n",
    "        #First, scale the input, and unsqueese to add in one dimension in dim 1 as channel. This is needed for convolution. \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1) # (N,1,L)\n",
    "        x=self.frozen_conv(x) # (N, n_diff+1, L)\n",
    "        x=x.permute(0,2,1) # (N, L, n_diff+1)\n",
    "        x=self.linear_proj_input(x) # (N, L, proj_dim)\n",
    "\n",
    "        # NEW\n",
    "        stock_emb = self.stock_embedding(emb_id) # (N, stock_emb_dim) Do note that nn.Embedding directly maps one integer to a vector of dimension stock_emb_dim (in batches)\n",
    "        stock_emb = stock_emb.unsqueeze(1).expand(-1, x.shape[1], -1) # (N, L, stock_emb_dim)\n",
    "        x = torch.cat([x, stock_emb], dim=-1) # (N, L, proj_dim + stock_emb_dim)\n",
    "        \n",
    "        \n",
    "        x=self.RNN_layer(x)[0] # (N, L, hidden_size)\n",
    "        x=self.linear_post_rnn(x) # (N,L, 1)\n",
    "        \n",
    "        return torch.sum(x,dim=1)/self.input_scaler # (N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3520b49-a38c-48ea-94c2-dd8e130a79a4",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a579e2c4-ce12-4b32-8773-8bef20472290",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_emb_model=RV_RNN_conv_emb(n_diff=2, rnn_type=\"rnn\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000, stock_emb_dim=8).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_emb_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10bed8-4327-4fab-9866-4f45da8ea505",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bab08bbe-1412-4f9b-a4ee-d4f40a0e17ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  1.349992275238037  epoch  1 has training loss  tensor(0.2788, device='cuda:0')  and validation loss  tensor(0.2365, device='cuda:0') .\n",
      "\n",
      "At  8.94292426109314  epoch  5 has training loss  tensor(0.2466, device='cuda:0')  and validation loss  tensor(0.2300, device='cuda:0') .\n",
      "\n",
      "At  18.258508920669556  epoch  10 has training loss  tensor(0.2450, device='cuda:0')  and validation loss  tensor(0.2300, device='cuda:0') .\n",
      "\n",
      "At  28.20546579360962  epoch  15 has training loss  tensor(0.2444, device='cuda:0')  and validation loss  tensor(0.2265, device='cuda:0') .\n",
      "\n",
      "At  39.103919506073  epoch  20 has training loss  tensor(0.2440, device='cuda:0')  and validation loss  tensor(0.2290, device='cuda:0') .\n",
      "\n",
      "At  49.105814695358276  epoch  25 has training loss  tensor(0.2435, device='cuda:0')  and validation loss  tensor(0.2259, device='cuda:0') .\n",
      "\n",
      "At  59.59119391441345  epoch  30 has training loss  tensor(0.2431, device='cuda:0')  and validation loss  tensor(0.2276, device='cuda:0') .\n",
      "\n",
      "At  69.47187566757202  epoch  35 has training loss  tensor(0.2429, device='cuda:0')  and validation loss  tensor(0.2266, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 29  with validation loss:  tensor(0.2256, device='cuda:0') .\n",
      " The total number of epoch trained is  39 .\n",
      " Training completed in:  78.39641618728638 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.0161, -0.3591, -0.0708],\n",
       "                      [ 0.1355,  0.0194, -0.1619],\n",
       "                      [-0.0083,  0.4166,  0.4963],\n",
       "                      [-0.0465,  0.1142,  0.1077],\n",
       "                      [ 0.4109, -0.1237,  0.3958],\n",
       "                      [ 0.3618,  0.2320, -0.2923],\n",
       "                      [ 0.1499,  0.1747, -0.2268],\n",
       "                      [-0.0958, -0.2178, -0.2119],\n",
       "                      [-0.2366, -0.6817, -0.4363],\n",
       "                      [ 0.0028,  0.0819,  0.0558],\n",
       "                      [ 0.2525,  0.4167,  0.1376],\n",
       "                      [-0.2045,  0.0547,  0.0108],\n",
       "                      [-0.4198, -0.6393, -0.4531],\n",
       "                      [-0.3736, -0.3660,  0.1482],\n",
       "                      [ 0.4928,  0.6487, -0.3968],\n",
       "                      [-0.2159, -0.2583, -0.2428],\n",
       "                      [ 0.0426,  0.2553,  0.3397],\n",
       "                      [-0.2983, -0.3297,  0.1352],\n",
       "                      [ 0.0504, -0.0949, -0.4020],\n",
       "                      [ 0.2241,  0.0500, -0.0752],\n",
       "                      [ 0.0276, -0.1934, -0.1673],\n",
       "                      [-0.0047,  0.0103,  0.0010],\n",
       "                      [ 0.0134, -0.1293, -0.2244],\n",
       "                      [ 0.2396,  0.2417, -0.2978],\n",
       "                      [ 0.2906, -0.2416,  0.2104],\n",
       "                      [-0.2521,  0.2610,  0.2958],\n",
       "                      [ 0.0028, -0.2057, -0.1733],\n",
       "                      [ 0.0067,  0.0128, -0.0080],\n",
       "                      [ 0.0337,  0.2168,  0.0669],\n",
       "                      [-0.0369, -0.3110, -0.1341],\n",
       "                      [-0.0692, -0.1237, -0.0437],\n",
       "                      [-0.0206, -0.5687, -0.4297]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 0.2958, -0.2905,  0.1137,  0.1021, -0.2492, -0.2115,  0.2862,  0.2010,\n",
       "                       0.0630,  0.0078, -0.1916,  0.2442, -0.3590, -0.0900,  0.1035,  0.4781,\n",
       "                      -0.3919,  0.2277, -0.1424, -0.4673, -0.0422, -0.0182,  0.0595, -0.4574,\n",
       "                      -0.4100,  0.4846, -0.0101, -0.0711, -0.2265,  0.1839,  0.3048,  0.0847],\n",
       "                     device='cuda:0')),\n",
       "             ('stock_embedding.weight',\n",
       "              tensor([[ 0.5440, -1.5859, -0.9540,  0.5885, -2.8414,  0.1460, -0.7964,  1.2660],\n",
       "                      [-0.5380,  1.6136, -0.4758, -0.1977, -0.8407,  0.2842,  0.1021, -0.5029],\n",
       "                      [ 0.3891, -0.9613, -0.9532, -0.8993,  0.6653, -0.1704,  1.1366,  0.0614],\n",
       "                      [-2.2225, -1.2220,  0.8931,  1.2878, -1.8696,  0.9012, -0.5386,  2.1453],\n",
       "                      [ 0.3523, -0.7389,  0.8587,  1.6284, -2.9390, -1.2635, -1.3391,  1.4983],\n",
       "                      [ 0.7233,  0.4800,  0.2977,  0.9592, -0.3398,  1.2999, -1.5213, -0.1608],\n",
       "                      [-1.8058, -0.9823,  0.1700,  0.6213, -2.7613,  0.7477, -0.8991,  0.5499],\n",
       "                      [-0.7765, -0.4781, -0.5806,  1.9173,  0.8964, -0.0826,  1.0220, -0.3519],\n",
       "                      [-1.8152,  0.4174, -1.2626,  0.3005, -0.2993, -0.6564,  1.3732, -0.7276],\n",
       "                      [ 0.3994, -0.5660, -1.9543,  0.9341, -1.7131,  1.7015, -0.0455,  0.8537],\n",
       "                      [ 0.7138, -0.2195,  0.5230,  0.4414, -0.7913,  0.9463,  1.7262,  1.2116],\n",
       "                      [ 0.1872,  0.0047, -0.5483, -0.2216, -0.3835, -0.3607, -1.5646,  0.7994],\n",
       "                      [-0.4350,  0.3523, -1.1584, -2.0318, -0.0512, -1.7036,  0.6260, -1.0068],\n",
       "                      [-1.0470, -1.0452,  0.5486, -0.2960,  0.0356, -1.3199,  0.9420,  0.5766],\n",
       "                      [ 0.5838, -0.5271, -0.6013,  0.4942,  0.0863, -0.7862, -0.7142,  0.9570],\n",
       "                      [-1.6682, -0.5584, -0.8324,  0.6566, -0.5695, -0.1552, -1.2885, -0.8330],\n",
       "                      [-0.6680, -0.4308, -0.4182,  1.0369,  1.6092,  0.8996,  0.5532,  0.1805],\n",
       "                      [-1.7474,  1.0710, -0.8863,  2.8738,  0.2672,  1.2835, -1.7035, -1.4076],\n",
       "                      [-0.8624,  1.2117,  0.1258, -2.3748,  1.6233,  0.7393, -0.5139,  1.4777],\n",
       "                      [-0.2445,  0.2248,  0.9659,  0.3589, -0.9822, -1.2069,  0.8184, -0.1540],\n",
       "                      [-0.1306, -0.8386,  0.2396,  0.9378, -1.5741, -1.7077,  1.6863, -0.6114],\n",
       "                      [-0.2870,  1.8081, -1.2020,  0.6216,  0.5782,  0.6882, -0.4412,  1.0616],\n",
       "                      [-0.5383,  1.5045, -1.5646,  0.5081, -0.5895,  0.7251,  1.1464,  0.8017],\n",
       "                      [-0.9516,  0.9035,  0.3647, -1.0698,  0.4247, -0.5362,  0.2191,  0.9060],\n",
       "                      [ 1.4624,  0.6934, -0.8185,  2.2785, -1.2178,  2.1663,  0.3531, -0.4433],\n",
       "                      [ 0.6357,  1.2627, -0.6077, -1.8467, -0.6269, -0.0711,  0.8308, -0.3476],\n",
       "                      [ 0.0612, -0.6730,  1.0353,  0.2276,  1.2960, -0.8926, -0.1414,  0.9193],\n",
       "                      [-0.2441, -0.6182, -0.4153,  1.0309, -0.0296,  1.3254,  0.1580, -0.4720],\n",
       "                      [-0.1262, -0.1666,  1.9463, -0.6357,  0.2077, -0.6043,  0.8909, -0.7137],\n",
       "                      [-0.4822, -0.0179, -0.3776,  0.5368,  1.7154, -0.2479,  1.1577,  1.7264],\n",
       "                      [ 1.1473,  1.7904, -1.1055,  1.2048, -1.0140,  1.0455, -0.0495, -0.0698],\n",
       "                      [-0.5718,  0.2862, -0.7556, -0.8522,  0.6873, -1.3892, -0.4582,  0.0348],\n",
       "                      [-0.2114, -1.2080,  1.2632,  0.3928, -0.0846, -1.3893, -1.0695,  0.5081],\n",
       "                      [-1.2849, -1.2183, -0.1843, -0.9657,  1.0981,  0.5290,  0.6820, -0.3966],\n",
       "                      [ 2.7114,  2.0480,  1.2469,  1.2044, -0.6721,  1.9772, -1.2636,  0.4616],\n",
       "                      [ 0.8831, -0.2128, -1.5181,  0.1949, -2.4207, -0.1720, -0.2714, -0.4273],\n",
       "                      [ 0.8418, -0.1878,  0.5014,  0.8246,  0.8572, -0.6765,  0.2909, -0.3622],\n",
       "                      [-0.2739,  2.6756, -2.6714,  0.6327,  1.6743, -0.1397, -1.0932, -1.4389],\n",
       "                      [ 0.4386, -2.7322, -0.3942,  0.9349,  0.6903, -0.5206,  1.6917, -0.7140],\n",
       "                      [-1.0250, -0.8815, -0.1573, -1.5887, -0.2635,  1.5009,  0.1821, -1.6661],\n",
       "                      [-0.2727, -0.3244,  1.2693,  0.4252,  1.1371, -1.1548, -0.6186,  1.0184],\n",
       "                      [ 0.4544,  0.2208,  0.2848, -0.5540, -0.0936, -0.0256,  0.9628,  0.0050],\n",
       "                      [-0.4601, -0.4107, -1.1771, -1.8472, -0.1245, -1.8727,  0.3850, -0.0583],\n",
       "                      [ 1.2399,  0.4057, -0.1375, -0.5120,  0.4883, -0.9986,  2.0575,  0.6496],\n",
       "                      [-0.1700,  0.7115,  0.7464, -0.7962, -0.7528,  0.5762,  0.5282, -0.7814],\n",
       "                      [ 1.2081, -0.1138,  1.1625, -1.3788, -0.8209, -0.0100,  0.7258, -0.9079],\n",
       "                      [-0.5869, -0.2847, -0.8123, -1.0321,  0.2518, -0.4321,  0.2323, -0.0956],\n",
       "                      [-0.1111, -0.2458, -1.2662, -1.1287, -0.0036,  1.3890,  1.3159,  0.1301],\n",
       "                      [-0.6106, -0.1397, -0.2209, -0.4104,  0.9315, -0.7142, -0.2108, -0.4482],\n",
       "                      [-1.4757,  1.1024, -1.7947, -0.5787, -1.1955,  0.9809, -0.1013,  1.5583],\n",
       "                      [-0.9979,  0.8112,  0.9183, -0.5691,  0.3821, -0.5230, -1.3120, -0.6309],\n",
       "                      [-0.4250,  1.1071, -1.7178, -1.4397, -1.4588,  1.9751,  0.7309,  1.6415],\n",
       "                      [-0.2569,  1.2566,  1.0870, -0.5096, -0.7967,  0.2034,  0.4711, -0.2215],\n",
       "                      [-1.1730,  1.8723, -0.7602, -1.1375, -1.2362, -0.2013, -0.6221,  0.1322],\n",
       "                      [-0.2817,  0.5900,  1.0324, -0.0335, -0.8843,  0.0552,  0.2838, -0.3544],\n",
       "                      [-0.6610,  0.2036, -2.5377, -0.0356, -1.0048, -0.0751, -0.8905,  1.3065],\n",
       "                      [ 1.2062,  1.1536,  0.9285, -0.7475,  0.1440,  0.9370,  1.2517,  0.5593],\n",
       "                      [ 2.1661,  0.0948,  0.9911,  0.6671, -0.0709,  0.1298,  2.0667, -0.0133],\n",
       "                      [-0.8623,  0.8132,  0.1953, -0.7196,  0.5326,  0.7958, -0.9177, -0.1028],\n",
       "                      [-0.5265, -0.1924, -0.4597, -1.2994, -0.8935, -1.9146, -0.8004, -0.5329],\n",
       "                      [-0.7580, -0.5178, -1.0140, -0.4229,  0.1898, -0.7585, -0.2743, -1.5745],\n",
       "                      [ 0.3107, -0.9171,  0.9645,  0.2098,  0.9457, -0.3682,  0.3945,  0.7220],\n",
       "                      [-0.2729, -0.0097, -0.5602, -1.0904,  0.5865,  0.5845, -0.0308, -0.2612],\n",
       "                      [-1.0111, -0.6467, -0.9637,  1.0220,  0.0147,  0.2515,  1.3375,  0.0371],\n",
       "                      [-1.3082,  0.4022,  0.2159,  0.8770,  1.0386,  0.3027, -0.2423,  0.9627],\n",
       "                      [-0.6088,  2.7022,  1.0563, -1.5152,  0.1661, -0.9507, -0.7280,  0.6424],\n",
       "                      [ 1.4052,  1.9668, -1.9420,  1.7438, -0.8772,  1.2702, -0.8286, -0.0038],\n",
       "                      [ 0.3672,  0.1132,  2.1192,  0.0184, -0.7268,  0.6143, -1.3098, -0.5117],\n",
       "                      [ 1.6270, -1.0037,  2.0929,  1.5531, -0.9338, -0.4080, -0.6655,  2.3164],\n",
       "                      [-0.0508, -0.4360,  0.2687,  0.5552, -1.9984,  1.4261,  0.1296,  0.2632],\n",
       "                      [-1.6319, -0.2692,  0.1490,  0.9773, -1.5112,  0.6613, -1.8645,  0.0428],\n",
       "                      [-2.9399, -0.8760,  1.0393,  0.0928,  1.6110,  1.3165,  1.6930,  0.2686],\n",
       "                      [-1.9732,  0.9307, -0.5576, -1.1580,  0.6128,  0.5214,  0.8145,  0.8664],\n",
       "                      [-2.1981,  0.6866, -1.1518,  1.4441,  1.1192,  0.2549,  0.0417, -0.7112],\n",
       "                      [-1.4356, -0.8801,  0.7998, -0.6956, -0.1677,  0.4238, -0.1740,  0.4306],\n",
       "                      [ 0.9153,  0.3919,  0.9477, -0.7384, -0.1824,  0.9253,  0.4598,  0.3429],\n",
       "                      [ 2.1149, -0.9355,  1.3825, -0.9324, -0.6610, -0.4861, -0.3985,  1.3090],\n",
       "                      [ 0.2839,  0.4026,  0.1582,  0.1027, -0.7735,  2.0003, -0.0925, -1.2720],\n",
       "                      [-1.2863,  1.1798, -0.3120,  1.1042,  1.0595, -0.3685, -2.2306, -0.6339],\n",
       "                      [-0.0827, -0.3496, -0.4490,  1.0183,  0.9237,  0.4138,  1.0169, -0.7218],\n",
       "                      [ 1.9680,  1.8286, -0.5826,  1.5558,  0.7003,  0.9448, -0.8738,  0.3022],\n",
       "                      [ 0.3904, -1.4768, -0.0461, -0.6942,  0.1970, -0.5910,  0.1555, -1.9530],\n",
       "                      [-1.9864,  0.6807,  0.2450,  0.5062,  0.1349, -0.2202, -0.2435,  0.5023],\n",
       "                      [ 0.4715, -0.5260, -0.3473, -0.5295, -0.2433,  0.4511,  0.7221, -1.1416],\n",
       "                      [ 0.0541, -0.6881,  0.5819, -0.8907, -1.1637, -0.7637, -1.8189,  1.2739],\n",
       "                      [ 1.1065,  1.0854, -0.6252,  1.1272, -1.5141,  0.8351, -1.4911,  0.3514],\n",
       "                      [-0.6424,  0.0845, -1.1515,  1.3255, -0.1250,  1.0998, -0.7221, -1.0552],\n",
       "                      [ 0.0938,  2.1650,  1.2818, -0.7034, -0.6713, -1.9626,  0.2885,  0.7432],\n",
       "                      [-0.9941, -0.4366, -0.1551, -0.0387, -0.3824,  2.1703,  0.0176,  1.2422],\n",
       "                      [-0.3190,  0.5079,  0.7197, -0.0457,  0.6461,  0.5836, -0.1749, -0.2102],\n",
       "                      [-1.3940,  0.2350, -0.2703,  2.2310,  1.2467,  0.2190, -0.2622,  0.1518],\n",
       "                      [ 0.1719,  0.5348, -2.1371,  0.1465, -0.5247,  0.1229, -1.3124, -1.0295],\n",
       "                      [-0.0439, -0.6040,  0.4602, -0.0766, -0.7620,  0.3875, -0.2461,  0.0294],\n",
       "                      [ 1.1081,  0.2914, -0.1805, -0.7716,  1.3142,  0.9752,  1.2549,  0.9366],\n",
       "                      [-1.6071, -0.0208, -0.5121, -1.0655, -0.5614, -0.2308, -0.3800, -0.8395],\n",
       "                      [ 1.2159, -0.7052, -0.1143, -0.5074,  1.5400, -0.7139, -1.9033,  1.2697],\n",
       "                      [-1.1255,  0.4888,  0.4973, -0.2429,  0.2042,  0.7696, -0.3816,  0.4670],\n",
       "                      [ 0.7154, -0.0543, -1.1002,  0.7549, -1.5932, -0.9743,  0.3298,  0.3122],\n",
       "                      [ 0.8685, -1.2878,  0.3871,  0.8516,  0.9679, -0.4866,  1.0694, -0.5571],\n",
       "                      [-0.1003,  1.4568, -1.6639,  0.0385, -0.4131,  0.5779, -1.5810, -0.2020],\n",
       "                      [ 1.0857, -0.7329, -0.3410,  0.1466, -0.0312, -0.4339, -1.6826,  0.7598],\n",
       "                      [-1.7424,  0.7653, -1.0787,  0.2081, -1.4764,  0.6442,  1.0630, -0.2318],\n",
       "                      [-0.6145,  1.0548,  0.3294, -0.8358, -1.0697, -0.3804,  1.3791, -0.0419],\n",
       "                      [ 0.0042,  0.9735,  1.1256,  1.7705, -0.6281,  1.8328,  0.3059,  1.0124],\n",
       "                      [ 0.0710,  1.7496, -0.7737,  0.6653,  0.3482,  1.2640,  0.5420, -1.1643],\n",
       "                      [ 0.1254,  0.9317, -0.2112, -0.3439,  0.4200, -0.6739,  0.6430,  1.0791],\n",
       "                      [ 0.2216,  1.5343,  0.6088, -1.1524, -0.0719, -0.6823,  0.9712,  1.0815],\n",
       "                      [ 0.3424,  1.1953,  0.1148, -0.6615, -0.3843,  0.6141,  0.0630, -0.4974],\n",
       "                      [ 0.1646, -1.6883,  0.4993,  0.2249,  0.7673, -1.3125, -0.2198, -0.8549],\n",
       "                      [ 1.1329,  0.0161,  0.8787,  0.0828,  1.8592,  1.5905,  0.7698,  0.6388],\n",
       "                      [ 0.6770, -0.7129,  0.5295,  0.3030,  0.5399, -2.1286,  0.0953, -0.9309],\n",
       "                      [ 1.2181,  2.1286, -0.7237, -0.5906, -1.1252,  1.4133, -0.8120,  1.1406]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.1051,  0.0962,  0.0743,  ...,  0.1703, -0.1036, -0.0137],\n",
       "                      [ 0.0343, -0.1063,  0.0933,  ...,  0.0646,  0.0639, -0.1273],\n",
       "                      [-0.0369, -0.0315, -0.0280,  ...,  0.2895, -0.2250,  0.0008],\n",
       "                      ...,\n",
       "                      [ 0.1143, -0.0889,  0.1463,  ..., -0.0832,  0.1525, -0.2978],\n",
       "                      [ 0.1006, -0.0669, -0.1356,  ..., -0.0045, -0.1690,  0.0305],\n",
       "                      [ 0.1579,  0.0070, -0.0934,  ..., -0.2264,  0.0312,  0.2391]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.2729, -0.0603, -0.0086,  ...,  0.4763,  0.4629, -0.0155],\n",
       "                      [-0.3555, -0.2684, -0.3093,  ..., -0.2296,  0.5745,  0.0275],\n",
       "                      [-0.2740,  0.0831,  0.0556,  ...,  0.2299,  0.4842, -0.0350],\n",
       "                      ...,\n",
       "                      [-0.4796, -0.1208, -0.2847,  ...,  0.2982, -0.1101, -0.0063],\n",
       "                      [-0.1061,  0.1618, -0.0714,  ..., -0.0651, -0.0373,  0.1876],\n",
       "                      [-0.5496, -0.0853, -0.5064,  ..., -0.0640,  0.1862, -0.0912]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.1258, -0.0090, -0.1247, -0.0731,  0.0350,  0.0195, -0.0168,  0.0356,\n",
       "                       0.2318, -0.1500,  0.0409, -0.0058,  0.1007,  0.0117, -0.1649, -0.0236,\n",
       "                      -0.0511,  0.1072,  0.0579,  0.0988,  0.1442,  0.0866, -0.1285, -0.1281,\n",
       "                      -0.0215, -0.0473,  0.1074,  0.0491,  0.0701,  0.1772,  0.0517,  0.1482],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.0618,  0.0313,  0.1200,  0.2227,  0.0761,  0.1304,  0.0834,  0.0587,\n",
       "                       0.2451, -0.1807,  0.0724,  0.0613, -0.1681,  0.0729, -0.2014,  0.1417,\n",
       "                       0.1814,  0.0492, -0.0445, -0.1523,  0.0985, -0.0968, -0.0841,  0.0188,\n",
       "                       0.0875, -0.0462,  0.0432, -0.0184, -0.2026,  0.0775,  0.0030,  0.0481],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.1787,  0.2152,  0.1287,  0.1587, -0.1425, -0.1136, -0.0605,  0.0862,\n",
       "                        0.0983, -0.0469,  0.1022,  0.1213,  0.1454, -0.1659, -0.1351, -0.0702,\n",
       "                       -0.1943,  0.0795,  0.0781,  0.1210, -0.1605, -0.0176, -0.2140,  0.1339,\n",
       "                       -0.0203,  0.1182, -0.0484,  0.1800,  0.0049,  0.0634, -0.1616,  0.0743]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0249], device='cuda:0'))])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_emb_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3cbba78c-5b38-4da3-91c0-4a1731759a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f43353e0250>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
