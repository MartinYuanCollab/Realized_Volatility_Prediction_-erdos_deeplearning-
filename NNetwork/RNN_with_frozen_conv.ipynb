{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77e9ebe",
   "metadata": {},
   "source": [
    "## RNN with frozen convolution layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b854e",
   "metadata": {},
   "source": [
    "The idea is inspired by an application of RNN in predicting if an online review (say, for a product) is positive or negative (1 or 0). Each word in the review sentence is first projected to a large dimension vector space and then sent into an RNN network sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6b66b",
   "metadata": {},
   "source": [
    "We will make use of frozen convolution layer to create derivative like features for our time series features. Then, we use the derivative values of a certain time as if a \"word\" in a \"review\", the target RV as if the \"score\" of the \"review\" to train an RNN network that predicts the target RV with the time series features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd88f7",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907e47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef8d13b-6c6f-4cac-b98c-105c0941a447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12efccd",
   "metadata": {},
   "source": [
    "Below is what Yuan needed to get his gpu working, do not run if you do not need it. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d19d5a3a-dc13-4ea8-b759-1a7d2ba08f81",
   "metadata": {},
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1bc2da4-b065-439a-8faf-e282b2ee24a6",
   "metadata": {},
   "source": [
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb26cd",
   "metadata": {},
   "source": [
    "Let's say, we have following timeseries feature (created randomly), we will create the derivative features first. As a reminder, the zero dimension is the batch size, the dimension one is channel (needed for the first convolution layer, not really a \"thing\" for time series like features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(1,1,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d5ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5577,  0.7130,  1.3506, -1.5546,  0.3281,  0.9122,  0.4965,\n",
       "           0.6177, -1.2331,  0.9436, -0.6563, -0.2899, -0.4059,  1.1815,\n",
       "          -0.5097, -0.1566, -0.7031,  1.1402,  1.0926, -0.3847,  2.3373,\n",
       "          -1.5838,  0.6909, -1.1103,  0.7288, -1.7757,  0.0241,  1.0242,\n",
       "          -0.6571,  0.1368, -1.3972,  0.7094, -1.1373,  0.3374,  1.7012,\n",
       "           2.3106, -0.9056,  0.7240, -0.4777,  1.3106,  0.7943, -0.2757,\n",
       "          -1.0394, -0.8101, -0.4421, -1.4641,  0.0069,  1.4155,  1.4152,\n",
       "           0.1695,  1.4291, -0.3199, -1.9401, -2.0056,  1.0310,  1.5263,\n",
       "          -0.7727,  1.3345, -0.4410, -1.9410]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739b2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_create_diff=training.frozen_diff_conv(n_diff=4)\n",
    "ts_diff_feature=conv_create_diff(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48f9ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.5775e-01,  7.1296e-01,  1.3506e+00, -1.5546e+00,  3.2810e-01,\n",
       "           9.1217e-01,  4.9651e-01,  6.1770e-01, -1.2331e+00,  9.4364e-01,\n",
       "          -6.5634e-01, -2.8991e-01, -4.0593e-01,  1.1815e+00, -5.0972e-01,\n",
       "          -1.5659e-01, -7.0315e-01,  1.1402e+00,  1.0926e+00, -3.8470e-01,\n",
       "           2.3373e+00, -1.5838e+00,  6.9093e-01, -1.1103e+00,  7.2877e-01,\n",
       "          -1.7757e+00,  2.4134e-02,  1.0242e+00, -6.5708e-01,  1.3678e-01,\n",
       "          -1.3972e+00,  7.0943e-01, -1.1373e+00,  3.3745e-01,  1.7012e+00,\n",
       "           2.3106e+00, -9.0558e-01,  7.2397e-01, -4.7765e-01,  1.3106e+00,\n",
       "           7.9435e-01, -2.7569e-01, -1.0394e+00, -8.1008e-01, -4.4211e-01,\n",
       "          -1.4641e+00,  6.9265e-03,  1.4155e+00,  1.4152e+00,  1.6947e-01,\n",
       "           1.4291e+00, -3.1987e-01, -1.9401e+00, -2.0056e+00,  1.0310e+00,\n",
       "           1.5263e+00, -7.7269e-01,  1.3345e+00, -4.4095e-01, -1.9410e+00],\n",
       "         [ 1.2707e+00,  6.3766e-01, -2.9052e+00,  1.8827e+00,  5.8407e-01,\n",
       "          -4.1565e-01,  1.2119e-01, -1.8508e+00,  2.1768e+00, -1.6000e+00,\n",
       "           3.6643e-01, -1.1602e-01,  1.5874e+00, -1.6912e+00,  3.5313e-01,\n",
       "          -5.4655e-01,  1.8433e+00, -4.7559e-02, -1.4773e+00,  2.7220e+00,\n",
       "          -3.9212e+00,  2.2747e+00, -1.8012e+00,  1.8390e+00, -2.5045e+00,\n",
       "           1.7998e+00,  1.0000e+00, -1.6812e+00,  7.9386e-01, -1.5339e+00,\n",
       "           2.1066e+00, -1.8467e+00,  1.4747e+00,  1.3638e+00,  6.0939e-01,\n",
       "          -3.2162e+00,  1.6295e+00, -1.2016e+00,  1.7883e+00, -5.1630e-01,\n",
       "          -1.0700e+00, -7.6369e-01,  2.2930e-01,  3.6797e-01, -1.0220e+00,\n",
       "           1.4710e+00,  1.4086e+00, -2.8634e-04, -1.2457e+00,  1.2596e+00,\n",
       "          -1.7489e+00, -1.6202e+00, -6.5531e-02,  3.0366e+00,  4.9528e-01,\n",
       "          -2.2989e+00,  2.1072e+00, -1.7755e+00, -1.5001e+00,  0.0000e+00],\n",
       "         [-6.3305e-01, -3.5429e+00,  4.7880e+00, -1.2987e+00, -9.9972e-01,\n",
       "           5.3684e-01, -1.9720e+00,  4.0276e+00, -3.7767e+00,  1.9664e+00,\n",
       "          -4.8246e-01,  1.7034e+00, -3.2786e+00,  2.0443e+00, -8.9969e-01,\n",
       "           2.3899e+00, -1.8909e+00, -1.4297e+00,  4.1994e+00, -6.6432e+00,\n",
       "           6.1959e+00, -4.0759e+00,  3.6402e+00, -4.3435e+00,  4.3043e+00,\n",
       "          -7.9981e-01, -2.6813e+00,  2.4751e+00, -2.3278e+00,  3.6405e+00,\n",
       "          -3.9533e+00,  3.3214e+00, -1.1095e-01, -7.5438e-01, -3.8256e+00,\n",
       "           4.8457e+00, -2.8312e+00,  2.9899e+00, -2.3046e+00, -5.5373e-01,\n",
       "           3.0635e-01,  9.9299e-01,  1.3867e-01, -1.3900e+00,  2.4930e+00,\n",
       "          -6.2478e-02, -1.4088e+00, -1.2454e+00,  2.5053e+00, -3.0085e+00,\n",
       "           1.2869e-01,  1.5547e+00,  3.1022e+00, -2.5413e+00, -2.7942e+00,\n",
       "           4.4062e+00, -3.8827e+00,  2.7543e-01,  0.0000e+00,  0.0000e+00],\n",
       "         [-2.9099e+00,  8.3309e+00, -6.0866e+00,  2.9893e-01,  1.5366e+00,\n",
       "          -2.5089e+00,  5.9996e+00, -7.8043e+00,  5.7432e+00, -2.4489e+00,\n",
       "           2.1859e+00, -4.9820e+00,  5.3229e+00, -2.9440e+00,  3.2895e+00,\n",
       "          -4.2807e+00,  4.6112e-01,  5.6291e+00, -1.0843e+01,  1.2839e+01,\n",
       "          -1.0272e+01,  7.7161e+00, -7.9837e+00,  8.6478e+00, -5.1041e+00,\n",
       "          -1.8815e+00,  5.1564e+00, -4.8029e+00,  5.9683e+00, -7.5938e+00,\n",
       "           7.2748e+00, -3.4324e+00, -6.4343e-01, -3.0712e+00,  8.6713e+00,\n",
       "          -7.6769e+00,  5.8211e+00, -5.2945e+00,  1.7509e+00,  8.6008e-01,\n",
       "           6.8664e-01, -8.5432e-01, -1.5286e+00,  3.8830e+00, -2.5555e+00,\n",
       "          -1.3464e+00,  1.6340e-01,  3.7508e+00, -5.5139e+00,  3.1372e+00,\n",
       "           1.4260e+00,  1.5474e+00, -5.6435e+00, -2.5288e-01,  7.2004e+00,\n",
       "          -8.2889e+00,  4.1581e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 1.1241e+01, -1.4417e+01,  6.3855e+00,  1.2376e+00, -4.0454e+00,\n",
       "           8.5084e+00, -1.3804e+01,  1.3547e+01, -8.1920e+00,  4.6347e+00,\n",
       "          -7.1679e+00,  1.0305e+01, -8.2669e+00,  6.2336e+00, -7.5703e+00,\n",
       "           4.7418e+00,  5.1680e+00, -1.6472e+01,  2.3682e+01, -2.3111e+01,\n",
       "           1.7988e+01, -1.5700e+01,  1.6631e+01, -1.3752e+01,  3.2226e+00,\n",
       "           7.0378e+00, -9.9593e+00,  1.0771e+01, -1.3562e+01,  1.4869e+01,\n",
       "          -1.0707e+01,  2.7890e+00, -2.4278e+00,  1.1743e+01, -1.6348e+01,\n",
       "           1.3498e+01, -1.1116e+01,  7.0454e+00, -8.9079e-01, -1.7344e-01,\n",
       "          -1.5410e+00, -6.7431e-01,  5.4116e+00, -6.4385e+00,  1.2091e+00,\n",
       "           1.5098e+00,  3.5874e+00, -9.2647e+00,  8.6511e+00, -1.7112e+00,\n",
       "           1.2141e-01, -7.1909e+00,  5.3906e+00,  7.4533e+00, -1.5489e+01,\n",
       "           1.2447e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79075913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 60])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3354b4",
   "metadata": {},
   "source": [
    "We now permute the last two dimensions, essentially, this is just a transposition of the last two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76682d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_feature=ts_diff_feature.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed4b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cff150",
   "metadata": {},
   "source": [
    "Now, this is a batch (of size 1) of timeseries feature with 60 time steps, and 5 features in each step. We then expand the 5 features, say, to 32 by projection. As a reminder, nn.Linear automatically apply to the last dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7d96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_proj=nn.Linear(5,32)\n",
    "ts_feature_proj=linear_proj(ts_diff_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f82b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40c151",
   "metadata": {},
   "source": [
    "In this example, we will not go into too much detail, so let's make the most simple version. We then pass through a layer of RNN, then a layer of linear (to project to dimension 1 again). Learn more about RNN at https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f611ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_layer=nn.RNN(input_size=32,hidden_size=32,num_layers=1,nonlinearity=\"tanh\",batch_first=True,dropout=0)\n",
    "linear_end=nn.Linear(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207568f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_out=RNN_layer(ts_feature_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc91386",
   "metadata": {},
   "source": [
    "As a reminder, since no training is done, the RNN basically just applies the initial weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f31dfe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e423255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_proj=linear_end(RNN_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba4ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22784470",
   "metadata": {},
   "source": [
    "We will use sum, but we may change this to other functions, according to context or just feeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e293bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_out=torch.sum(out_proj,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35c7bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.7825]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9f52c",
   "metadata": {},
   "source": [
    "## Creating the actual NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d007bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created 07/02/25\n",
    "#07/02/25: Moved to training.py \n",
    "#07/08/25: Moved from training.py\n",
    "class RV_RNN_conv(nn.Module):        \n",
    "    #Created 07/02/25 see RNN_with_frozen_conv.ipynb for documentation. \n",
    "    #Modified 07/08/25 Added LSTM and GRU options\n",
    "    def __init__(self,n_diff,rnn_num_layer,rnn_drop_out,rnn_type=\"rnn\",rnn_act=\"tanh\",proj_dim=32,rnn_hidden_size=32,input_scaler=10000):\n",
    "        \"\"\"\n",
    "        :param n_diff: Decides how many derivative features is wanted in the time series. \n",
    "        :param rnn_num_layer: num_layer parameter for rnn. \n",
    "        :param rnn_drop_out: dropout parameter for rnn. \n",
    "        :param rnn_act: Defaulted to \"tanh\". Nonlinearity parameter for rnn. \n",
    "        :param proj_dim: Defaulted to 32. Decided the dimension of projection before feeding into rnn. \n",
    "        :param rnn_hidden_size: Defaulted to 32. The hidden_size parameter for rnn. \n",
    "        :param input_scaler: Defaulted to 10000. Set a scaling to input, a lot of timeseries values of our data are extremely close to zero. \n",
    "        :param rnn_type: 'rnn', 'lstm', or 'gru'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_scaler=input_scaler\n",
    "        self.frozen_conv=frozen_diff_conv(n_diff=n_diff)\n",
    "        self.linear_proj_input=nn.Linear(n_diff+1,proj_dim)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == \"rnn\":\n",
    "            self.RNN_layer=nn.RNN(input_size=proj_dim,\n",
    "                                  hidden_size=rnn_hidden_size,\n",
    "                                  num_layers=rnn_num_layer,\n",
    "                                  nonlinearity=rnn_act,\n",
    "                                  batch_first=True,\n",
    "                                  dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='lstm'\")\n",
    "            self.RNN_layer = nn.LSTM(input_size=proj_dim,\n",
    "                                     hidden_size=rnn_hidden_size,\n",
    "                                     num_layers=rnn_num_layer,\n",
    "                                     batch_first=True,\n",
    "                                     dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"gru\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='gru'\")\n",
    "            self.RNN_layer = nn.GRU(input_size=proj_dim,\n",
    "                                    hidden_size=rnn_hidden_size,\n",
    "                                    num_layers=rnn_num_layer,\n",
    "                                    batch_first=True,\n",
    "                                    dropout=rnn_drop_out)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported rnn_type: {rnn_type}\")\n",
    "        \n",
    "        self.linear_post_rnn=nn.Linear(rnn_hidden_size,1)\n",
    "        self.frozen_list=[\"frozen_conv\"] \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #First, scale the input, and unsqueese to add in one dimension in dim 1 as channel. This is needed for convolution. \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1)\n",
    "        x=self.frozen_conv(x)\n",
    "        x=x.permute(0,2,1)\n",
    "        x=self.linear_proj_input(x)\n",
    "        x=self.RNN_layer(x)[0]\n",
    "        x=self.linear_post_rnn(x)\n",
    "        \n",
    "        return torch.sum(x,dim=1)/self.input_scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71432b31",
   "metadata": {},
   "source": [
    "## Basic testing on the RNN with frozen convolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9583750",
   "metadata": {},
   "source": [
    "Test it first. As a reminder, the expected input dimensions are (Batch Size, Time Series Length), this is distinct from the example above in that the channel dimension is not present. The channel dimension is added with unsqueeze at dimension 1 so that the first convolution layer can be utilized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df3d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(10,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a33fd643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3691,  0.6008, -0.7491,  0.6827, -0.0298, -0.6829,  1.1673, -0.9580,\n",
       "         -0.0426,  0.9583, -0.6718,  0.8255, -0.6608, -1.0352,  0.0733, -0.5476,\n",
       "         -0.2988,  1.1749, -0.9487, -1.5452,  0.5344,  0.4224, -0.3108, -0.2225,\n",
       "          1.0031,  0.0261,  0.3297, -0.5437, -2.6797, -0.7719, -0.3952,  1.5811,\n",
       "          0.3911, -0.0708, -0.9342, -0.1704, -0.8037, -0.1527, -0.2513,  1.2018,\n",
       "          0.4559, -0.5213,  0.9909, -0.5318,  1.1439,  0.3972,  0.5222,  0.1130,\n",
       "         -0.0846,  0.9227,  0.0876, -1.0440, -0.9952,  1.0073,  1.1305,  0.9681,\n",
       "          0.4329,  0.2897, -1.4206,  0.2871],\n",
       "        [ 0.6732,  1.4589, -0.0327,  2.3941,  0.1705,  1.4748,  0.1476,  0.4469,\n",
       "         -0.5629, -0.6084, -0.1726, -0.5009,  0.2859, -0.2576, -0.2342,  0.7011,\n",
       "         -0.3509,  1.1059, -1.0635,  1.4440, -1.6945,  0.8974, -0.1783,  2.0359,\n",
       "          0.3362,  0.8404, -0.5280, -0.6305, -1.5888,  0.3255, -1.4203, -0.6525,\n",
       "          1.1098,  0.2628, -1.3003, -0.3188, -0.8202,  0.6200,  0.2621, -1.4408,\n",
       "          0.7445, -0.9997,  0.8704, -0.1545, -0.0922,  0.1268, -0.2153, -2.3220,\n",
       "          0.6466, -2.4672, -0.3287, -0.5903, -0.5237,  1.0507,  0.8610, -1.1270,\n",
       "          1.0529,  0.9758,  0.2571,  1.9535],\n",
       "        [ 1.0861,  0.5497, -1.3839,  0.4508, -0.6564,  0.1700,  0.2525,  0.4555,\n",
       "          1.8633, -1.2849, -0.6529, -1.4887,  1.1636,  0.0212,  1.1645, -0.3941,\n",
       "          0.9381, -0.4916,  1.4178,  0.4822,  0.0690,  0.2961,  0.1532, -0.3336,\n",
       "         -1.7279,  0.7010, -1.1445, -0.0315,  0.7724,  1.2425,  0.4189,  1.2639,\n",
       "          0.3416, -0.7222,  0.2914, -0.9067, -0.2629, -0.9623, -0.1402, -0.0396,\n",
       "         -0.7500,  1.1090,  0.2011, -0.8695, -0.1170, -0.9332,  2.4818,  2.1298,\n",
       "          0.6066, -1.1389,  1.0964,  0.6335,  0.5581,  0.6218,  0.6091,  0.5516,\n",
       "         -0.1632,  0.8144, -0.4217,  0.0114],\n",
       "        [ 0.4595,  0.9659,  0.1610, -0.5622,  0.5417, -0.5678,  0.6287,  0.7672,\n",
       "         -0.2987, -0.0907, -0.0990, -0.6882,  0.4402, -0.5562, -0.8176,  0.3934,\n",
       "          0.5093, -0.3707,  1.5168,  0.7252, -0.6975, -0.1405, -0.1680,  0.3832,\n",
       "          1.0597,  1.1802,  0.3509,  0.4478,  0.9207, -0.5212, -1.4589, -0.6694,\n",
       "         -0.0347,  0.5371, -1.0062, -0.8882, -1.5295,  1.0920,  0.1964,  1.4773,\n",
       "         -0.6533,  1.0983,  0.4911,  1.0911, -0.6860,  0.2176, -1.8270, -1.5279,\n",
       "         -0.6996, -1.1056, -1.2394,  0.4600, -1.6362,  0.2639,  1.1026, -1.0102,\n",
       "         -2.5016, -0.1081, -0.5574, -0.0498],\n",
       "        [ 0.5056,  0.1381,  0.2090,  0.8820, -1.0065,  1.9709, -0.1182, -0.6180,\n",
       "         -0.3265,  0.3947, -0.9126,  0.3644,  1.3110,  0.6638, -0.9343, -0.7084,\n",
       "         -0.7896,  0.7810,  1.5722, -1.3955, -1.0381,  0.1539,  2.2668,  0.2574,\n",
       "          1.0893, -0.1177,  0.7494,  0.6302,  0.4432,  1.6237,  0.2176, -0.7455,\n",
       "          0.3468,  1.4508, -0.6390,  0.3485,  0.9291, -0.7589, -0.6130, -2.0083,\n",
       "          1.6124, -0.2779, -1.2093, -0.0114, -0.2377,  0.0313,  0.6478, -0.1876,\n",
       "         -0.0524,  0.9096,  0.7771,  2.3679, -0.1339, -0.6659, -0.7560, -1.3376,\n",
       "         -0.6319, -0.4097,  1.2842,  0.8555],\n",
       "        [-1.2133, -1.3011, -1.9129, -0.1595, -1.3009,  0.5087,  0.4163, -0.7921,\n",
       "         -0.2978,  0.4145, -0.6629,  0.8996, -0.9207,  0.4256,  1.4870,  1.2506,\n",
       "         -0.3056,  0.3635,  0.2168, -0.1546,  1.4009, -0.4223, -0.2513, -0.8067,\n",
       "          0.3628,  0.5334,  0.4940, -0.7970, -0.9755, -0.6541, -1.2464,  1.5779,\n",
       "          2.0305,  0.7935, -0.4192,  0.2824,  1.1964, -0.2610,  0.0755,  1.3426,\n",
       "         -0.6929,  0.4034,  0.6220, -0.1843, -1.0114,  0.6420,  0.1394, -1.5182,\n",
       "         -1.1340, -0.0654,  0.1095,  0.3847,  0.9402,  0.9401,  0.9055, -0.4193,\n",
       "         -1.2463,  1.8386, -1.5116,  0.9555],\n",
       "        [ 0.5988,  0.6070, -0.9295, -1.8738,  0.6498,  0.5782, -0.5457, -1.3630,\n",
       "         -0.5465,  1.0459, -2.0164,  0.1721,  2.2047, -0.4809,  1.3311,  0.0709,\n",
       "          0.7807, -1.4615, -0.2352,  0.7575, -0.9625, -0.0290,  0.0846, -1.0619,\n",
       "         -0.6167,  0.2850,  0.3681, -0.1910, -0.0785,  0.9353, -1.9950,  0.2453,\n",
       "         -0.4173, -0.7832,  1.6126, -0.0674, -0.0768, -0.3831, -0.1042,  0.0309,\n",
       "          0.9108,  1.2738, -2.2581, -0.6676,  0.0099,  1.3548,  1.3692,  1.1654,\n",
       "          1.5481, -0.4213,  0.5553,  1.4298, -0.8512,  0.5518,  0.1855,  0.5961,\n",
       "          0.0306, -0.6607,  0.3637,  2.4329],\n",
       "        [ 0.2806, -0.3968,  0.1002, -0.3026,  1.3892,  0.8731, -0.1606,  0.5047,\n",
       "         -0.2921, -0.5726,  0.6186,  0.5189, -0.1881, -1.1910, -0.8989, -0.1859,\n",
       "          0.2642,  1.2291,  2.1685,  0.1762, -0.8726,  0.7421, -0.4455, -0.4742,\n",
       "         -0.8099, -0.4739, -0.1801,  1.2127,  0.8619,  0.4181, -1.3045, -0.8461,\n",
       "          0.7105,  0.0825,  0.0225, -1.2948,  0.4610,  0.3648,  1.9555, -1.6467,\n",
       "          0.2892,  2.2143,  0.8149,  0.8783, -1.7607,  0.6659, -1.0430,  1.2865,\n",
       "         -0.0785, -1.9592,  1.2667,  0.8374, -1.4831, -0.1283, -0.9271, -1.2802,\n",
       "          0.3170,  0.8120, -0.6370,  1.2006],\n",
       "        [-0.4566, -0.5579,  0.0691, -0.7415,  0.6495,  1.3815,  0.4402, -2.1017,\n",
       "         -0.1267, -0.7263, -0.0738,  1.9137,  0.9800,  0.3562,  0.9644,  1.0397,\n",
       "         -1.3478, -0.3030,  0.5266,  0.8394, -1.2679,  0.5185,  0.6506, -1.3185,\n",
       "         -0.0333,  1.6969,  0.1191, -0.1203, -0.6605,  0.9073, -0.2739, -0.2869,\n",
       "          1.7411, -0.4761, -2.2709,  0.7408, -0.8134,  1.3001,  1.9768,  0.6491,\n",
       "         -1.2694, -0.0252, -0.6147,  0.4298,  2.4237, -1.7485,  1.4192, -1.7496,\n",
       "          2.6889, -1.1925, -0.6681,  0.1456, -1.0167, -0.6089, -1.1013,  0.9911,\n",
       "          2.4699, -0.5494, -2.6269,  0.6075],\n",
       "        [-0.1129,  0.0365,  0.3200,  0.1866,  0.5612,  1.2585,  0.4190,  1.2931,\n",
       "          0.4536, -0.1879, -0.9626, -0.4094, -1.3397,  0.3686,  1.1832, -0.8829,\n",
       "         -3.3576,  1.1667,  1.3846, -0.1838, -0.3988,  1.8529, -1.3473, -1.4966,\n",
       "          0.7963,  1.2019, -0.0081, -0.4798,  0.8431, -1.2588,  0.6576,  1.3595,\n",
       "          0.5535, -0.0392,  0.3015,  0.3844, -0.6414, -0.7390, -0.1388, -2.7719,\n",
       "         -1.1237, -0.5743, -0.2168, -0.1742,  0.6013, -0.1101, -1.2614,  0.6709,\n",
       "         -0.3900,  0.7926,  1.7043, -1.2178,  1.7427,  0.2325, -0.5153, -1.3277,\n",
       "         -1.4626,  0.1673,  0.7379,  1.1401]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72cd7276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3691,  0.6008, -0.7491,  0.6827, -0.0298, -0.6829,  1.1673,\n",
       "          -0.9580, -0.0426,  0.9583, -0.6718,  0.8255, -0.6608, -1.0352,\n",
       "           0.0733, -0.5476, -0.2988,  1.1749, -0.9487, -1.5452,  0.5344,\n",
       "           0.4224, -0.3108, -0.2225,  1.0031,  0.0261,  0.3297, -0.5437,\n",
       "          -2.6797, -0.7719, -0.3952,  1.5811,  0.3911, -0.0708, -0.9342,\n",
       "          -0.1704, -0.8037, -0.1527, -0.2513,  1.2018,  0.4559, -0.5213,\n",
       "           0.9909, -0.5318,  1.1439,  0.3972,  0.5222,  0.1130, -0.0846,\n",
       "           0.9227,  0.0876, -1.0440, -0.9952,  1.0073,  1.1305,  0.9681,\n",
       "           0.4329,  0.2897, -1.4206,  0.2871]],\n",
       "\n",
       "        [[ 0.6732,  1.4589, -0.0327,  2.3941,  0.1705,  1.4748,  0.1476,\n",
       "           0.4469, -0.5629, -0.6084, -0.1726, -0.5009,  0.2859, -0.2576,\n",
       "          -0.2342,  0.7011, -0.3509,  1.1059, -1.0635,  1.4440, -1.6945,\n",
       "           0.8974, -0.1783,  2.0359,  0.3362,  0.8404, -0.5280, -0.6305,\n",
       "          -1.5888,  0.3255, -1.4203, -0.6525,  1.1098,  0.2628, -1.3003,\n",
       "          -0.3188, -0.8202,  0.6200,  0.2621, -1.4408,  0.7445, -0.9997,\n",
       "           0.8704, -0.1545, -0.0922,  0.1268, -0.2153, -2.3220,  0.6466,\n",
       "          -2.4672, -0.3287, -0.5903, -0.5237,  1.0507,  0.8610, -1.1270,\n",
       "           1.0529,  0.9758,  0.2571,  1.9535]],\n",
       "\n",
       "        [[ 1.0861,  0.5497, -1.3839,  0.4508, -0.6564,  0.1700,  0.2525,\n",
       "           0.4555,  1.8633, -1.2849, -0.6529, -1.4887,  1.1636,  0.0212,\n",
       "           1.1645, -0.3941,  0.9381, -0.4916,  1.4178,  0.4822,  0.0690,\n",
       "           0.2961,  0.1532, -0.3336, -1.7279,  0.7010, -1.1445, -0.0315,\n",
       "           0.7724,  1.2425,  0.4189,  1.2639,  0.3416, -0.7222,  0.2914,\n",
       "          -0.9067, -0.2629, -0.9623, -0.1402, -0.0396, -0.7500,  1.1090,\n",
       "           0.2011, -0.8695, -0.1170, -0.9332,  2.4818,  2.1298,  0.6066,\n",
       "          -1.1389,  1.0964,  0.6335,  0.5581,  0.6218,  0.6091,  0.5516,\n",
       "          -0.1632,  0.8144, -0.4217,  0.0114]],\n",
       "\n",
       "        [[ 0.4595,  0.9659,  0.1610, -0.5622,  0.5417, -0.5678,  0.6287,\n",
       "           0.7672, -0.2987, -0.0907, -0.0990, -0.6882,  0.4402, -0.5562,\n",
       "          -0.8176,  0.3934,  0.5093, -0.3707,  1.5168,  0.7252, -0.6975,\n",
       "          -0.1405, -0.1680,  0.3832,  1.0597,  1.1802,  0.3509,  0.4478,\n",
       "           0.9207, -0.5212, -1.4589, -0.6694, -0.0347,  0.5371, -1.0062,\n",
       "          -0.8882, -1.5295,  1.0920,  0.1964,  1.4773, -0.6533,  1.0983,\n",
       "           0.4911,  1.0911, -0.6860,  0.2176, -1.8270, -1.5279, -0.6996,\n",
       "          -1.1056, -1.2394,  0.4600, -1.6362,  0.2639,  1.1026, -1.0102,\n",
       "          -2.5016, -0.1081, -0.5574, -0.0498]],\n",
       "\n",
       "        [[ 0.5056,  0.1381,  0.2090,  0.8820, -1.0065,  1.9709, -0.1182,\n",
       "          -0.6180, -0.3265,  0.3947, -0.9126,  0.3644,  1.3110,  0.6638,\n",
       "          -0.9343, -0.7084, -0.7896,  0.7810,  1.5722, -1.3955, -1.0381,\n",
       "           0.1539,  2.2668,  0.2574,  1.0893, -0.1177,  0.7494,  0.6302,\n",
       "           0.4432,  1.6237,  0.2176, -0.7455,  0.3468,  1.4508, -0.6390,\n",
       "           0.3485,  0.9291, -0.7589, -0.6130, -2.0083,  1.6124, -0.2779,\n",
       "          -1.2093, -0.0114, -0.2377,  0.0313,  0.6478, -0.1876, -0.0524,\n",
       "           0.9096,  0.7771,  2.3679, -0.1339, -0.6659, -0.7560, -1.3376,\n",
       "          -0.6319, -0.4097,  1.2842,  0.8555]],\n",
       "\n",
       "        [[-1.2133, -1.3011, -1.9129, -0.1595, -1.3009,  0.5087,  0.4163,\n",
       "          -0.7921, -0.2978,  0.4145, -0.6629,  0.8996, -0.9207,  0.4256,\n",
       "           1.4870,  1.2506, -0.3056,  0.3635,  0.2168, -0.1546,  1.4009,\n",
       "          -0.4223, -0.2513, -0.8067,  0.3628,  0.5334,  0.4940, -0.7970,\n",
       "          -0.9755, -0.6541, -1.2464,  1.5779,  2.0305,  0.7935, -0.4192,\n",
       "           0.2824,  1.1964, -0.2610,  0.0755,  1.3426, -0.6929,  0.4034,\n",
       "           0.6220, -0.1843, -1.0114,  0.6420,  0.1394, -1.5182, -1.1340,\n",
       "          -0.0654,  0.1095,  0.3847,  0.9402,  0.9401,  0.9055, -0.4193,\n",
       "          -1.2463,  1.8386, -1.5116,  0.9555]],\n",
       "\n",
       "        [[ 0.5988,  0.6070, -0.9295, -1.8738,  0.6498,  0.5782, -0.5457,\n",
       "          -1.3630, -0.5465,  1.0459, -2.0164,  0.1721,  2.2047, -0.4809,\n",
       "           1.3311,  0.0709,  0.7807, -1.4615, -0.2352,  0.7575, -0.9625,\n",
       "          -0.0290,  0.0846, -1.0619, -0.6167,  0.2850,  0.3681, -0.1910,\n",
       "          -0.0785,  0.9353, -1.9950,  0.2453, -0.4173, -0.7832,  1.6126,\n",
       "          -0.0674, -0.0768, -0.3831, -0.1042,  0.0309,  0.9108,  1.2738,\n",
       "          -2.2581, -0.6676,  0.0099,  1.3548,  1.3692,  1.1654,  1.5481,\n",
       "          -0.4213,  0.5553,  1.4298, -0.8512,  0.5518,  0.1855,  0.5961,\n",
       "           0.0306, -0.6607,  0.3637,  2.4329]],\n",
       "\n",
       "        [[ 0.2806, -0.3968,  0.1002, -0.3026,  1.3892,  0.8731, -0.1606,\n",
       "           0.5047, -0.2921, -0.5726,  0.6186,  0.5189, -0.1881, -1.1910,\n",
       "          -0.8989, -0.1859,  0.2642,  1.2291,  2.1685,  0.1762, -0.8726,\n",
       "           0.7421, -0.4455, -0.4742, -0.8099, -0.4739, -0.1801,  1.2127,\n",
       "           0.8619,  0.4181, -1.3045, -0.8461,  0.7105,  0.0825,  0.0225,\n",
       "          -1.2948,  0.4610,  0.3648,  1.9555, -1.6467,  0.2892,  2.2143,\n",
       "           0.8149,  0.8783, -1.7607,  0.6659, -1.0430,  1.2865, -0.0785,\n",
       "          -1.9592,  1.2667,  0.8374, -1.4831, -0.1283, -0.9271, -1.2802,\n",
       "           0.3170,  0.8120, -0.6370,  1.2006]],\n",
       "\n",
       "        [[-0.4566, -0.5579,  0.0691, -0.7415,  0.6495,  1.3815,  0.4402,\n",
       "          -2.1017, -0.1267, -0.7263, -0.0738,  1.9137,  0.9800,  0.3562,\n",
       "           0.9644,  1.0397, -1.3478, -0.3030,  0.5266,  0.8394, -1.2679,\n",
       "           0.5185,  0.6506, -1.3185, -0.0333,  1.6969,  0.1191, -0.1203,\n",
       "          -0.6605,  0.9073, -0.2739, -0.2869,  1.7411, -0.4761, -2.2709,\n",
       "           0.7408, -0.8134,  1.3001,  1.9768,  0.6491, -1.2694, -0.0252,\n",
       "          -0.6147,  0.4298,  2.4237, -1.7485,  1.4192, -1.7496,  2.6889,\n",
       "          -1.1925, -0.6681,  0.1456, -1.0167, -0.6089, -1.1013,  0.9911,\n",
       "           2.4699, -0.5494, -2.6269,  0.6075]],\n",
       "\n",
       "        [[-0.1129,  0.0365,  0.3200,  0.1866,  0.5612,  1.2585,  0.4190,\n",
       "           1.2931,  0.4536, -0.1879, -0.9626, -0.4094, -1.3397,  0.3686,\n",
       "           1.1832, -0.8829, -3.3576,  1.1667,  1.3846, -0.1838, -0.3988,\n",
       "           1.8529, -1.3473, -1.4966,  0.7963,  1.2019, -0.0081, -0.4798,\n",
       "           0.8431, -1.2588,  0.6576,  1.3595,  0.5535, -0.0392,  0.3015,\n",
       "           0.3844, -0.6414, -0.7390, -0.1388, -2.7719, -1.1237, -0.5743,\n",
       "          -0.2168, -0.1742,  0.6013, -0.1101, -1.2614,  0.6709, -0.3900,\n",
       "           0.7926,  1.7043, -1.2178,  1.7427,  0.2325, -0.5153, -1.3277,\n",
       "          -1.4626,  0.1673,  0.7379,  1.1401]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(ts_feature,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "455ed170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_num_layer=2,rnn_drop_out=0.3,rnn_hidden_size=32,proj_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85bf9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc35034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0005],\n",
       "        [-0.0005],\n",
       "        [-0.0007],\n",
       "        [-0.0006],\n",
       "        [-0.0005],\n",
       "        [-0.0003],\n",
       "        [-0.0002],\n",
       "        [-0.0004],\n",
       "        [-0.0005],\n",
       "        [-0.0008]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfbac7",
   "metadata": {},
   "source": [
    "## Training loop (basic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06d4fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "739d9a32-e68b-4f66-bd6b-0fda83803f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4294 31984 31570 ... 29316 32195 10890]\n"
     ]
    }
   ],
   "source": [
    "print(list_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "825838c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87ca970a-b88b-4b85-8337-6cf6a957e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4294, 31984, 31570, ...,  5629, 10421,  8117])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7ba8aa2-a446-4389-8d49-bca021ceb63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15516, 30276, 16402, 27182, 24497, 13529,   373,  4219, 20323,\n",
       "        9160, 28983, 17820, 22678,  7460, 29676, 32048, 22405, 31380,\n",
       "        1816, 14079, 29944, 21990, 26804, 28210, 18142, 11682, 32597,\n",
       "       13513, 32690, 27120, 27427,  7418,  1213,  9822, 29692, 24523,\n",
       "       25318,  6274, 25569, 12713,   169, 20732, 15906, 28877, 25551,\n",
       "       10745, 31320, 31714,  6076, 23656,   424,   309, 17604, 28963,\n",
       "       23144, 11872, 29219, 25357, 22828, 17569, 17955, 11920, 18509,\n",
       "       19626, 16149,  5392,  7200, 10929,  4774, 27278, 23639, 10633,\n",
       "          72, 32534, 26944, 31018, 26494,  6648,   709,  6823, 21239,\n",
       "       11995, 23265, 31883,  2711,  1350,  1321, 16282,  5046, 29875,\n",
       "        7133, 15823, 25463,  9064,  3333, 11440, 16831,  6815, 19580,\n",
       "       30620, 24014, 17193, 10708, 30597,  4367, 27962, 13010, 32254,\n",
       "       23226, 22903,  5929, 30327,  1866, 14629,  1205,  9352, 10619,\n",
       "       14234, 15276,  4091, 22752, 18653, 11453, 26708, 30183, 13986,\n",
       "           5,  7864,  9889, 31471, 26868, 10672, 31347, 15418, 30430,\n",
       "       26568, 28267,  3955,  1392, 27014, 22081, 15845, 18728,  9936,\n",
       "        5232,  2366, 26886, 30272, 11393, 30750,  7572, 21601,  2331,\n",
       "       13207, 12073,  2058, 18502, 25429, 12532, 27496,  5932,   536,\n",
       "       27595, 23185, 26752,  2683,  6585, 15131,  6144, 27042,  7743,\n",
       "       22249, 32611,  3758, 19271, 13614, 31572, 17570,  9367, 11263,\n",
       "       14285, 12981,   146,  2643, 31266, 23490,  2109, 29906, 30303,\n",
       "       12102, 32649,  8721, 26606, 32012, 16511, 30908, 19871,  3513,\n",
       "        3001, 24127, 29974, 27752, 16504,  6631,  8750,  6493, 29819,\n",
       "       12147, 13503, 11264, 31236,  8365, 23486, 13294,  1292, 17265,\n",
       "       16594, 20928, 18205,  6316,  8459, 19955,  7369, 26763, 13560,\n",
       "        3211, 31254, 13720,   152,  4844, 14738, 22548, 27886,  4131,\n",
       "        6657, 13699, 25639,  2000, 26788, 21103, 11577, 29037,  9947,\n",
       "       32134, 30341, 17112,  7548, 20265, 12533, 10262, 10616,  7512,\n",
       "       28354, 25879,  2440, 21614, 32255, 15584,  9735, 31874, 30366,\n",
       "       31047, 16507,  6906,  9396,  6217,  1521, 17378, 26091,  3318,\n",
       "       32746,  8744, 26889,  1468,  6965, 17117,   817,  3130, 14928,\n",
       "       21373, 13980, 28634,   103, 27543, 26849,  7909, 18077, 30569,\n",
       "       10105, 12178, 20491, 32704, 12923, 15393, 14976, 26168,  2867,\n",
       "       12182, 27524, 30339, 18285, 28474, 27981, 13928, 10892, 14909,\n",
       "       21024, 25971,  9266, 25277,  5425, 17454,  3962, 14449, 31389,\n",
       "       17672,  9887, 20669,  4089, 19512, 30212, 11151, 22912, 25359,\n",
       "       29947, 31348, 16731,  1948,  6730, 14176,  2656, 15728,  8573,\n",
       "       21762,  6359,  5846, 12521, 26578,  8623,  9096, 23423, 22513,\n",
       "       23539, 17528,  5663, 24021, 32240, 28635,  2553, 13791, 22427,\n",
       "       19647, 26170,  2718, 28192, 19065,  2136, 29679,  9028, 17120,\n",
       "       25312,   618, 18184, 21658, 13627, 25338, 31402, 24406, 31331,\n",
       "        7759,  3123,  2027, 18703, 28837, 11718, 13579, 10455, 10604,\n",
       "       24913, 15365, 29316, 32195, 10890])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72aedca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3338fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62e2f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b9cf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e42729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts[\"sub_int_RV_norm\"]=scalar.fit_transform(df_RV_ts[[\"sub_int_RV\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "995d9083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>sub_int_RV</th>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sub_int_RV_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-5</td>\n",
       "      <td>-0.208285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-11</td>\n",
       "      <td>-0.453866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-16</td>\n",
       "      <td>-0.569259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-31</td>\n",
       "      <td>-0.428690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-62</td>\n",
       "      <td>-0.540259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735915</th>\n",
       "      <td>32686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32686</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735916</th>\n",
       "      <td>32690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32690</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735917</th>\n",
       "      <td>32712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32712</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735918</th>\n",
       "      <td>32746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32746</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735919</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25735920 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time_id  sub_int_RV  sub_int_num  stock_id     row_id  \\\n",
       "0               5    0.000329            1        93       93-5   \n",
       "1              11    0.000191            1        93      93-11   \n",
       "2              16    0.000126            1        93      93-16   \n",
       "3              31    0.000205            1        93      93-31   \n",
       "4              62    0.000142            1        93      93-62   \n",
       "...           ...         ...          ...       ...        ...   \n",
       "25735915    32686    0.000000           60       104  104-32686   \n",
       "25735916    32690    0.000000           60       104  104-32690   \n",
       "25735917    32712    0.000000           60       104  104-32712   \n",
       "25735918    32746    0.000000           60       104  104-32746   \n",
       "25735919    32758    0.000000           60       104  104-32758   \n",
       "\n",
       "          sub_int_RV_norm  \n",
       "0               -0.208285  \n",
       "1               -0.453866  \n",
       "2               -0.569259  \n",
       "3               -0.428690  \n",
       "4               -0.540259  \n",
       "...                   ...  \n",
       "25735915        -0.793956  \n",
       "25735916        -0.793956  \n",
       "25735917        -0.793956  \n",
       "25735918        -0.793956  \n",
       "25735919        -0.793956  \n",
       "\n",
       "[25735920 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de450e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">sub_int_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-1000</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.818799e-07</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2.313288e-04</td>\n",
       "      <td>1.060893e-05</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10000</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>3.154886e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>4.375100e-04</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>2.552987e-03</td>\n",
       "      <td>5.364106e-04</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10017</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>6.771948e-05</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>3.104404e-03</td>\n",
       "      <td>1.224910e-03</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10030</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.586782e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>4.842470e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9972</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.503467e-04</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>9.916624e-05</td>\n",
       "      <td>1.809852e-04</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9973</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>9.650211e-04</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>1.862600e-03</td>\n",
       "      <td>7.668418e-04</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9976</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>7.203531e-04</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5.946683e-04</td>\n",
       "      <td>1.509652e-04</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9988</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.957402e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.440137e-04</td>\n",
       "      <td>3.200939e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9993</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.798617e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>2.728767e-04</td>\n",
       "      <td>2.108380e-04</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sub_int_RV                                                        \\\n",
       "sub_int_num         1         2         3         4         5             6    \n",
       "row_id                                                                         \n",
       "0-1000        0.000341  0.000000  0.000023  0.000000  0.000170  3.818799e-07   \n",
       "0-10000       0.000290  0.000191  0.000087  0.000193  0.000241  3.154886e-04   \n",
       "0-10005       0.000000  0.000000  0.001554  0.002177  0.002303  4.375100e-04   \n",
       "0-10017       0.000142  0.000142  0.001464  0.001086  0.000068  6.771948e-05   \n",
       "0-10030       0.000327  0.000058  0.000293  0.000842  0.000120  2.586782e-04   \n",
       "...                ...       ...       ...       ...       ...           ...   \n",
       "99-9972       0.000197  0.000181  0.000171  0.000172  0.000369  2.503467e-04   \n",
       "99-9973       0.000821  0.000346  0.000691  0.001591  0.000863  9.650211e-04   \n",
       "99-9976       0.000569  0.001101  0.001002  0.000430  0.000797  7.203531e-04   \n",
       "99-9988       0.000040  0.000069  0.000123  0.000056  0.000016  1.957402e-04   \n",
       "99-9993       0.000249  0.000179  0.000155  0.000025  0.000325  1.798617e-04   \n",
       "\n",
       "                                                     ...                      \\\n",
       "sub_int_num        7         8         9         10  ...        51        52   \n",
       "row_id                                               ...                       \n",
       "0-1000       0.000089  0.000552  0.000012  0.000000  ...  0.000265  0.000000   \n",
       "0-10000      0.000000  0.000247  0.000265  0.000000  ...  0.000202  0.000375   \n",
       "0-10005      0.000617  0.001199  0.002306  0.001215  ...  0.000000  0.000486   \n",
       "0-10017      0.000899  0.000064  0.000593  0.000451  ...  0.000029  0.000000   \n",
       "0-10030      0.000221  0.000436  0.000099  0.000008  ...  0.000410  0.000437   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "99-9972      0.000349  0.000356  0.000390  0.000050  ...  0.000075  0.000185   \n",
       "99-9973      0.000504  0.001925  0.000641  0.000382  ...  0.001081  0.001095   \n",
       "99-9976      0.000586  0.000538  0.000570  0.000781  ...  0.000508  0.000406   \n",
       "99-9988      0.000071  0.000095  0.000063  0.000030  ...  0.000034  0.000176   \n",
       "99-9993      0.000080  0.000125  0.000126  0.000205  ...  0.000099  0.000370   \n",
       "\n",
       "                                                                   \\\n",
       "sub_int_num        53        54        55        56            57   \n",
       "row_id                                                              \n",
       "0-1000       0.000214  0.000003  0.000000  0.000118  2.313288e-04   \n",
       "0-10000      0.000616  0.000564  0.000000  0.000023  3.777703e-08   \n",
       "0-10005      0.000050  0.001761  0.001617  0.001801  2.552987e-03   \n",
       "0-10017      0.001293  0.002092  0.000994  0.000848  3.104404e-03   \n",
       "0-10030      0.000004  0.000215  0.000457  0.000183  4.842470e-04   \n",
       "...               ...       ...       ...       ...           ...   \n",
       "99-9972      0.000314  0.000318  0.000115  0.000143  9.916624e-05   \n",
       "99-9973      0.000425  0.000789  0.001295  0.000596  1.862600e-03   \n",
       "99-9976      0.000662  0.000338  0.000710  0.000179  5.946683e-04   \n",
       "99-9988      0.000140  0.000129  0.000175  0.000019  1.440137e-04   \n",
       "99-9993      0.000929  0.000328  0.000251  0.000204  2.728767e-04   \n",
       "\n",
       "                                               \n",
       "sub_int_num            58        59        60  \n",
       "row_id                                         \n",
       "0-1000       1.060893e-05  0.000111  0.000288  \n",
       "0-10000      3.777703e-08  0.000020  0.000310  \n",
       "0-10005      5.364106e-04  0.000872  0.000000  \n",
       "0-10017      1.224910e-03  0.001316  0.003287  \n",
       "0-10030      0.000000e+00  0.000756  0.000005  \n",
       "...                   ...       ...       ...  \n",
       "99-9972      1.809852e-04  0.000334  0.000089  \n",
       "99-9973      7.668418e-04  0.001035  0.002115  \n",
       "99-9976      1.509652e-04  0.000388  0.000403  \n",
       "99-9988      3.200939e-05  0.000041  0.000007  \n",
       "99-9993      2.108380e-04  0.000126  0.000353  \n",
       "\n",
       "[428932 rows x 60 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts.pivot(index=\"row_id\",columns=[\"sub_int_num\"],values=[\"sub_int_RV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "677c1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "252d6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdb28caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b2a07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7c432cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 60])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07885f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0056627",
   "metadata": {},
   "source": [
    "Not entirely sure what the error code is about, I am literally doing exactly as suggested by the warning. https://stackoverflow.com/questions/23688307/settingwithcopywarning-even-when-using-loc says this is a false positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596532d4-3c50-4a8e-bbda-8448b8f02b4d",
   "metadata": {},
   "source": [
    "## Experiment: RNN (with some fine tuning), LSTM, and linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2721fdfa-a2d2-4461-8a99-0fe183fcbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a44c92-9ff1-4909-808f-0a05b6aa2a14",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00de91c2-12af-4f4b-953c-8fa907c945c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  1.2836482524871826  epoch  1 has training loss  tensor(0.2619, device='cuda:0')  and validation loss  tensor(0.2423, device='cuda:0') .\n",
      "\n",
      "At  6.662927627563477  epoch  5 has training loss  tensor(0.2547, device='cuda:0')  and validation loss  tensor(0.2368, device='cuda:0') .\n",
      "\n",
      "At  12.984842538833618  epoch  10 has training loss  tensor(0.2536, device='cuda:0')  and validation loss  tensor(0.2351, device='cuda:0') .\n",
      "\n",
      "At  19.630865812301636  epoch  15 has training loss  tensor(0.2527, device='cuda:0')  and validation loss  tensor(0.2357, device='cuda:0') .\n",
      "\n",
      "At  26.094637393951416  epoch  20 has training loss  tensor(0.2527, device='cuda:0')  and validation loss  tensor(0.2357, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 14  with validation loss:  tensor(0.2348, device='cuda:0') .\n",
      " The total number of epoch trained is  24 .\n",
      " Training completed in:  31.20871138572693 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.0534,  0.2919, -0.3057],\n",
       "                      [ 0.0650,  0.0654, -0.2658],\n",
       "                      [ 0.0175,  0.2920,  0.2604],\n",
       "                      [-0.4015,  0.4187,  0.5416],\n",
       "                      [-0.0904, -0.2123, -0.3803],\n",
       "                      [-0.1478,  0.3972, -0.3277],\n",
       "                      [ 0.5207,  0.7690,  0.4038],\n",
       "                      [ 0.0969, -0.2740, -0.5250],\n",
       "                      [-0.0276, -0.5302, -0.1606],\n",
       "                      [-0.2822, -0.2647,  0.5187],\n",
       "                      [ 0.0045, -0.3951, -0.1687],\n",
       "                      [ 0.5052,  0.1409,  0.3657],\n",
       "                      [ 0.0687,  0.5994,  0.2664],\n",
       "                      [-0.3185, -0.3795,  0.4575],\n",
       "                      [ 0.2545,  0.3227,  0.0565],\n",
       "                      [-0.0836, -0.1112, -0.0495],\n",
       "                      [-0.1078,  0.2917,  0.0700],\n",
       "                      [ 0.4257,  0.1079,  0.0385],\n",
       "                      [ 0.1929, -0.2913, -0.1357],\n",
       "                      [ 0.0022, -0.2931,  0.3934],\n",
       "                      [-0.1998, -0.0600, -0.0532],\n",
       "                      [-0.0650,  0.5099,  0.4387],\n",
       "                      [-0.0485,  0.6677,  0.4892],\n",
       "                      [ 0.0210, -0.5561, -0.0992],\n",
       "                      [-0.1579,  0.0940, -0.4233],\n",
       "                      [-0.2049, -0.0132, -0.1750],\n",
       "                      [ 0.3622, -0.0936,  0.3698],\n",
       "                      [-0.2976,  0.0076,  0.0029],\n",
       "                      [-0.1410,  0.2274, -0.1086],\n",
       "                      [-0.2515,  0.2471,  0.0651],\n",
       "                      [-0.4305, -0.1122, -0.2941],\n",
       "                      [ 0.4586,  0.3367, -0.0064]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.2166, -0.0607, -0.0186,  0.1198,  0.1875,  0.1542, -0.2492, -0.2298,\n",
       "                      -0.1050, -0.4194,  0.2647,  0.0163,  0.0282,  0.3430, -0.2433,  0.1832,\n",
       "                       0.2823, -0.5221, -0.2325,  0.0210,  0.0933,  0.1346, -0.0552,  0.0137,\n",
       "                       0.0161, -0.0591, -0.2444, -0.2754,  0.2937, -0.4088,  0.3112,  0.1076],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.0255,  0.3028, -0.2161,  ..., -0.1424,  0.0265, -0.1383],\n",
       "                      [-0.0417,  0.1997, -0.0438,  ...,  0.0671,  0.1211, -0.1283],\n",
       "                      [-0.0783, -0.3230,  0.0236,  ...,  0.0160, -0.1296,  0.0806],\n",
       "                      ...,\n",
       "                      [-0.0510, -0.0287,  0.0570,  ...,  0.3532,  0.1984, -0.0767],\n",
       "                      [-0.1034, -0.0024, -0.0551,  ..., -0.1347, -0.1531, -0.0676],\n",
       "                      [-0.1809, -0.2125,  0.6011,  ..., -0.0998, -0.0267,  0.0536]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.0135,  0.2369,  0.2202,  ..., -0.1054,  0.0496,  0.0646],\n",
       "                      [-0.1969,  0.0312, -0.3042,  ..., -0.2111, -0.1470, -0.1231],\n",
       "                      [-0.0090, -0.2736,  0.0037,  ...,  0.0503,  0.0562,  0.1543],\n",
       "                      ...,\n",
       "                      [-0.0804, -0.0174, -0.0900,  ...,  0.1085, -0.2329,  0.1649],\n",
       "                      [-0.1400, -0.1192, -0.1340,  ..., -0.1028,  0.0357, -0.0168],\n",
       "                      [ 0.3256, -0.0276,  0.1408,  ...,  0.1454,  0.1549,  0.0894]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0286,  0.0196,  0.0165,  0.1395, -0.0161,  0.2002,  0.1304,  0.0225,\n",
       "                      -0.1438,  0.0755, -0.0122,  0.1250, -0.0436,  0.0879, -0.0780, -0.0996,\n",
       "                      -0.2170,  0.0061,  0.0891,  0.0799,  0.0999, -0.0529, -0.0097, -0.1093,\n",
       "                       0.0731, -0.0588, -0.1403,  0.0970, -0.0883, -0.0254, -0.0019,  0.1061],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.1170,  0.0916, -0.0219,  0.0942,  0.0589, -0.0051, -0.1581, -0.1008,\n",
       "                       0.1751,  0.0371,  0.0915, -0.1489, -0.0865,  0.0103, -0.1195, -0.0916,\n",
       "                      -0.1451,  0.1011, -0.1168,  0.1082, -0.0648,  0.0260, -0.0390,  0.2157,\n",
       "                      -0.1093, -0.1658,  0.0428,  0.1888, -0.1285, -0.0735,  0.1128,  0.0019],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.1181,  0.0145,  0.0381,  0.1178,  0.0454,  0.1180, -0.1846, -0.1981,\n",
       "                       -0.0787, -0.0040,  0.1482, -0.0111,  0.1731, -0.1102, -0.1142, -0.1898,\n",
       "                       -0.1260, -0.1804,  0.2199,  0.1806, -0.1239, -0.0537,  0.0457, -0.0358,\n",
       "                       -0.2200, -0.1397,  0.0721,  0.0918, -0.0590, -0.0432,  0.1559, -0.1018]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0988], device='cuda:0'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"rnn\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb1f55fb-a478-4bee-bf57-12189db4383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7c7a7f06a0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b608cb1-05a8-417d-8a2a-8816518de943",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf7afa75-8e8c-4318-9c75-4e4029fdc57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: rnn_act='tanh' is ignored when using rnn_type='lstm'\n",
      "At  1.0748326778411865  epoch  1 has training loss  tensor(0.2743, device='cuda:0')  and validation loss  tensor(0.2365, device='cuda:0') .\n",
      "\n",
      "At  6.18251633644104  epoch  5 has training loss  tensor(0.2503, device='cuda:0')  and validation loss  tensor(0.2335, device='cuda:0') .\n",
      "\n",
      "At  12.641299962997437  epoch  10 has training loss  tensor(0.2477, device='cuda:0')  and validation loss  tensor(0.2336, device='cuda:0') .\n",
      "\n",
      "At  19.42552661895752  epoch  15 has training loss  tensor(0.2458, device='cuda:0')  and validation loss  tensor(0.2312, device='cuda:0') .\n",
      "\n",
      "At  26.10793972015381  epoch  20 has training loss  tensor(0.2452, device='cuda:0')  and validation loss  tensor(0.2344, device='cuda:0') .\n",
      "\n",
      "At  32.48069524765015  epoch  25 has training loss  tensor(0.2447, device='cuda:0')  and validation loss  tensor(0.2304, device='cuda:0') .\n",
      "\n",
      "At  38.90877842903137  epoch  30 has training loss  tensor(0.2443, device='cuda:0')  and validation loss  tensor(0.2304, device='cuda:0') .\n",
      "\n",
      "At  45.39295244216919  epoch  35 has training loss  tensor(0.2446, device='cuda:0')  and validation loss  tensor(0.2311, device='cuda:0') .\n",
      "\n",
      "At  51.812114238739014  epoch  40 has training loss  tensor(0.2434, device='cuda:0')  and validation loss  tensor(0.2316, device='cuda:0') .\n",
      "\n",
      "At  58.206992864608765  epoch  45 has training loss  tensor(0.2434, device='cuda:0')  and validation loss  tensor(0.2309, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 36  with validation loss:  tensor(0.2301, device='cuda:0') .\n",
      " The total number of epoch trained is  46 .\n",
      " Training completed in:  59.470561027526855 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.0069,  0.1811,  0.1279],\n",
       "                      [ 0.2459,  0.4032,  0.2393],\n",
       "                      [-0.2490, -0.3000, -0.2406],\n",
       "                      [-0.1185,  0.1376,  0.0902],\n",
       "                      [ 0.2450, -0.0417, -0.2803],\n",
       "                      [ 0.0578,  0.1179, -0.0844],\n",
       "                      [-0.0424,  0.0367,  0.1358],\n",
       "                      [-0.1225, -0.4786, -0.1143],\n",
       "                      [-0.0425, -0.0565, -0.0021],\n",
       "                      [-0.0367,  0.2773,  0.1936],\n",
       "                      [ 0.2026, -0.6658, -0.3960],\n",
       "                      [ 0.2435, -0.0487, -0.2872],\n",
       "                      [ 0.2213, -0.2336,  0.1110],\n",
       "                      [ 0.0607, -0.2668,  0.1187],\n",
       "                      [ 0.1262, -0.0500, -0.0125],\n",
       "                      [ 0.0250,  0.3876,  0.2328],\n",
       "                      [-0.0094,  0.0118, -0.0095],\n",
       "                      [-0.0987, -0.2755,  0.0026],\n",
       "                      [ 0.0923,  0.1470, -0.0529],\n",
       "                      [-0.4250, -0.0608, -0.0056],\n",
       "                      [-0.3656, -0.5486, -0.3285],\n",
       "                      [ 0.1059,  0.1513,  0.0551],\n",
       "                      [ 0.0100,  0.0130, -0.0014],\n",
       "                      [ 0.1909, -0.2455, -0.1381],\n",
       "                      [-0.1148,  0.5762,  0.3146],\n",
       "                      [-0.0052,  0.1987,  0.0629],\n",
       "                      [ 0.0022, -0.0055, -0.0096],\n",
       "                      [ 0.2796,  0.2539,  0.1095],\n",
       "                      [-0.0893,  0.0100, -0.0477],\n",
       "                      [-0.1785, -0.2729,  0.1361],\n",
       "                      [-0.1971, -0.4311, -0.2046],\n",
       "                      [ 0.0139,  0.0293,  0.0283]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 0.0412, -0.3936, -0.0962, -0.0134,  0.3826,  0.1734,  0.0759,  0.0704,\n",
       "                       0.0194, -0.0012,  0.4403, -0.5624, -0.0754,  0.2423,  0.0489,  0.3024,\n",
       "                      -0.0165,  0.2290,  0.0462,  0.4898,  0.4525, -0.3432, -0.0146, -0.2409,\n",
       "                       0.3129,  0.0036,  0.0272, -0.1457, -0.0912,  0.1124, -0.3341, -0.0011],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.2317,  0.1856, -0.1432,  ..., -0.1780,  0.2370,  0.0142],\n",
       "                      [ 0.0170, -0.0407, -0.0063,  ..., -0.0324,  0.1027,  0.0033],\n",
       "                      [-0.1094, -0.3182,  0.2347,  ...,  0.1834,  0.3727,  0.0236],\n",
       "                      ...,\n",
       "                      [ 0.0263,  0.2301, -0.0820,  ...,  0.0773,  0.0254, -0.1379],\n",
       "                      [ 0.4527, -0.3282,  0.0490,  ..., -0.0975, -0.1202,  0.4408],\n",
       "                      [ 0.2176, -0.0699, -0.1599,  ..., -0.0924,  0.0980, -0.0711]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.4456,  0.0507,  0.7273,  ...,  0.1298, -0.1539,  0.5780],\n",
       "                      [-0.1408,  0.1037, -0.1009,  ..., -0.8678,  0.0574, -0.5133],\n",
       "                      [ 0.2311,  0.1507, -0.1981,  ...,  0.9246,  0.5777,  0.2164],\n",
       "                      ...,\n",
       "                      [ 0.2492, -0.8771, -0.6296,  ...,  0.9705,  0.1573, -0.3814],\n",
       "                      [ 0.0062,  0.1042,  0.0538,  ...,  0.9150, -0.3338, -0.3413],\n",
       "                      [ 0.3815,  0.2860, -0.5249,  ...,  0.7534,  0.0410,  0.0828]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.3316, -0.5057,  0.0554, -0.2755, -0.0686, -0.1504, -0.1102, -0.0749,\n",
       "                       0.1811, -0.1539,  0.0111,  0.1353,  0.1077, -0.0717, -0.1701,  0.0916,\n",
       "                      -0.2137, -0.2951, -0.3266, -0.0127,  0.0734, -0.2507,  0.0165, -0.2718,\n",
       "                      -0.0625, -0.4720, -0.2241, -0.6282, -0.3049, -0.5354, -0.1142, -0.3366,\n",
       "                       0.2957,  0.5678,  0.4350, -0.0579,  0.1187,  0.0399,  0.0426,  0.3158,\n",
       "                       0.1435, -0.0359, -0.1362,  0.1402, -0.1535,  0.1162,  0.5572, -0.2148,\n",
       "                      -0.0318,  0.0838, -0.3519, -0.1658, -0.0833, -0.3891,  0.1197, -0.0358,\n",
       "                      -0.0217,  0.0355,  0.3625,  0.2918,  0.1041,  0.0851,  0.2861,  0.0059,\n",
       "                      -0.1761, -0.0271,  0.1748,  0.1153,  0.0097,  0.1038,  0.1728,  0.0741,\n",
       "                       0.2667,  0.0172, -0.1286, -0.0452, -0.0845, -0.0076,  0.0044,  0.1467,\n",
       "                       0.0848,  0.0604, -0.0011,  0.0776,  0.0484,  0.0302,  0.0369,  0.0293,\n",
       "                      -0.0691, -0.2069,  0.0263,  0.2676,  0.0750,  0.1344,  0.0114,  0.1975,\n",
       "                       0.2047, -0.0957, -0.3829, -0.5359,  0.0074,  0.0905, -0.1422,  0.1295,\n",
       "                       0.0152, -0.0562, -0.0028, -0.0343, -0.1382,  0.1141,  0.5125, -0.2931,\n",
       "                      -0.3311,  0.0468, -0.0811,  0.0967, -0.2007, -0.3248, -0.0444, -0.2794,\n",
       "                       0.0376, -0.2631, -0.1056, -0.0707, -0.2245, -0.2669,  0.1758, -0.2160],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-8.8549e-02, -5.2937e-01, -1.3004e-01, -1.7320e-01,  2.6681e-02,\n",
       "                      -2.2231e-01, -1.7193e-01, -1.2021e-01,  1.0195e-01, -1.4612e-02,\n",
       "                      -8.5040e-02,  5.6488e-02, -5.9794e-02, -2.0995e-01, -3.8654e-01,\n",
       "                       7.6246e-02, -1.1156e-01, -3.4893e-01, -5.6934e-02, -1.8513e-01,\n",
       "                       1.8791e-01, -4.2117e-01, -5.1045e-02, -3.6390e-01, -3.2657e-01,\n",
       "                      -4.1814e-01, -1.5989e-01, -7.0820e-01, -3.2840e-01, -6.5348e-01,\n",
       "                      -1.0752e-01, -2.1882e-01,  9.0862e-02,  8.2863e-01,  3.9657e-01,\n",
       "                      -1.0478e-02, -5.0463e-02,  1.7033e-01, -2.6971e-01,  3.1212e-01,\n",
       "                       2.5552e-01, -2.5991e-02, -5.3191e-02,  3.7042e-01, -3.8214e-02,\n",
       "                       1.3545e-01,  4.6551e-01, -2.5957e-01, -5.2676e-02, -1.3714e-01,\n",
       "                      -2.2770e-01, -3.3108e-01,  1.0820e-01, -4.4645e-01,  1.1484e-01,\n",
       "                       1.7134e-01, -2.5024e-02, -3.5697e-02,  8.9490e-02,  2.3356e-01,\n",
       "                       1.2614e-02,  1.0102e-01, -4.3026e-02,  2.0924e-01, -2.3880e-01,\n",
       "                       7.2477e-02,  9.1396e-02,  7.2033e-04, -2.3103e-01, -1.3457e-01,\n",
       "                      -5.5093e-02, -1.5555e-01,  4.6025e-02,  7.4473e-02,  1.1606e-01,\n",
       "                       2.4819e-01, -1.2268e-01, -2.2761e-02,  1.6870e-01, -1.7470e-01,\n",
       "                      -2.5953e-02,  1.0441e-02, -3.1291e-02,  4.5320e-02,  2.4888e-02,\n",
       "                       7.6519e-02,  1.1444e-01, -2.5722e-01,  1.5287e-01, -1.5460e-01,\n",
       "                       4.0361e-02,  1.6580e-01, -1.3105e-01,  2.7144e-02, -1.9940e-02,\n",
       "                      -2.4212e-02, -9.1406e-02, -7.5458e-02, -2.7376e-01, -7.0111e-01,\n",
       "                      -1.6905e-01,  2.0888e-01, -1.7869e-01,  2.9886e-01, -3.7016e-02,\n",
       "                      -2.8346e-02,  4.3057e-03,  1.7122e-01, -2.9766e-03,  1.6104e-01,\n",
       "                       4.0175e-01, -2.8064e-01, -1.2980e-01, -5.4575e-02, -1.7442e-01,\n",
       "                       3.7165e-02,  5.3997e-02, -1.0892e-01, -3.5698e-02, -5.7713e-02,\n",
       "                       8.8507e-02, -4.9803e-01,  3.3861e-03,  2.1898e-02, -3.5680e-01,\n",
       "                      -5.6063e-01,  9.8985e-02,  4.8310e-02], device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.1404,  0.0863, -0.2096,  0.3198,  0.1619,  0.0306, -0.1657,  0.0631,\n",
       "                        0.1982,  0.1974, -0.0836,  0.1116,  0.2887,  0.1497, -0.0251, -0.2737,\n",
       "                       -0.1737, -0.3410,  0.1187,  0.1497, -0.0098,  0.2129,  0.1252,  0.1107,\n",
       "                       -0.2667,  0.3283, -0.0385, -0.0567, -0.1953,  0.3865, -0.0339, -0.0470]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.0666], device='cuda:0'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"lstm\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5aa699c1-a918-4831-9f1b-8697e25bd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7c7a151c30>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344515ae-1741-4b2e-8716-2725cee570cd",
   "metadata": {},
   "source": [
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78c69b98-2b5a-4a8a-9998-a0c0951bd7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First build an approximate RV feature\n",
    "path_book=\"../raw_data/kaggle_ORVP/book_train.parquet\"\n",
    "df_rv=data_processing.create_df_RV_by_row_id_parallel(path_book)\n",
    "\n",
    "# Then merge with target dataframe\n",
    "df_rv_target=pd.merge(df_target, df_rv, on=[\"row_id\",\"time_id\",\"stock_id\"])\n",
    "\n",
    "train_dataset_base = df_rv_target.loc[df_rv_target['time_id'].isin(train_time_id), ['RV','target','row_id']].set_index('row_id')\n",
    "test_dataset_base = df_rv_target.loc[df_rv_target['time_id'].isin(test_time_id), ['RV','target','row_id']].set_index('row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b878416c-6f16-4029-9291-a62fb6d1657b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The losses for training and validation data are: 0.3019 and 0.2678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train=train_dataset_base[['RV']]\n",
    "y_train=train_dataset_base['target']\n",
    "\n",
    "X_test=test_dataset_base[['RV']]\n",
    "y_test=test_dataset_base['target']\n",
    "\n",
    "model= LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "training_loss = training.rmspe(model.predict(X_train),y_train)\n",
    "validation_loss = training.rmspe(model.predict(X_test),y_test)\n",
    "\n",
    "print(\"The losses for training and validation data are: {:.4f} and {:.4f}\".format(training_loss, validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c408726",
   "metadata": {},
   "source": [
    "## Training with native values, with a 10000 times scaler on input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc50c5",
   "metadata": {},
   "source": [
    "A key issue with our input timeseries is that all values are extremely close to zero, so a 10000 times scaler can help with expanding them a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2efd16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b95e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3846a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55dd6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "292fcf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "810267b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.4124667644500732  epoch  1 has training loss  tensor(0.2708, device='cuda:0')  and validation loss  tensor(0.2384, device='cuda:0') .\n",
      "\n",
      "At  12.776042699813843  epoch  5 has training loss  tensor(0.2543, device='cuda:0')  and validation loss  tensor(0.2427, device='cuda:0') .\n",
      "\n",
      "At  25.39820647239685  epoch  10 has training loss  tensor(0.2535, device='cuda:0')  and validation loss  tensor(0.2367, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 4  with validation loss:  tensor(0.2355, device='cuda:0') .\n",
      " The total number of epoch trained is  14 .\n",
      " Training completed in:  35.43797254562378 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.0025,  0.3429, -0.3135, -0.3415,  0.0344],\n",
       "                      [-0.3418, -0.2520,  0.3134,  0.0784, -0.0113],\n",
       "                      [-0.0905,  0.0536,  0.2372,  0.2678,  0.2170],\n",
       "                      [ 0.1711,  0.4248,  0.1065,  0.3274,  0.2058],\n",
       "                      [ 0.1589, -0.0608,  0.2764,  0.5181,  0.2483],\n",
       "                      [ 0.2800,  0.2423,  0.2475,  0.1755, -0.2207],\n",
       "                      [ 0.0426,  0.0317,  0.0968,  0.2307,  0.1035],\n",
       "                      [-0.2158, -0.1542, -0.5177, -0.2377,  0.2228],\n",
       "                      [ 0.1103,  0.1349,  0.4890,  0.3527,  0.0660],\n",
       "                      [ 0.0250, -0.0797, -0.2141,  0.0243,  0.0511],\n",
       "                      [-0.3591, -0.4367, -0.2663, -0.3177, -0.1018],\n",
       "                      [ 0.0740, -0.3691, -0.1955, -0.2974, -0.2060],\n",
       "                      [ 0.4069,  0.1485, -0.4036,  0.1674, -0.2197],\n",
       "                      [-0.2402, -0.4507, -0.0917,  0.2876,  0.1590],\n",
       "                      [ 0.4173,  0.2370, -0.3375,  0.0564,  0.1278],\n",
       "                      [ 0.0111, -0.0725,  0.2003, -0.2293,  0.1565],\n",
       "                      [ 0.1807,  0.6240,  0.3554, -0.3125, -0.2494],\n",
       "                      [ 0.0284, -0.2425, -0.2189, -0.1109, -0.0828],\n",
       "                      [ 0.1114,  0.0901, -0.3234, -0.1055,  0.0656],\n",
       "                      [-0.3856, -0.5179,  0.0685,  0.1002, -0.2194],\n",
       "                      [-0.3777, -0.3699, -0.4680, -0.1083, -0.2665],\n",
       "                      [ 0.1547,  0.6416,  0.2032, -0.1377,  0.2134],\n",
       "                      [-0.3235, -0.1713, -0.2430,  0.3123, -0.0120],\n",
       "                      [ 0.0452,  0.0333,  0.1796, -0.1291, -0.1167],\n",
       "                      [ 0.1949,  0.5191,  0.2493, -0.0389, -0.1115],\n",
       "                      [-0.0575,  0.3855,  0.6115,  0.0808, -0.1879],\n",
       "                      [-0.4828, -0.3844,  0.2603, -0.1607,  0.2353],\n",
       "                      [-0.0044,  0.0653,  0.3483,  0.3473,  0.1101],\n",
       "                      [-0.0601,  0.4179,  0.1086,  0.2150,  0.1569],\n",
       "                      [-0.1659,  0.5302,  0.4838, -0.2114, -0.2596],\n",
       "                      [ 0.2102,  0.1182, -0.2083, -0.2416, -0.0433],\n",
       "                      [-0.3400,  0.0460,  0.0715,  0.1072, -0.0207]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.0540,  0.4019, -0.0352, -0.1232, -0.1309, -0.1846, -0.1597, -0.0719,\n",
       "                      -0.1221, -0.1207,  0.0215, -0.1495, -0.1527,  0.0558,  0.0778, -0.3758,\n",
       "                      -0.0701, -0.2706,  0.1363, -0.2008,  0.2474,  0.2924, -0.3213,  0.0112,\n",
       "                      -0.1071,  0.0182, -0.2942, -0.0023,  0.1434, -0.1814,  0.1282,  0.2293],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.3520, -0.2467,  0.1214,  ...,  0.1434,  0.0374,  0.0038],\n",
       "                      [-0.2447, -0.0669, -0.1399,  ...,  0.0801,  0.0248,  0.0914],\n",
       "                      [-0.0623, -0.0128,  0.0966,  ...,  0.0194,  0.0297, -0.2098],\n",
       "                      ...,\n",
       "                      [-0.1841, -0.1684, -0.1372,  ...,  0.1359, -0.1675, -0.0573],\n",
       "                      [ 0.2876,  0.0979,  0.4298,  ...,  0.0208,  0.0652, -0.1935],\n",
       "                      [ 0.1216,  0.0700, -0.1700,  ...,  0.0453,  0.0104, -0.1146]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.0470,  0.1249, -0.0861,  ..., -0.0714, -0.2498, -0.0314],\n",
       "                      [ 0.1172,  0.0135,  0.0724,  ...,  0.1981,  0.0289, -0.0933],\n",
       "                      [ 0.2798, -0.1029, -0.0512,  ..., -0.2505,  0.1897, -0.1338],\n",
       "                      ...,\n",
       "                      [ 0.0845, -0.1617,  0.0931,  ..., -0.0843, -0.1191, -0.0494],\n",
       "                      [-0.0880,  0.2290,  0.1512,  ..., -0.0065, -0.1732, -0.1909],\n",
       "                      [ 0.2784, -0.2916, -0.0269,  ...,  0.0489,  0.0331, -0.0684]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.1727,  0.1092,  0.1193,  0.0975, -0.0381,  0.0342,  0.1268, -0.1595,\n",
       "                       0.1163,  0.0503,  0.1711, -0.0880,  0.1482, -0.0576,  0.0776,  0.0163,\n",
       "                      -0.0395, -0.0956, -0.0930,  0.1879, -0.0771, -0.0464, -0.0849, -0.0337,\n",
       "                       0.0883,  0.0296, -0.0218, -0.0618,  0.1653,  0.0057, -0.0527, -0.0991],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.0936, -0.0699,  0.0592,  0.0962, -0.0144, -0.1631,  0.1370, -0.1290,\n",
       "                      -0.1554, -0.0415,  0.1315,  0.1546, -0.1666,  0.0170,  0.0308, -0.0903,\n",
       "                       0.0126, -0.0650, -0.0274,  0.2071,  0.0113, -0.1119,  0.0086, -0.0105,\n",
       "                      -0.1630,  0.0928, -0.0712,  0.0117, -0.0747, -0.0729, -0.0793,  0.0742],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.0477, -0.0532,  0.1342, -0.0327, -0.0826, -0.3027,  0.2345,  0.1194,\n",
       "                       -0.1267, -0.0319, -0.0183, -0.0595, -0.2260,  0.0113, -0.1125,  0.0900,\n",
       "                       -0.1676,  0.1786, -0.0276,  0.0114, -0.0668, -0.0207,  0.3450,  0.4875,\n",
       "                       -0.2197, -0.1522, -0.0066,  0.0801, -0.0939,  0.0817, -0.1096,  0.1861]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.1853], device='cuda:0'))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66a81f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e88bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4ccf4",
   "metadata": {},
   "source": [
    "Above is an example of the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05ee5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebe3da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7c6fe87b80>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b72925",
   "metadata": {},
   "source": [
    "## Try to normalize only the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2324a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68516afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae9de7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "509b7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4056c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0a66b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.3960013389587402  epoch  1 has training loss  tensor(284.9402, device='cuda:0')  and validation loss  tensor(12.9999, device='cuda:0') .\n",
      "\n",
      "At  12.366611242294312  epoch  5 has training loss  tensor(23.0415, device='cuda:0')  and validation loss  tensor(13.2517, device='cuda:0') .\n",
      "\n",
      "At  25.075587034225464  epoch  10 has training loss  tensor(14.2988, device='cuda:0')  and validation loss  tensor(4.0947, device='cuda:0') .\n",
      "\n",
      "At  37.931830406188965  epoch  15 has training loss  tensor(11.1785, device='cuda:0')  and validation loss  tensor(10.6493, device='cuda:0') .\n",
      "\n",
      "At  51.06553649902344  epoch  20 has training loss  tensor(8.5535, device='cuda:0')  and validation loss  tensor(4.9181, device='cuda:0') .\n",
      "\n",
      "At  64.10282301902771  epoch  25 has training loss  tensor(7.1558, device='cuda:0')  and validation loss  tensor(6.0890, device='cuda:0') .\n",
      "\n",
      "At  76.88521456718445  epoch  30 has training loss  tensor(8.1487, device='cuda:0')  and validation loss  tensor(6.0491, device='cuda:0') .\n",
      "\n",
      "At  89.54181432723999  epoch  35 has training loss  tensor(7.0531, device='cuda:0')  and validation loss  tensor(3.3039, device='cuda:0') .\n",
      "\n",
      "At  102.12669515609741  epoch  40 has training loss  tensor(6.5249, device='cuda:0')  and validation loss  tensor(2.0817, device='cuda:0') .\n",
      "\n",
      "At  114.96764969825745  epoch  45 has training loss  tensor(6.3755, device='cuda:0')  and validation loss  tensor(7.7941, device='cuda:0') .\n",
      "\n",
      "At  127.87263512611389  epoch  50 has training loss  tensor(6.8019, device='cuda:0')  and validation loss  tensor(3.2662, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 31  with validation loss:  tensor(0.7778, device='cuda:0') .\n",
      " The total number of epoch trained is  51 .\n",
      " Training completed in:  130.40415477752686 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.3186,  0.1845, -0.1395, -0.1375, -0.1039],\n",
       "                      [ 0.0506,  0.0708,  0.4410, -0.2497, -0.1732],\n",
       "                      [-0.0100, -0.0899,  0.0360, -0.0640, -0.0462],\n",
       "                      [-0.0792, -0.0444,  0.3355, -0.2384,  0.0049],\n",
       "                      [-0.0320,  0.6086, -0.0610, -0.1013, -0.1538],\n",
       "                      [-0.2306, -0.2493, -0.2432,  0.1330,  0.1080],\n",
       "                      [-0.0303,  0.0970, -0.2825, -0.0410,  0.0820],\n",
       "                      [ 0.0065, -0.2076, -0.1258, -0.0473, -0.0814],\n",
       "                      [-0.0928,  0.1704, -0.2404, -0.0216, -0.1829],\n",
       "                      [ 0.0984, -0.3246,  0.3306,  0.0594,  0.0576],\n",
       "                      [-0.0158,  0.1499, -0.3494,  0.1280,  0.1238],\n",
       "                      [-0.2787,  0.1843, -0.2477,  0.0438,  0.0326],\n",
       "                      [ 0.0289, -0.2880, -0.1902,  0.1362, -0.1995],\n",
       "                      [-0.0215, -0.4013,  0.2752, -0.1539, -0.0789],\n",
       "                      [-0.3304, -0.1368,  0.0079,  0.2691,  0.3504],\n",
       "                      [-0.0262,  0.0205, -0.2115,  0.1077,  0.0193],\n",
       "                      [-0.0050, -0.0199,  0.1080,  0.0127,  0.0636],\n",
       "                      [-0.0067, -0.2681, -0.5099,  0.0198,  0.0760],\n",
       "                      [ 0.0829, -0.3406, -0.3552,  0.1072, -0.1417],\n",
       "                      [-0.0195, -0.1177, -0.3892, -0.0868,  0.0165],\n",
       "                      [ 0.0017,  0.1403,  0.1484,  0.2051, -0.0417],\n",
       "                      [-0.0043,  0.1303, -0.2870, -0.2729, -0.0661],\n",
       "                      [ 0.1893, -0.3428, -0.0154,  0.0959, -0.1196],\n",
       "                      [ 0.2160, -0.3141, -0.0782,  0.1716,  0.1347],\n",
       "                      [-0.0390,  0.2099, -0.4074, -0.3473, -0.0969],\n",
       "                      [ 0.2390,  0.2866, -0.1904,  0.4481,  0.2281],\n",
       "                      [-0.0876,  0.4984, -0.1813,  0.2878, -0.0767],\n",
       "                      [-0.0256,  0.2677,  0.3138, -0.0411,  0.0575],\n",
       "                      [-0.0643,  0.2452,  0.2947, -0.2726, -0.0655],\n",
       "                      [ 0.2716, -0.4535, -0.2223,  0.3118,  0.2343],\n",
       "                      [ 0.0379,  0.0793,  0.1844,  0.2390, -0.0084],\n",
       "                      [-0.0062, -0.1132, -0.1926,  0.4163,  0.1402]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-2.8421e-01, -4.9164e-04,  1.2385e-02,  3.7537e-02,  4.4712e-03,\n",
       "                      -1.3767e-01,  1.0507e-02, -8.6248e-03, -2.8511e-01, -3.7007e-01,\n",
       "                       1.7357e-02,  6.4282e-03, -3.2070e-01,  2.7562e-01, -2.3769e-01,\n",
       "                      -1.3616e-02,  3.0085e-03,  8.8650e-03,  4.5609e-01, -2.8112e-06,\n",
       "                      -2.4201e-02, -3.0159e-01, -1.8396e-01,  4.2549e-01,  2.1672e-03,\n",
       "                       2.1722e-01, -1.6849e-01,  1.6110e-02,  2.7044e-03, -2.4376e-01,\n",
       "                       4.9393e-03, -3.2013e-03], device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.0694,  0.1284,  0.1407,  ...,  0.0052,  0.1849,  0.0107],\n",
       "                      [ 0.1218, -0.1971, -0.0103,  ..., -0.0459, -0.1914,  0.2615],\n",
       "                      [ 0.1384,  0.2077, -0.0489,  ...,  0.0726, -0.1110,  0.0085],\n",
       "                      ...,\n",
       "                      [-0.1534,  0.0414,  0.0195,  ..., -0.1828, -0.0489, -0.2548],\n",
       "                      [ 0.1528,  0.0595,  0.3098,  ..., -0.0553, -0.0545, -0.0525],\n",
       "                      [-0.0834,  0.1225,  0.1977,  ...,  0.1576,  0.1489, -0.1091]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.7438,  0.0224, -0.2332,  ...,  0.1818, -0.0914, -0.2801],\n",
       "                      [-0.1361, -0.4050, -0.0157,  ...,  0.0152,  0.3700,  0.0168],\n",
       "                      [-0.2603,  0.0708, -0.8954,  ..., -0.0911, -0.0879, -0.0035],\n",
       "                      ...,\n",
       "                      [ 0.0315,  0.0364,  0.2788,  ..., -0.2528, -0.0624,  0.2178],\n",
       "                      [-0.0406,  0.4060,  0.1274,  ..., -0.0673, -0.3887,  0.0360],\n",
       "                      [-0.2719, -0.0825, -0.2872,  ..., -0.0713, -0.0548, -0.3814]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0378,  0.0419, -0.0738,  0.1453,  0.1272,  0.1514, -0.0679, -0.1102,\n",
       "                      -0.1000,  0.0750,  0.0714,  0.0212, -0.1240,  0.0679, -0.0928,  0.1017,\n",
       "                       0.0575, -0.0113,  0.0561, -0.1153,  0.1033, -0.1168,  0.1457, -0.0107,\n",
       "                      -0.0393, -0.1163,  0.0248,  0.0564,  0.0865, -0.1102,  0.0955,  0.0751],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.1276, -0.0332, -0.1605, -0.0847, -0.1761, -0.0259, -0.0955, -0.0449,\n",
       "                      -0.0986, -0.1136,  0.2323,  0.1199, -0.1372,  0.1252,  0.0405,  0.1195,\n",
       "                      -0.1242, -0.0904,  0.1502,  0.0751,  0.1230, -0.1175,  0.0566,  0.0693,\n",
       "                       0.1790, -0.0774,  0.1726,  0.0395,  0.0599, -0.0682, -0.1679, -0.1446],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 3.8919e-05, -3.7087e-03, -1.8533e-04, -6.9074e-04, -6.7908e-04,\n",
       "                       -2.1202e-04,  3.0530e-04, -6.9434e-04, -4.2912e-04, -3.8835e-03,\n",
       "                        1.2531e-01,  6.9252e-03,  7.0874e-04,  1.5387e-03, -1.7137e-04,\n",
       "                        4.3941e-04, -7.2169e-03, -1.1279e-03, -6.8791e-03,  5.1957e-03,\n",
       "                        8.1878e-03,  2.0954e-04, -4.0472e-03,  5.7564e-03,  5.7594e-04,\n",
       "                       -1.0700e-04,  4.5241e-04, -3.3318e-04,  5.8779e-04, -6.1166e-03,\n",
       "                       -8.5497e-03, -6.3939e-03]], device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.0977], device='cuda:0'))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7684d",
   "metadata": {},
   "source": [
    "As a remark, I ran above loop twice, the keep learning to same model after the fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef1351bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2bb082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1802af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b022072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7c7a000e80>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb605a91",
   "metadata": {},
   "source": [
    "It appears that only normalizing input ts is not a good idea. I should consider normalizing both the input and the target. Plus, in above, I fit transformed on both the training and the test set together, that is technically a data leak. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef78913",
   "metadata": {},
   "source": [
    "## Training with normalization on both input and target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64325299",
   "metadata": {},
   "source": [
    "I have added normalization functionality to dataset creation function, so not we can create the train and test datasets without dataleaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c3ffa765",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1190590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2a6245db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n",
      "Notice: target has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict={\"sub_int_RV\":None,\"target\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d97d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8b790b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_feat_dict=copy.deepcopy(train_dataset.feat_norm_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "40163bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0038471398027541486), np.float64(0.0029489987966883967))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict.pop(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "630660e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee121136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131))}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622afc7",
   "metadata": {},
   "source": [
    "As a reminder, do not apply normalization to target of test set. I am choosing to force the target input features to share the same mean and std as the test dataset's corresponding features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "de12b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict=test_norm_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0f6a5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c799fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f5ab2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.496488571166992  epoch  1 has training loss  tensor(0.3740, device='cuda:0')  and validation loss  tensor(0.2811, device='cuda:0') .\n",
      "\n",
      "At  12.812148094177246  epoch  5 has training loss  tensor(0.2693, device='cuda:0')  and validation loss  tensor(0.2372, device='cuda:0') .\n",
      "\n",
      "At  25.671175956726074  epoch  10 has training loss  tensor(0.2597, device='cuda:0')  and validation loss  tensor(0.2382, device='cuda:0') .\n",
      "\n",
      "At  38.55030798912048  epoch  15 has training loss  tensor(0.2576, device='cuda:0')  and validation loss  tensor(0.2377, device='cuda:0') .\n",
      "\n",
      "At  51.40321445465088  epoch  20 has training loss  tensor(0.2570, device='cuda:0')  and validation loss  tensor(0.2516, device='cuda:0') .\n",
      "\n",
      "At  64.32748532295227  epoch  25 has training loss  tensor(0.2563, device='cuda:0')  and validation loss  tensor(0.2365, device='cuda:0') .\n",
      "\n",
      "At  77.1183078289032  epoch  30 has training loss  tensor(0.2559, device='cuda:0')  and validation loss  tensor(0.2402, device='cuda:0') .\n",
      "\n",
      "At  90.0968804359436  epoch  35 has training loss  tensor(0.2551, device='cuda:0')  and validation loss  tensor(0.2398, device='cuda:0') .\n",
      "\n",
      "At  103.2206711769104  epoch  40 has training loss  tensor(0.2549, device='cuda:0')  and validation loss  tensor(0.2369, device='cuda:0') .\n",
      "\n",
      "At  116.29850935935974  epoch  45 has training loss  tensor(0.2553, device='cuda:0')  and validation loss  tensor(0.2368, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 29  with validation loss:  tensor(0.2360, device='cuda:0') .\n",
      " The total number of epoch trained is  49 .\n",
      " Training completed in:  126.611079454422 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 6.3097e-03,  2.0847e-01,  3.4123e-01,  2.2930e-01,  5.0760e-02],\n",
       "                      [ 3.7075e-02, -3.6896e-01, -3.7051e-01, -2.3305e-01, -1.3058e-01],\n",
       "                      [-2.6604e-01, -4.4438e-01, -2.4109e-01,  3.6088e-01,  2.7250e-01],\n",
       "                      [-3.2787e-01, -8.6684e-01, -3.5205e-01, -1.5231e-02,  1.3437e-01],\n",
       "                      [ 3.5537e-01,  2.7114e-02,  6.2167e-01, -3.6873e-02, -1.2874e-01],\n",
       "                      [-1.6656e-03,  5.3297e-03,  2.4204e-02,  2.6801e-02,  7.6921e-03],\n",
       "                      [ 2.6000e-01,  2.9354e-01,  6.4853e-02,  4.5484e-02,  5.7350e-02],\n",
       "                      [-1.4712e-01, -5.8372e-02, -2.5959e-01, -6.4162e-02, -9.6054e-02],\n",
       "                      [-2.2970e-01,  1.9180e-01,  2.1107e-01, -2.1063e-01, -1.8893e-02],\n",
       "                      [-1.5465e-01, -7.6058e-02, -1.4094e-01, -9.4835e-02, -5.8588e-02],\n",
       "                      [ 6.3576e-02, -3.2213e-01,  7.9342e-01, -2.7064e-01,  2.1241e-01],\n",
       "                      [ 3.4518e-01,  6.9660e-01,  3.0890e-01, -3.3865e-02, -1.9360e-01],\n",
       "                      [-6.0597e-04,  1.6004e-02, -5.6552e-02, -8.0925e-02, -3.4983e-02],\n",
       "                      [ 5.8018e-03,  1.9096e-01,  5.1574e-01,  3.6979e-01,  1.2190e-01],\n",
       "                      [ 3.0223e-02, -1.9333e-01, -1.9618e-01,  3.1681e-02,  5.9458e-02],\n",
       "                      [ 1.8020e-01,  6.5489e-03,  3.5287e-01,  3.7571e-01,  1.1631e-01],\n",
       "                      [ 4.5016e-02,  3.2262e-01, -2.9691e-01, -2.4535e-01,  1.8733e-02],\n",
       "                      [-2.3316e-01, -9.7209e-01, -4.2505e-01, -3.0164e-01, -2.7970e-01],\n",
       "                      [-1.6730e-01, -4.2745e-01, -2.4075e-01,  1.1649e-01,  1.4780e-02],\n",
       "                      [-6.0873e-03,  5.0115e-01,  6.3206e-01,  2.8951e-01,  5.7721e-02],\n",
       "                      [ 1.1756e-01,  2.7605e-01,  4.0333e-02, -5.8181e-02, -1.5896e-02],\n",
       "                      [-7.7373e-02,  6.1327e-01,  5.1101e-01,  1.2840e-01,  6.5859e-02],\n",
       "                      [-1.3871e-01, -4.6760e-01, -1.0116e-02,  1.2661e-01,  1.9283e-02],\n",
       "                      [ 2.4961e-01,  6.6915e-01,  1.7206e-01, -1.5142e-01, -2.7123e-01],\n",
       "                      [-2.1930e-01, -2.6762e-01,  2.2570e-01,  7.4485e-02,  1.9341e-01],\n",
       "                      [-2.3405e-03, -3.9814e-01, -5.1305e-01, -2.3372e-01, -1.5872e-02],\n",
       "                      [-6.7660e-03,  5.8546e-02, -3.4921e-02, -1.1028e-01, -5.0620e-02],\n",
       "                      [ 6.2539e-02,  8.5621e-01,  5.2713e-01,  1.5685e-03,  4.0907e-03],\n",
       "                      [ 8.0518e-04, -2.9206e-03,  1.8764e-02,  3.9097e-03,  8.0635e-03],\n",
       "                      [ 7.4063e-02, -2.1978e-01, -4.8218e-01,  3.2428e-01,  2.3290e-01],\n",
       "                      [ 1.1089e-01, -1.3462e-01,  1.7292e-01,  2.7938e-01,  1.3063e-01],\n",
       "                      [ 2.3396e-01, -5.3039e-01, -1.8616e-01, -1.9835e-01, -2.0767e-02]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 1.9808e-03,  2.4607e-02, -1.3593e-01, -1.6289e-01, -1.0284e-01,\n",
       "                       4.6558e-04,  1.2557e-01, -7.0555e-02, -1.2560e-01, -7.7425e-02,\n",
       "                      -1.0085e-01,  1.7708e-01,  1.5964e-04,  4.5105e-04,  1.7989e-02,\n",
       "                       9.2319e-02,  1.8484e-02, -1.0277e-01,  5.5437e-02, -6.2407e-03,\n",
       "                       6.2896e-02, -4.7279e-02, -6.8646e-02, -2.0640e-01, -1.2857e-01,\n",
       "                       1.1120e-03, -2.7652e-03,  2.7125e-02,  5.4296e-04,  4.0136e-02,\n",
       "                       5.6751e-02,  1.1310e-01], device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.0282,  0.1348,  0.0917,  ...,  0.1807, -0.0373, -0.1470],\n",
       "                      [ 0.0334, -0.1227,  0.1874,  ..., -0.1839,  0.0656,  0.1611],\n",
       "                      [ 0.0259, -0.1020, -0.0731,  ..., -0.0034,  0.0438, -0.0476],\n",
       "                      ...,\n",
       "                      [ 0.0056, -0.1914, -0.2830,  ..., -0.2030, -0.0771, -0.0169],\n",
       "                      [ 0.0575,  0.1290, -0.0420,  ..., -0.0269,  0.1149,  0.2715],\n",
       "                      [ 0.0237,  0.1411,  0.0908,  ...,  0.1550, -0.0363, -0.0183]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.1013, -0.3585, -0.1073,  ..., -0.0585, -0.0046,  0.2750],\n",
       "                      [-0.2219,  0.2446,  0.1427,  ...,  0.0360,  0.0294, -0.3045],\n",
       "                      [ 0.0507,  0.0592, -0.5959,  ...,  0.0722, -0.0034,  0.3587],\n",
       "                      ...,\n",
       "                      [ 0.0429,  0.1038,  0.1532,  ..., -0.3876, -0.1364,  0.1956],\n",
       "                      [ 0.0039,  0.1583,  0.1677,  ..., -0.0080, -0.4415,  0.0915],\n",
       "                      [-0.1026,  0.1685, -0.3879,  ..., -0.1341, -0.3116, -0.7203]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.1764,  0.0793, -0.0504,  0.0401,  0.0936, -0.0344,  0.1501,  0.0219,\n",
       "                      -0.0540,  0.1371,  0.0007,  0.0059, -0.0320,  0.0748,  0.1454, -0.0368,\n",
       "                      -0.0449, -0.0315,  0.1204, -0.0244,  0.0060,  0.0683,  0.0941, -0.0934,\n",
       "                      -0.1173, -0.0679, -0.0584,  0.1028,  0.1540,  0.0840, -0.0598,  0.0659],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.0046,  0.0830,  0.0069,  0.0626, -0.0574,  0.0760, -0.0992, -0.0110,\n",
       "                       0.0719, -0.1065, -0.0206,  0.0588, -0.0436, -0.1241, -0.1518,  0.0232,\n",
       "                      -0.0440,  0.0679, -0.1413,  0.0995, -0.0487, -0.0674, -0.0747, -0.0604,\n",
       "                       0.1229,  0.1074, -0.0284, -0.0067, -0.1346, -0.0632,  0.0848, -0.0674],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.0483, -0.0277,  0.0028, -0.0142,  0.0129, -0.0039, -0.0185, -0.0077,\n",
       "                        0.0062,  0.0041, -0.0029,  0.0027, -0.0032,  0.0086,  0.0011,  0.0046,\n",
       "                        0.0070, -0.0130, -0.0101,  0.0084,  0.0138,  0.0041, -0.0077,  0.0100,\n",
       "                       -0.0042,  0.0026,  0.0011,  0.0657,  0.0098, -0.0032,  0.0007,  0.0035]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-7.9766e-05], device='cuda:0'))])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1,norm_train_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81cbbb",
   "metadata": {},
   "source": [
    "Oh this over trained quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0703dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "20ecaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b859c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7be3343280>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.linspace(1,len(train_loss),len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44b27b",
   "metadata": {},
   "source": [
    "As of now, the best outcome comes with \"scaling\" the input timeseries by 10000. Maybe adjust the NN a bit? add some linear and conv layers after the RNN? Multiple layers of RNN? We will see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75828a2e-6f95-4c00-abf9-041bd4c645f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7e524-f3b0-41ff-accc-788f56123f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
