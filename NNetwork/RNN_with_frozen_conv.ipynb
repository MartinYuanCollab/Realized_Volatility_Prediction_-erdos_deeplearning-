{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77e9ebe",
   "metadata": {},
   "source": [
    "## RNN with frozen convolution layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b854e",
   "metadata": {},
   "source": [
    "The idea is inspired by an application of RNN in predicting if an online review (say, for a product) is positive or negative (1 or 0). Each word in the review sentence is first projected to a large dimension vector space and then sent into an RNN network sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6b66b",
   "metadata": {},
   "source": [
    "We will make use of frozen convolution layer to create derivative like features for our time series features. Then, we use the derivative values of a certain time as if a \"word\" in a \"review\", the target RV as if the \"score\" of the \"review\" to train an RNN network that predicts the target RV with the time series features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd88f7",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "907e47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12efccd",
   "metadata": {},
   "source": [
    "Below is what Yuan needed to get his gpu working, do not run if you do not need it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25b03193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3.0\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")\n",
    "\n",
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080eb42",
   "metadata": {},
   "source": [
    "## hardware setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a96751bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb26cd",
   "metadata": {},
   "source": [
    "Let's say, we have following timeseries feature (created randomly), we will create the derivative features first. As a reminder, the zero dimension is the batch size, the dimension one is channel (needed for the first convolution layer, not really a \"thing\" for time series like features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(1,1,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d5ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5577,  0.7130,  1.3506, -1.5546,  0.3281,  0.9122,  0.4965,\n",
       "           0.6177, -1.2331,  0.9436, -0.6563, -0.2899, -0.4059,  1.1815,\n",
       "          -0.5097, -0.1566, -0.7031,  1.1402,  1.0926, -0.3847,  2.3373,\n",
       "          -1.5838,  0.6909, -1.1103,  0.7288, -1.7757,  0.0241,  1.0242,\n",
       "          -0.6571,  0.1368, -1.3972,  0.7094, -1.1373,  0.3374,  1.7012,\n",
       "           2.3106, -0.9056,  0.7240, -0.4777,  1.3106,  0.7943, -0.2757,\n",
       "          -1.0394, -0.8101, -0.4421, -1.4641,  0.0069,  1.4155,  1.4152,\n",
       "           0.1695,  1.4291, -0.3199, -1.9401, -2.0056,  1.0310,  1.5263,\n",
       "          -0.7727,  1.3345, -0.4410, -1.9410]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739b2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_create_diff=training.frozen_diff_conv(n_diff=4)\n",
    "ts_diff_feature=conv_create_diff(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48f9ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.5775e-01,  7.1296e-01,  1.3506e+00, -1.5546e+00,  3.2810e-01,\n",
       "           9.1217e-01,  4.9651e-01,  6.1770e-01, -1.2331e+00,  9.4364e-01,\n",
       "          -6.5634e-01, -2.8991e-01, -4.0593e-01,  1.1815e+00, -5.0972e-01,\n",
       "          -1.5659e-01, -7.0315e-01,  1.1402e+00,  1.0926e+00, -3.8470e-01,\n",
       "           2.3373e+00, -1.5838e+00,  6.9093e-01, -1.1103e+00,  7.2877e-01,\n",
       "          -1.7757e+00,  2.4134e-02,  1.0242e+00, -6.5708e-01,  1.3678e-01,\n",
       "          -1.3972e+00,  7.0943e-01, -1.1373e+00,  3.3745e-01,  1.7012e+00,\n",
       "           2.3106e+00, -9.0558e-01,  7.2397e-01, -4.7765e-01,  1.3106e+00,\n",
       "           7.9435e-01, -2.7569e-01, -1.0394e+00, -8.1008e-01, -4.4211e-01,\n",
       "          -1.4641e+00,  6.9265e-03,  1.4155e+00,  1.4152e+00,  1.6947e-01,\n",
       "           1.4291e+00, -3.1987e-01, -1.9401e+00, -2.0056e+00,  1.0310e+00,\n",
       "           1.5263e+00, -7.7269e-01,  1.3345e+00, -4.4095e-01, -1.9410e+00],\n",
       "         [ 1.2707e+00,  6.3766e-01, -2.9052e+00,  1.8827e+00,  5.8407e-01,\n",
       "          -4.1565e-01,  1.2119e-01, -1.8508e+00,  2.1768e+00, -1.6000e+00,\n",
       "           3.6643e-01, -1.1602e-01,  1.5874e+00, -1.6912e+00,  3.5313e-01,\n",
       "          -5.4655e-01,  1.8433e+00, -4.7559e-02, -1.4773e+00,  2.7220e+00,\n",
       "          -3.9212e+00,  2.2747e+00, -1.8012e+00,  1.8390e+00, -2.5045e+00,\n",
       "           1.7998e+00,  1.0000e+00, -1.6812e+00,  7.9386e-01, -1.5339e+00,\n",
       "           2.1066e+00, -1.8467e+00,  1.4747e+00,  1.3638e+00,  6.0939e-01,\n",
       "          -3.2162e+00,  1.6295e+00, -1.2016e+00,  1.7883e+00, -5.1630e-01,\n",
       "          -1.0700e+00, -7.6369e-01,  2.2930e-01,  3.6797e-01, -1.0220e+00,\n",
       "           1.4710e+00,  1.4086e+00, -2.8634e-04, -1.2457e+00,  1.2596e+00,\n",
       "          -1.7489e+00, -1.6202e+00, -6.5531e-02,  3.0366e+00,  4.9528e-01,\n",
       "          -2.2989e+00,  2.1072e+00, -1.7755e+00, -1.5001e+00,  0.0000e+00],\n",
       "         [-6.3305e-01, -3.5429e+00,  4.7880e+00, -1.2987e+00, -9.9972e-01,\n",
       "           5.3684e-01, -1.9720e+00,  4.0276e+00, -3.7767e+00,  1.9664e+00,\n",
       "          -4.8246e-01,  1.7034e+00, -3.2786e+00,  2.0443e+00, -8.9969e-01,\n",
       "           2.3899e+00, -1.8909e+00, -1.4297e+00,  4.1994e+00, -6.6432e+00,\n",
       "           6.1959e+00, -4.0759e+00,  3.6402e+00, -4.3435e+00,  4.3043e+00,\n",
       "          -7.9981e-01, -2.6813e+00,  2.4751e+00, -2.3278e+00,  3.6405e+00,\n",
       "          -3.9533e+00,  3.3214e+00, -1.1095e-01, -7.5438e-01, -3.8256e+00,\n",
       "           4.8457e+00, -2.8312e+00,  2.9899e+00, -2.3046e+00, -5.5373e-01,\n",
       "           3.0635e-01,  9.9299e-01,  1.3867e-01, -1.3900e+00,  2.4930e+00,\n",
       "          -6.2478e-02, -1.4088e+00, -1.2454e+00,  2.5053e+00, -3.0085e+00,\n",
       "           1.2869e-01,  1.5547e+00,  3.1022e+00, -2.5413e+00, -2.7942e+00,\n",
       "           4.4062e+00, -3.8827e+00,  2.7543e-01,  0.0000e+00,  0.0000e+00],\n",
       "         [-2.9099e+00,  8.3309e+00, -6.0866e+00,  2.9893e-01,  1.5366e+00,\n",
       "          -2.5089e+00,  5.9996e+00, -7.8043e+00,  5.7432e+00, -2.4489e+00,\n",
       "           2.1859e+00, -4.9820e+00,  5.3229e+00, -2.9440e+00,  3.2895e+00,\n",
       "          -4.2807e+00,  4.6112e-01,  5.6291e+00, -1.0843e+01,  1.2839e+01,\n",
       "          -1.0272e+01,  7.7161e+00, -7.9837e+00,  8.6478e+00, -5.1041e+00,\n",
       "          -1.8815e+00,  5.1564e+00, -4.8029e+00,  5.9683e+00, -7.5938e+00,\n",
       "           7.2748e+00, -3.4324e+00, -6.4343e-01, -3.0712e+00,  8.6713e+00,\n",
       "          -7.6769e+00,  5.8211e+00, -5.2945e+00,  1.7509e+00,  8.6008e-01,\n",
       "           6.8664e-01, -8.5432e-01, -1.5286e+00,  3.8830e+00, -2.5555e+00,\n",
       "          -1.3464e+00,  1.6340e-01,  3.7508e+00, -5.5139e+00,  3.1372e+00,\n",
       "           1.4260e+00,  1.5474e+00, -5.6435e+00, -2.5288e-01,  7.2004e+00,\n",
       "          -8.2889e+00,  4.1581e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 1.1241e+01, -1.4417e+01,  6.3855e+00,  1.2376e+00, -4.0454e+00,\n",
       "           8.5084e+00, -1.3804e+01,  1.3547e+01, -8.1920e+00,  4.6347e+00,\n",
       "          -7.1679e+00,  1.0305e+01, -8.2669e+00,  6.2336e+00, -7.5703e+00,\n",
       "           4.7418e+00,  5.1680e+00, -1.6472e+01,  2.3682e+01, -2.3111e+01,\n",
       "           1.7988e+01, -1.5700e+01,  1.6631e+01, -1.3752e+01,  3.2226e+00,\n",
       "           7.0378e+00, -9.9593e+00,  1.0771e+01, -1.3562e+01,  1.4869e+01,\n",
       "          -1.0707e+01,  2.7890e+00, -2.4278e+00,  1.1743e+01, -1.6348e+01,\n",
       "           1.3498e+01, -1.1116e+01,  7.0454e+00, -8.9079e-01, -1.7344e-01,\n",
       "          -1.5410e+00, -6.7431e-01,  5.4116e+00, -6.4385e+00,  1.2091e+00,\n",
       "           1.5098e+00,  3.5874e+00, -9.2647e+00,  8.6511e+00, -1.7112e+00,\n",
       "           1.2141e-01, -7.1909e+00,  5.3906e+00,  7.4533e+00, -1.5489e+01,\n",
       "           1.2447e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79075913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 60])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3354b4",
   "metadata": {},
   "source": [
    "We now permute the last two dimensions, essentially, this is just a transposition of the last two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76682d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_feature=ts_diff_feature.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed4b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cff150",
   "metadata": {},
   "source": [
    "Now, this is a batch (of size 1) of timeseries feature with 60 time steps, and 5 features in each step. We then expand the 5 features, say, to 32 by projection. As a reminder, nn.Linear automatically apply to the last dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7d96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_proj=nn.Linear(5,32)\n",
    "ts_feature_proj=linear_proj(ts_diff_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f82b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40c151",
   "metadata": {},
   "source": [
    "In this example, we will not go into too much detail, so let's make the most simple version. We then pass through a layer of RNN, then a layer of linear (to project to dimension 1 again). Learn more about RNN at https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f611ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_layer=nn.RNN(input_size=32,hidden_size=32,num_layers=1,nonlinearity=\"tanh\",batch_first=True,dropout=0)\n",
    "linear_end=nn.Linear(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207568f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_out=RNN_layer(ts_feature_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc91386",
   "metadata": {},
   "source": [
    "As a reminder, since no training is done, the RNN basically just applies the initial weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f31dfe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e423255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_proj=linear_end(RNN_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba4ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22784470",
   "metadata": {},
   "source": [
    "We will use sum, but we may change this to other functions, according to context or just feeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e293bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_out=torch.sum(out_proj,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35c7bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.7825]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9f52c",
   "metadata": {},
   "source": [
    "## Creating the actual NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d007bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created 07/02/25\n",
    "#07/02/25: Moved to training.py \n",
    "#07/08/25: Moved from training.py\n",
    "class RV_RNN_conv(nn.Module):        \n",
    "    #Created 07/02/25 see RNN_with_frozen_conv.ipynb for documentation. \n",
    "    #Modified 07/08/25 Added LSTM and GRU options\n",
    "    def __init__(self,n_diff,rnn_num_layer,rnn_drop_out,rnn_type=\"rnn\",rnn_act=\"tanh\",proj_dim=32,rnn_hidden_size=32,input_scaler=10000):\n",
    "        \"\"\"\n",
    "        :param n_diff: Decides how many derivative features is wanted in the time series. \n",
    "        :param rnn_num_layer: num_layer parameter for rnn. \n",
    "        :param rnn_drop_out: dropout parameter for rnn. \n",
    "        :param rnn_act: Defaulted to \"tanh\". Nonlinearity parameter for rnn. \n",
    "        :param proj_dim: Defaulted to 32. Decided the dimension of projection before feeding into rnn. \n",
    "        :param rnn_hidden_size: Defaulted to 32. The hidden_size parameter for rnn. \n",
    "        :param input_scaler: Defaulted to 10000. Set a scaling to input, a lot of timeseries values of our data are extremely close to zero. \n",
    "        :param rnn_type: 'rnn', 'lstm', or 'gru'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_scaler=input_scaler\n",
    "        self.frozen_conv=frozen_diff_conv(n_diff=n_diff)\n",
    "        self.linear_proj_input=nn.Linear(n_diff+1,proj_dim)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == \"rnn\":\n",
    "            self.RNN_layer=nn.RNN(input_size=proj_dim,\n",
    "                                  hidden_size=rnn_hidden_size,\n",
    "                                  num_layers=rnn_num_layer,\n",
    "                                  nonlinearity=rnn_act,\n",
    "                                  batch_first=True,\n",
    "                                  dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='lstm'\")\n",
    "            self.RNN_layer = nn.LSTM(input_size=proj_dim,\n",
    "                                     hidden_size=rnn_hidden_size,\n",
    "                                     num_layers=rnn_num_layer,\n",
    "                                     batch_first=True,\n",
    "                                     dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"gru\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='gru'\")\n",
    "            self.RNN_layer = nn.GRU(input_size=proj_dim,\n",
    "                                    hidden_size=rnn_hidden_size,\n",
    "                                    num_layers=rnn_num_layer,\n",
    "                                    batch_first=True,\n",
    "                                    dropout=rnn_drop_out)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported rnn_type: {rnn_type}\")\n",
    "        \n",
    "        self.linear_post_rnn=nn.Linear(rnn_hidden_size,1)\n",
    "        self.frozen_list=[\"frozen_conv\"] \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #First, scale the input, and unsqueese to add in one dimension in dim 1 as channel. This is needed for convolution. \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1)\n",
    "        x=self.frozen_conv(x)\n",
    "        x=x.permute(0,2,1)\n",
    "        x=self.linear_proj_input(x)\n",
    "        x=self.RNN_layer(x)[0]\n",
    "        x=self.linear_post_rnn(x)\n",
    "        \n",
    "        return torch.sum(x,dim=1)/self.input_scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71432b31",
   "metadata": {},
   "source": [
    "## Basic testing on the RNN with frozen convolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9583750",
   "metadata": {},
   "source": [
    "Test it first. As a reminder, the expected input dimensions are (Batch Size, Time Series Length), this is distinct from the example above in that the channel dimension is not present. The channel dimension is added with unsqueeze at dimension 1 so that the first convolution layer can be utilized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df3d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(10,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a33fd643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3691,  0.6008, -0.7491,  0.6827, -0.0298, -0.6829,  1.1673, -0.9580,\n",
       "         -0.0426,  0.9583, -0.6718,  0.8255, -0.6608, -1.0352,  0.0733, -0.5476,\n",
       "         -0.2988,  1.1749, -0.9487, -1.5452,  0.5344,  0.4224, -0.3108, -0.2225,\n",
       "          1.0031,  0.0261,  0.3297, -0.5437, -2.6797, -0.7719, -0.3952,  1.5811,\n",
       "          0.3911, -0.0708, -0.9342, -0.1704, -0.8037, -0.1527, -0.2513,  1.2018,\n",
       "          0.4559, -0.5213,  0.9909, -0.5318,  1.1439,  0.3972,  0.5222,  0.1130,\n",
       "         -0.0846,  0.9227,  0.0876, -1.0440, -0.9952,  1.0073,  1.1305,  0.9681,\n",
       "          0.4329,  0.2897, -1.4206,  0.2871],\n",
       "        [ 0.6732,  1.4589, -0.0327,  2.3941,  0.1705,  1.4748,  0.1476,  0.4469,\n",
       "         -0.5629, -0.6084, -0.1726, -0.5009,  0.2859, -0.2576, -0.2342,  0.7011,\n",
       "         -0.3509,  1.1059, -1.0635,  1.4440, -1.6945,  0.8974, -0.1783,  2.0359,\n",
       "          0.3362,  0.8404, -0.5280, -0.6305, -1.5888,  0.3255, -1.4203, -0.6525,\n",
       "          1.1098,  0.2628, -1.3003, -0.3188, -0.8202,  0.6200,  0.2621, -1.4408,\n",
       "          0.7445, -0.9997,  0.8704, -0.1545, -0.0922,  0.1268, -0.2153, -2.3220,\n",
       "          0.6466, -2.4672, -0.3287, -0.5903, -0.5237,  1.0507,  0.8610, -1.1270,\n",
       "          1.0529,  0.9758,  0.2571,  1.9535],\n",
       "        [ 1.0861,  0.5497, -1.3839,  0.4508, -0.6564,  0.1700,  0.2525,  0.4555,\n",
       "          1.8633, -1.2849, -0.6529, -1.4887,  1.1636,  0.0212,  1.1645, -0.3941,\n",
       "          0.9381, -0.4916,  1.4178,  0.4822,  0.0690,  0.2961,  0.1532, -0.3336,\n",
       "         -1.7279,  0.7010, -1.1445, -0.0315,  0.7724,  1.2425,  0.4189,  1.2639,\n",
       "          0.3416, -0.7222,  0.2914, -0.9067, -0.2629, -0.9623, -0.1402, -0.0396,\n",
       "         -0.7500,  1.1090,  0.2011, -0.8695, -0.1170, -0.9332,  2.4818,  2.1298,\n",
       "          0.6066, -1.1389,  1.0964,  0.6335,  0.5581,  0.6218,  0.6091,  0.5516,\n",
       "         -0.1632,  0.8144, -0.4217,  0.0114],\n",
       "        [ 0.4595,  0.9659,  0.1610, -0.5622,  0.5417, -0.5678,  0.6287,  0.7672,\n",
       "         -0.2987, -0.0907, -0.0990, -0.6882,  0.4402, -0.5562, -0.8176,  0.3934,\n",
       "          0.5093, -0.3707,  1.5168,  0.7252, -0.6975, -0.1405, -0.1680,  0.3832,\n",
       "          1.0597,  1.1802,  0.3509,  0.4478,  0.9207, -0.5212, -1.4589, -0.6694,\n",
       "         -0.0347,  0.5371, -1.0062, -0.8882, -1.5295,  1.0920,  0.1964,  1.4773,\n",
       "         -0.6533,  1.0983,  0.4911,  1.0911, -0.6860,  0.2176, -1.8270, -1.5279,\n",
       "         -0.6996, -1.1056, -1.2394,  0.4600, -1.6362,  0.2639,  1.1026, -1.0102,\n",
       "         -2.5016, -0.1081, -0.5574, -0.0498],\n",
       "        [ 0.5056,  0.1381,  0.2090,  0.8820, -1.0065,  1.9709, -0.1182, -0.6180,\n",
       "         -0.3265,  0.3947, -0.9126,  0.3644,  1.3110,  0.6638, -0.9343, -0.7084,\n",
       "         -0.7896,  0.7810,  1.5722, -1.3955, -1.0381,  0.1539,  2.2668,  0.2574,\n",
       "          1.0893, -0.1177,  0.7494,  0.6302,  0.4432,  1.6237,  0.2176, -0.7455,\n",
       "          0.3468,  1.4508, -0.6390,  0.3485,  0.9291, -0.7589, -0.6130, -2.0083,\n",
       "          1.6124, -0.2779, -1.2093, -0.0114, -0.2377,  0.0313,  0.6478, -0.1876,\n",
       "         -0.0524,  0.9096,  0.7771,  2.3679, -0.1339, -0.6659, -0.7560, -1.3376,\n",
       "         -0.6319, -0.4097,  1.2842,  0.8555],\n",
       "        [-1.2133, -1.3011, -1.9129, -0.1595, -1.3009,  0.5087,  0.4163, -0.7921,\n",
       "         -0.2978,  0.4145, -0.6629,  0.8996, -0.9207,  0.4256,  1.4870,  1.2506,\n",
       "         -0.3056,  0.3635,  0.2168, -0.1546,  1.4009, -0.4223, -0.2513, -0.8067,\n",
       "          0.3628,  0.5334,  0.4940, -0.7970, -0.9755, -0.6541, -1.2464,  1.5779,\n",
       "          2.0305,  0.7935, -0.4192,  0.2824,  1.1964, -0.2610,  0.0755,  1.3426,\n",
       "         -0.6929,  0.4034,  0.6220, -0.1843, -1.0114,  0.6420,  0.1394, -1.5182,\n",
       "         -1.1340, -0.0654,  0.1095,  0.3847,  0.9402,  0.9401,  0.9055, -0.4193,\n",
       "         -1.2463,  1.8386, -1.5116,  0.9555],\n",
       "        [ 0.5988,  0.6070, -0.9295, -1.8738,  0.6498,  0.5782, -0.5457, -1.3630,\n",
       "         -0.5465,  1.0459, -2.0164,  0.1721,  2.2047, -0.4809,  1.3311,  0.0709,\n",
       "          0.7807, -1.4615, -0.2352,  0.7575, -0.9625, -0.0290,  0.0846, -1.0619,\n",
       "         -0.6167,  0.2850,  0.3681, -0.1910, -0.0785,  0.9353, -1.9950,  0.2453,\n",
       "         -0.4173, -0.7832,  1.6126, -0.0674, -0.0768, -0.3831, -0.1042,  0.0309,\n",
       "          0.9108,  1.2738, -2.2581, -0.6676,  0.0099,  1.3548,  1.3692,  1.1654,\n",
       "          1.5481, -0.4213,  0.5553,  1.4298, -0.8512,  0.5518,  0.1855,  0.5961,\n",
       "          0.0306, -0.6607,  0.3637,  2.4329],\n",
       "        [ 0.2806, -0.3968,  0.1002, -0.3026,  1.3892,  0.8731, -0.1606,  0.5047,\n",
       "         -0.2921, -0.5726,  0.6186,  0.5189, -0.1881, -1.1910, -0.8989, -0.1859,\n",
       "          0.2642,  1.2291,  2.1685,  0.1762, -0.8726,  0.7421, -0.4455, -0.4742,\n",
       "         -0.8099, -0.4739, -0.1801,  1.2127,  0.8619,  0.4181, -1.3045, -0.8461,\n",
       "          0.7105,  0.0825,  0.0225, -1.2948,  0.4610,  0.3648,  1.9555, -1.6467,\n",
       "          0.2892,  2.2143,  0.8149,  0.8783, -1.7607,  0.6659, -1.0430,  1.2865,\n",
       "         -0.0785, -1.9592,  1.2667,  0.8374, -1.4831, -0.1283, -0.9271, -1.2802,\n",
       "          0.3170,  0.8120, -0.6370,  1.2006],\n",
       "        [-0.4566, -0.5579,  0.0691, -0.7415,  0.6495,  1.3815,  0.4402, -2.1017,\n",
       "         -0.1267, -0.7263, -0.0738,  1.9137,  0.9800,  0.3562,  0.9644,  1.0397,\n",
       "         -1.3478, -0.3030,  0.5266,  0.8394, -1.2679,  0.5185,  0.6506, -1.3185,\n",
       "         -0.0333,  1.6969,  0.1191, -0.1203, -0.6605,  0.9073, -0.2739, -0.2869,\n",
       "          1.7411, -0.4761, -2.2709,  0.7408, -0.8134,  1.3001,  1.9768,  0.6491,\n",
       "         -1.2694, -0.0252, -0.6147,  0.4298,  2.4237, -1.7485,  1.4192, -1.7496,\n",
       "          2.6889, -1.1925, -0.6681,  0.1456, -1.0167, -0.6089, -1.1013,  0.9911,\n",
       "          2.4699, -0.5494, -2.6269,  0.6075],\n",
       "        [-0.1129,  0.0365,  0.3200,  0.1866,  0.5612,  1.2585,  0.4190,  1.2931,\n",
       "          0.4536, -0.1879, -0.9626, -0.4094, -1.3397,  0.3686,  1.1832, -0.8829,\n",
       "         -3.3576,  1.1667,  1.3846, -0.1838, -0.3988,  1.8529, -1.3473, -1.4966,\n",
       "          0.7963,  1.2019, -0.0081, -0.4798,  0.8431, -1.2588,  0.6576,  1.3595,\n",
       "          0.5535, -0.0392,  0.3015,  0.3844, -0.6414, -0.7390, -0.1388, -2.7719,\n",
       "         -1.1237, -0.5743, -0.2168, -0.1742,  0.6013, -0.1101, -1.2614,  0.6709,\n",
       "         -0.3900,  0.7926,  1.7043, -1.2178,  1.7427,  0.2325, -0.5153, -1.3277,\n",
       "         -1.4626,  0.1673,  0.7379,  1.1401]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72cd7276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3691,  0.6008, -0.7491,  0.6827, -0.0298, -0.6829,  1.1673,\n",
       "          -0.9580, -0.0426,  0.9583, -0.6718,  0.8255, -0.6608, -1.0352,\n",
       "           0.0733, -0.5476, -0.2988,  1.1749, -0.9487, -1.5452,  0.5344,\n",
       "           0.4224, -0.3108, -0.2225,  1.0031,  0.0261,  0.3297, -0.5437,\n",
       "          -2.6797, -0.7719, -0.3952,  1.5811,  0.3911, -0.0708, -0.9342,\n",
       "          -0.1704, -0.8037, -0.1527, -0.2513,  1.2018,  0.4559, -0.5213,\n",
       "           0.9909, -0.5318,  1.1439,  0.3972,  0.5222,  0.1130, -0.0846,\n",
       "           0.9227,  0.0876, -1.0440, -0.9952,  1.0073,  1.1305,  0.9681,\n",
       "           0.4329,  0.2897, -1.4206,  0.2871]],\n",
       "\n",
       "        [[ 0.6732,  1.4589, -0.0327,  2.3941,  0.1705,  1.4748,  0.1476,\n",
       "           0.4469, -0.5629, -0.6084, -0.1726, -0.5009,  0.2859, -0.2576,\n",
       "          -0.2342,  0.7011, -0.3509,  1.1059, -1.0635,  1.4440, -1.6945,\n",
       "           0.8974, -0.1783,  2.0359,  0.3362,  0.8404, -0.5280, -0.6305,\n",
       "          -1.5888,  0.3255, -1.4203, -0.6525,  1.1098,  0.2628, -1.3003,\n",
       "          -0.3188, -0.8202,  0.6200,  0.2621, -1.4408,  0.7445, -0.9997,\n",
       "           0.8704, -0.1545, -0.0922,  0.1268, -0.2153, -2.3220,  0.6466,\n",
       "          -2.4672, -0.3287, -0.5903, -0.5237,  1.0507,  0.8610, -1.1270,\n",
       "           1.0529,  0.9758,  0.2571,  1.9535]],\n",
       "\n",
       "        [[ 1.0861,  0.5497, -1.3839,  0.4508, -0.6564,  0.1700,  0.2525,\n",
       "           0.4555,  1.8633, -1.2849, -0.6529, -1.4887,  1.1636,  0.0212,\n",
       "           1.1645, -0.3941,  0.9381, -0.4916,  1.4178,  0.4822,  0.0690,\n",
       "           0.2961,  0.1532, -0.3336, -1.7279,  0.7010, -1.1445, -0.0315,\n",
       "           0.7724,  1.2425,  0.4189,  1.2639,  0.3416, -0.7222,  0.2914,\n",
       "          -0.9067, -0.2629, -0.9623, -0.1402, -0.0396, -0.7500,  1.1090,\n",
       "           0.2011, -0.8695, -0.1170, -0.9332,  2.4818,  2.1298,  0.6066,\n",
       "          -1.1389,  1.0964,  0.6335,  0.5581,  0.6218,  0.6091,  0.5516,\n",
       "          -0.1632,  0.8144, -0.4217,  0.0114]],\n",
       "\n",
       "        [[ 0.4595,  0.9659,  0.1610, -0.5622,  0.5417, -0.5678,  0.6287,\n",
       "           0.7672, -0.2987, -0.0907, -0.0990, -0.6882,  0.4402, -0.5562,\n",
       "          -0.8176,  0.3934,  0.5093, -0.3707,  1.5168,  0.7252, -0.6975,\n",
       "          -0.1405, -0.1680,  0.3832,  1.0597,  1.1802,  0.3509,  0.4478,\n",
       "           0.9207, -0.5212, -1.4589, -0.6694, -0.0347,  0.5371, -1.0062,\n",
       "          -0.8882, -1.5295,  1.0920,  0.1964,  1.4773, -0.6533,  1.0983,\n",
       "           0.4911,  1.0911, -0.6860,  0.2176, -1.8270, -1.5279, -0.6996,\n",
       "          -1.1056, -1.2394,  0.4600, -1.6362,  0.2639,  1.1026, -1.0102,\n",
       "          -2.5016, -0.1081, -0.5574, -0.0498]],\n",
       "\n",
       "        [[ 0.5056,  0.1381,  0.2090,  0.8820, -1.0065,  1.9709, -0.1182,\n",
       "          -0.6180, -0.3265,  0.3947, -0.9126,  0.3644,  1.3110,  0.6638,\n",
       "          -0.9343, -0.7084, -0.7896,  0.7810,  1.5722, -1.3955, -1.0381,\n",
       "           0.1539,  2.2668,  0.2574,  1.0893, -0.1177,  0.7494,  0.6302,\n",
       "           0.4432,  1.6237,  0.2176, -0.7455,  0.3468,  1.4508, -0.6390,\n",
       "           0.3485,  0.9291, -0.7589, -0.6130, -2.0083,  1.6124, -0.2779,\n",
       "          -1.2093, -0.0114, -0.2377,  0.0313,  0.6478, -0.1876, -0.0524,\n",
       "           0.9096,  0.7771,  2.3679, -0.1339, -0.6659, -0.7560, -1.3376,\n",
       "          -0.6319, -0.4097,  1.2842,  0.8555]],\n",
       "\n",
       "        [[-1.2133, -1.3011, -1.9129, -0.1595, -1.3009,  0.5087,  0.4163,\n",
       "          -0.7921, -0.2978,  0.4145, -0.6629,  0.8996, -0.9207,  0.4256,\n",
       "           1.4870,  1.2506, -0.3056,  0.3635,  0.2168, -0.1546,  1.4009,\n",
       "          -0.4223, -0.2513, -0.8067,  0.3628,  0.5334,  0.4940, -0.7970,\n",
       "          -0.9755, -0.6541, -1.2464,  1.5779,  2.0305,  0.7935, -0.4192,\n",
       "           0.2824,  1.1964, -0.2610,  0.0755,  1.3426, -0.6929,  0.4034,\n",
       "           0.6220, -0.1843, -1.0114,  0.6420,  0.1394, -1.5182, -1.1340,\n",
       "          -0.0654,  0.1095,  0.3847,  0.9402,  0.9401,  0.9055, -0.4193,\n",
       "          -1.2463,  1.8386, -1.5116,  0.9555]],\n",
       "\n",
       "        [[ 0.5988,  0.6070, -0.9295, -1.8738,  0.6498,  0.5782, -0.5457,\n",
       "          -1.3630, -0.5465,  1.0459, -2.0164,  0.1721,  2.2047, -0.4809,\n",
       "           1.3311,  0.0709,  0.7807, -1.4615, -0.2352,  0.7575, -0.9625,\n",
       "          -0.0290,  0.0846, -1.0619, -0.6167,  0.2850,  0.3681, -0.1910,\n",
       "          -0.0785,  0.9353, -1.9950,  0.2453, -0.4173, -0.7832,  1.6126,\n",
       "          -0.0674, -0.0768, -0.3831, -0.1042,  0.0309,  0.9108,  1.2738,\n",
       "          -2.2581, -0.6676,  0.0099,  1.3548,  1.3692,  1.1654,  1.5481,\n",
       "          -0.4213,  0.5553,  1.4298, -0.8512,  0.5518,  0.1855,  0.5961,\n",
       "           0.0306, -0.6607,  0.3637,  2.4329]],\n",
       "\n",
       "        [[ 0.2806, -0.3968,  0.1002, -0.3026,  1.3892,  0.8731, -0.1606,\n",
       "           0.5047, -0.2921, -0.5726,  0.6186,  0.5189, -0.1881, -1.1910,\n",
       "          -0.8989, -0.1859,  0.2642,  1.2291,  2.1685,  0.1762, -0.8726,\n",
       "           0.7421, -0.4455, -0.4742, -0.8099, -0.4739, -0.1801,  1.2127,\n",
       "           0.8619,  0.4181, -1.3045, -0.8461,  0.7105,  0.0825,  0.0225,\n",
       "          -1.2948,  0.4610,  0.3648,  1.9555, -1.6467,  0.2892,  2.2143,\n",
       "           0.8149,  0.8783, -1.7607,  0.6659, -1.0430,  1.2865, -0.0785,\n",
       "          -1.9592,  1.2667,  0.8374, -1.4831, -0.1283, -0.9271, -1.2802,\n",
       "           0.3170,  0.8120, -0.6370,  1.2006]],\n",
       "\n",
       "        [[-0.4566, -0.5579,  0.0691, -0.7415,  0.6495,  1.3815,  0.4402,\n",
       "          -2.1017, -0.1267, -0.7263, -0.0738,  1.9137,  0.9800,  0.3562,\n",
       "           0.9644,  1.0397, -1.3478, -0.3030,  0.5266,  0.8394, -1.2679,\n",
       "           0.5185,  0.6506, -1.3185, -0.0333,  1.6969,  0.1191, -0.1203,\n",
       "          -0.6605,  0.9073, -0.2739, -0.2869,  1.7411, -0.4761, -2.2709,\n",
       "           0.7408, -0.8134,  1.3001,  1.9768,  0.6491, -1.2694, -0.0252,\n",
       "          -0.6147,  0.4298,  2.4237, -1.7485,  1.4192, -1.7496,  2.6889,\n",
       "          -1.1925, -0.6681,  0.1456, -1.0167, -0.6089, -1.1013,  0.9911,\n",
       "           2.4699, -0.5494, -2.6269,  0.6075]],\n",
       "\n",
       "        [[-0.1129,  0.0365,  0.3200,  0.1866,  0.5612,  1.2585,  0.4190,\n",
       "           1.2931,  0.4536, -0.1879, -0.9626, -0.4094, -1.3397,  0.3686,\n",
       "           1.1832, -0.8829, -3.3576,  1.1667,  1.3846, -0.1838, -0.3988,\n",
       "           1.8529, -1.3473, -1.4966,  0.7963,  1.2019, -0.0081, -0.4798,\n",
       "           0.8431, -1.2588,  0.6576,  1.3595,  0.5535, -0.0392,  0.3015,\n",
       "           0.3844, -0.6414, -0.7390, -0.1388, -2.7719, -1.1237, -0.5743,\n",
       "          -0.2168, -0.1742,  0.6013, -0.1101, -1.2614,  0.6709, -0.3900,\n",
       "           0.7926,  1.7043, -1.2178,  1.7427,  0.2325, -0.5153, -1.3277,\n",
       "          -1.4626,  0.1673,  0.7379,  1.1401]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(ts_feature,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "455ed170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_num_layer=2,rnn_drop_out=0.3,rnn_hidden_size=32,proj_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85bf9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc35034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0005],\n",
       "        [-0.0005],\n",
       "        [-0.0007],\n",
       "        [-0.0006],\n",
       "        [-0.0005],\n",
       "        [-0.0003],\n",
       "        [-0.0002],\n",
       "        [-0.0004],\n",
       "        [-0.0005],\n",
       "        [-0.0008]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfbac7",
   "metadata": {},
   "source": [
    "## Training loop (basic) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b6e9b2",
   "metadata": {},
   "source": [
    "## Create train test split by time_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06d4fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "739d9a32-e68b-4f66-bd6b-0fda83803f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4294 31984 31570 ... 29316 32195 10890]\n"
     ]
    }
   ],
   "source": [
    "print(list_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "825838c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87ca970a-b88b-4b85-8337-6cf6a957e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4294, 31984, 31570, ...,  5629, 10421,  8117])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7ba8aa2-a446-4389-8d49-bca021ceb63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15516, 30276, 16402, 27182, 24497, 13529,   373,  4219, 20323,\n",
       "        9160, 28983, 17820, 22678,  7460, 29676, 32048, 22405, 31380,\n",
       "        1816, 14079, 29944, 21990, 26804, 28210, 18142, 11682, 32597,\n",
       "       13513, 32690, 27120, 27427,  7418,  1213,  9822, 29692, 24523,\n",
       "       25318,  6274, 25569, 12713,   169, 20732, 15906, 28877, 25551,\n",
       "       10745, 31320, 31714,  6076, 23656,   424,   309, 17604, 28963,\n",
       "       23144, 11872, 29219, 25357, 22828, 17569, 17955, 11920, 18509,\n",
       "       19626, 16149,  5392,  7200, 10929,  4774, 27278, 23639, 10633,\n",
       "          72, 32534, 26944, 31018, 26494,  6648,   709,  6823, 21239,\n",
       "       11995, 23265, 31883,  2711,  1350,  1321, 16282,  5046, 29875,\n",
       "        7133, 15823, 25463,  9064,  3333, 11440, 16831,  6815, 19580,\n",
       "       30620, 24014, 17193, 10708, 30597,  4367, 27962, 13010, 32254,\n",
       "       23226, 22903,  5929, 30327,  1866, 14629,  1205,  9352, 10619,\n",
       "       14234, 15276,  4091, 22752, 18653, 11453, 26708, 30183, 13986,\n",
       "           5,  7864,  9889, 31471, 26868, 10672, 31347, 15418, 30430,\n",
       "       26568, 28267,  3955,  1392, 27014, 22081, 15845, 18728,  9936,\n",
       "        5232,  2366, 26886, 30272, 11393, 30750,  7572, 21601,  2331,\n",
       "       13207, 12073,  2058, 18502, 25429, 12532, 27496,  5932,   536,\n",
       "       27595, 23185, 26752,  2683,  6585, 15131,  6144, 27042,  7743,\n",
       "       22249, 32611,  3758, 19271, 13614, 31572, 17570,  9367, 11263,\n",
       "       14285, 12981,   146,  2643, 31266, 23490,  2109, 29906, 30303,\n",
       "       12102, 32649,  8721, 26606, 32012, 16511, 30908, 19871,  3513,\n",
       "        3001, 24127, 29974, 27752, 16504,  6631,  8750,  6493, 29819,\n",
       "       12147, 13503, 11264, 31236,  8365, 23486, 13294,  1292, 17265,\n",
       "       16594, 20928, 18205,  6316,  8459, 19955,  7369, 26763, 13560,\n",
       "        3211, 31254, 13720,   152,  4844, 14738, 22548, 27886,  4131,\n",
       "        6657, 13699, 25639,  2000, 26788, 21103, 11577, 29037,  9947,\n",
       "       32134, 30341, 17112,  7548, 20265, 12533, 10262, 10616,  7512,\n",
       "       28354, 25879,  2440, 21614, 32255, 15584,  9735, 31874, 30366,\n",
       "       31047, 16507,  6906,  9396,  6217,  1521, 17378, 26091,  3318,\n",
       "       32746,  8744, 26889,  1468,  6965, 17117,   817,  3130, 14928,\n",
       "       21373, 13980, 28634,   103, 27543, 26849,  7909, 18077, 30569,\n",
       "       10105, 12178, 20491, 32704, 12923, 15393, 14976, 26168,  2867,\n",
       "       12182, 27524, 30339, 18285, 28474, 27981, 13928, 10892, 14909,\n",
       "       21024, 25971,  9266, 25277,  5425, 17454,  3962, 14449, 31389,\n",
       "       17672,  9887, 20669,  4089, 19512, 30212, 11151, 22912, 25359,\n",
       "       29947, 31348, 16731,  1948,  6730, 14176,  2656, 15728,  8573,\n",
       "       21762,  6359,  5846, 12521, 26578,  8623,  9096, 23423, 22513,\n",
       "       23539, 17528,  5663, 24021, 32240, 28635,  2553, 13791, 22427,\n",
       "       19647, 26170,  2718, 28192, 19065,  2136, 29679,  9028, 17120,\n",
       "       25312,   618, 18184, 21658, 13627, 25338, 31402, 24406, 31331,\n",
       "        7759,  3123,  2027, 18703, 28837, 11718, 13579, 10455, 10604,\n",
       "       24913, 15365, 29316, 32195, 10890])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72aedca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0be6b5",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943d38f",
   "metadata": {},
   "source": [
    "## - First, feature data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3338fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99d692",
   "metadata": {},
   "source": [
    "## - In the follow exploratory normalization is done, this is all exploratory, leave the normalization to the dataset creation function is better. DO NOT feed pre-normalized data into the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62e2f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9cf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e42729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts[\"sub_int_RV_norm\"]=scalar.fit_transform(df_RV_ts[[\"sub_int_RV\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "995d9083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>sub_int_RV</th>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sub_int_RV_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-5</td>\n",
       "      <td>-0.208285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-11</td>\n",
       "      <td>-0.453866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-16</td>\n",
       "      <td>-0.569259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-31</td>\n",
       "      <td>-0.428690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-62</td>\n",
       "      <td>-0.540259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735915</th>\n",
       "      <td>32686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32686</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735916</th>\n",
       "      <td>32690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32690</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735917</th>\n",
       "      <td>32712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32712</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735918</th>\n",
       "      <td>32746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32746</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735919</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25735920 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time_id  sub_int_RV  sub_int_num  stock_id     row_id  \\\n",
       "0               5    0.000329            1        93       93-5   \n",
       "1              11    0.000191            1        93      93-11   \n",
       "2              16    0.000126            1        93      93-16   \n",
       "3              31    0.000205            1        93      93-31   \n",
       "4              62    0.000142            1        93      93-62   \n",
       "...           ...         ...          ...       ...        ...   \n",
       "25735915    32686    0.000000           60       104  104-32686   \n",
       "25735916    32690    0.000000           60       104  104-32690   \n",
       "25735917    32712    0.000000           60       104  104-32712   \n",
       "25735918    32746    0.000000           60       104  104-32746   \n",
       "25735919    32758    0.000000           60       104  104-32758   \n",
       "\n",
       "          sub_int_RV_norm  \n",
       "0               -0.208285  \n",
       "1               -0.453866  \n",
       "2               -0.569259  \n",
       "3               -0.428690  \n",
       "4               -0.540259  \n",
       "...                   ...  \n",
       "25735915        -0.793956  \n",
       "25735916        -0.793956  \n",
       "25735917        -0.793956  \n",
       "25735918        -0.793956  \n",
       "25735919        -0.793956  \n",
       "\n",
       "[25735920 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de450e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">sub_int_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-1000</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.818799e-07</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2.313288e-04</td>\n",
       "      <td>1.060893e-05</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10000</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>3.154886e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>4.375100e-04</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>2.552987e-03</td>\n",
       "      <td>5.364106e-04</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10017</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>6.771948e-05</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>3.104404e-03</td>\n",
       "      <td>1.224910e-03</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10030</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.586782e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>4.842470e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9972</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.503467e-04</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>9.916624e-05</td>\n",
       "      <td>1.809852e-04</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9973</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>9.650211e-04</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>1.862600e-03</td>\n",
       "      <td>7.668418e-04</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9976</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>7.203531e-04</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5.946683e-04</td>\n",
       "      <td>1.509652e-04</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9988</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.957402e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.440137e-04</td>\n",
       "      <td>3.200939e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9993</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.798617e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>2.728767e-04</td>\n",
       "      <td>2.108380e-04</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sub_int_RV                                                        \\\n",
       "sub_int_num         1         2         3         4         5             6    \n",
       "row_id                                                                         \n",
       "0-1000        0.000341  0.000000  0.000023  0.000000  0.000170  3.818799e-07   \n",
       "0-10000       0.000290  0.000191  0.000087  0.000193  0.000241  3.154886e-04   \n",
       "0-10005       0.000000  0.000000  0.001554  0.002177  0.002303  4.375100e-04   \n",
       "0-10017       0.000142  0.000142  0.001464  0.001086  0.000068  6.771948e-05   \n",
       "0-10030       0.000327  0.000058  0.000293  0.000842  0.000120  2.586782e-04   \n",
       "...                ...       ...       ...       ...       ...           ...   \n",
       "99-9972       0.000197  0.000181  0.000171  0.000172  0.000369  2.503467e-04   \n",
       "99-9973       0.000821  0.000346  0.000691  0.001591  0.000863  9.650211e-04   \n",
       "99-9976       0.000569  0.001101  0.001002  0.000430  0.000797  7.203531e-04   \n",
       "99-9988       0.000040  0.000069  0.000123  0.000056  0.000016  1.957402e-04   \n",
       "99-9993       0.000249  0.000179  0.000155  0.000025  0.000325  1.798617e-04   \n",
       "\n",
       "                                                     ...                      \\\n",
       "sub_int_num        7         8         9         10  ...        51        52   \n",
       "row_id                                               ...                       \n",
       "0-1000       0.000089  0.000552  0.000012  0.000000  ...  0.000265  0.000000   \n",
       "0-10000      0.000000  0.000247  0.000265  0.000000  ...  0.000202  0.000375   \n",
       "0-10005      0.000617  0.001199  0.002306  0.001215  ...  0.000000  0.000486   \n",
       "0-10017      0.000899  0.000064  0.000593  0.000451  ...  0.000029  0.000000   \n",
       "0-10030      0.000221  0.000436  0.000099  0.000008  ...  0.000410  0.000437   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "99-9972      0.000349  0.000356  0.000390  0.000050  ...  0.000075  0.000185   \n",
       "99-9973      0.000504  0.001925  0.000641  0.000382  ...  0.001081  0.001095   \n",
       "99-9976      0.000586  0.000538  0.000570  0.000781  ...  0.000508  0.000406   \n",
       "99-9988      0.000071  0.000095  0.000063  0.000030  ...  0.000034  0.000176   \n",
       "99-9993      0.000080  0.000125  0.000126  0.000205  ...  0.000099  0.000370   \n",
       "\n",
       "                                                                   \\\n",
       "sub_int_num        53        54        55        56            57   \n",
       "row_id                                                              \n",
       "0-1000       0.000214  0.000003  0.000000  0.000118  2.313288e-04   \n",
       "0-10000      0.000616  0.000564  0.000000  0.000023  3.777703e-08   \n",
       "0-10005      0.000050  0.001761  0.001617  0.001801  2.552987e-03   \n",
       "0-10017      0.001293  0.002092  0.000994  0.000848  3.104404e-03   \n",
       "0-10030      0.000004  0.000215  0.000457  0.000183  4.842470e-04   \n",
       "...               ...       ...       ...       ...           ...   \n",
       "99-9972      0.000314  0.000318  0.000115  0.000143  9.916624e-05   \n",
       "99-9973      0.000425  0.000789  0.001295  0.000596  1.862600e-03   \n",
       "99-9976      0.000662  0.000338  0.000710  0.000179  5.946683e-04   \n",
       "99-9988      0.000140  0.000129  0.000175  0.000019  1.440137e-04   \n",
       "99-9993      0.000929  0.000328  0.000251  0.000204  2.728767e-04   \n",
       "\n",
       "                                               \n",
       "sub_int_num            58        59        60  \n",
       "row_id                                         \n",
       "0-1000       1.060893e-05  0.000111  0.000288  \n",
       "0-10000      3.777703e-08  0.000020  0.000310  \n",
       "0-10005      5.364106e-04  0.000872  0.000000  \n",
       "0-10017      1.224910e-03  0.001316  0.003287  \n",
       "0-10030      0.000000e+00  0.000756  0.000005  \n",
       "...                   ...       ...       ...  \n",
       "99-9972      1.809852e-04  0.000334  0.000089  \n",
       "99-9973      7.668418e-04  0.001035  0.002115  \n",
       "99-9976      1.509652e-04  0.000388  0.000403  \n",
       "99-9988      3.200939e-05  0.000041  0.000007  \n",
       "99-9993      2.108380e-04  0.000126  0.000353  \n",
       "\n",
       "[428932 rows x 60 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts.pivot(index=\"row_id\",columns=[\"sub_int_num\"],values=[\"sub_int_RV\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195dd6e1",
   "metadata": {},
   "source": [
    "## - Load in target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "677c1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "252d6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdb28caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b71e6",
   "metadata": {},
   "source": [
    "## - An example of creating train and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b2a07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:397: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:397: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7c432cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 60])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07885f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596532d4-3c50-4a8e-bbda-8448b8f02b4d",
   "metadata": {},
   "source": [
    "## Experiment: RNN (with some fine tuning), LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada674f",
   "metadata": {},
   "source": [
    "## - A key issue with our input timeseries is that all values are extremely close to zero, so a 10000 times scaler can help with expanding them a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2721fdfa-a2d2-4461-8a99-0fe183fcbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a44c92-9ff1-4909-808f-0a05b6aa2a14",
   "metadata": {},
   "source": [
    "## - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00de91c2-12af-4f4b-953c-8fa907c945c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  1.2836482524871826  epoch  1 has training loss  tensor(0.2619, device='cuda:0')  and validation loss  tensor(0.2423, device='cuda:0') .\n",
      "\n",
      "At  6.662927627563477  epoch  5 has training loss  tensor(0.2547, device='cuda:0')  and validation loss  tensor(0.2368, device='cuda:0') .\n",
      "\n",
      "At  12.984842538833618  epoch  10 has training loss  tensor(0.2536, device='cuda:0')  and validation loss  tensor(0.2351, device='cuda:0') .\n",
      "\n",
      "At  19.630865812301636  epoch  15 has training loss  tensor(0.2527, device='cuda:0')  and validation loss  tensor(0.2357, device='cuda:0') .\n",
      "\n",
      "At  26.094637393951416  epoch  20 has training loss  tensor(0.2527, device='cuda:0')  and validation loss  tensor(0.2357, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 14  with validation loss:  tensor(0.2348, device='cuda:0') .\n",
      " The total number of epoch trained is  24 .\n",
      " Training completed in:  31.20871138572693 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.0534,  0.2919, -0.3057],\n",
       "                      [ 0.0650,  0.0654, -0.2658],\n",
       "                      [ 0.0175,  0.2920,  0.2604],\n",
       "                      [-0.4015,  0.4187,  0.5416],\n",
       "                      [-0.0904, -0.2123, -0.3803],\n",
       "                      [-0.1478,  0.3972, -0.3277],\n",
       "                      [ 0.5207,  0.7690,  0.4038],\n",
       "                      [ 0.0969, -0.2740, -0.5250],\n",
       "                      [-0.0276, -0.5302, -0.1606],\n",
       "                      [-0.2822, -0.2647,  0.5187],\n",
       "                      [ 0.0045, -0.3951, -0.1687],\n",
       "                      [ 0.5052,  0.1409,  0.3657],\n",
       "                      [ 0.0687,  0.5994,  0.2664],\n",
       "                      [-0.3185, -0.3795,  0.4575],\n",
       "                      [ 0.2545,  0.3227,  0.0565],\n",
       "                      [-0.0836, -0.1112, -0.0495],\n",
       "                      [-0.1078,  0.2917,  0.0700],\n",
       "                      [ 0.4257,  0.1079,  0.0385],\n",
       "                      [ 0.1929, -0.2913, -0.1357],\n",
       "                      [ 0.0022, -0.2931,  0.3934],\n",
       "                      [-0.1998, -0.0600, -0.0532],\n",
       "                      [-0.0650,  0.5099,  0.4387],\n",
       "                      [-0.0485,  0.6677,  0.4892],\n",
       "                      [ 0.0210, -0.5561, -0.0992],\n",
       "                      [-0.1579,  0.0940, -0.4233],\n",
       "                      [-0.2049, -0.0132, -0.1750],\n",
       "                      [ 0.3622, -0.0936,  0.3698],\n",
       "                      [-0.2976,  0.0076,  0.0029],\n",
       "                      [-0.1410,  0.2274, -0.1086],\n",
       "                      [-0.2515,  0.2471,  0.0651],\n",
       "                      [-0.4305, -0.1122, -0.2941],\n",
       "                      [ 0.4586,  0.3367, -0.0064]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.2166, -0.0607, -0.0186,  0.1198,  0.1875,  0.1542, -0.2492, -0.2298,\n",
       "                      -0.1050, -0.4194,  0.2647,  0.0163,  0.0282,  0.3430, -0.2433,  0.1832,\n",
       "                       0.2823, -0.5221, -0.2325,  0.0210,  0.0933,  0.1346, -0.0552,  0.0137,\n",
       "                       0.0161, -0.0591, -0.2444, -0.2754,  0.2937, -0.4088,  0.3112,  0.1076],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.0255,  0.3028, -0.2161,  ..., -0.1424,  0.0265, -0.1383],\n",
       "                      [-0.0417,  0.1997, -0.0438,  ...,  0.0671,  0.1211, -0.1283],\n",
       "                      [-0.0783, -0.3230,  0.0236,  ...,  0.0160, -0.1296,  0.0806],\n",
       "                      ...,\n",
       "                      [-0.0510, -0.0287,  0.0570,  ...,  0.3532,  0.1984, -0.0767],\n",
       "                      [-0.1034, -0.0024, -0.0551,  ..., -0.1347, -0.1531, -0.0676],\n",
       "                      [-0.1809, -0.2125,  0.6011,  ..., -0.0998, -0.0267,  0.0536]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.0135,  0.2369,  0.2202,  ..., -0.1054,  0.0496,  0.0646],\n",
       "                      [-0.1969,  0.0312, -0.3042,  ..., -0.2111, -0.1470, -0.1231],\n",
       "                      [-0.0090, -0.2736,  0.0037,  ...,  0.0503,  0.0562,  0.1543],\n",
       "                      ...,\n",
       "                      [-0.0804, -0.0174, -0.0900,  ...,  0.1085, -0.2329,  0.1649],\n",
       "                      [-0.1400, -0.1192, -0.1340,  ..., -0.1028,  0.0357, -0.0168],\n",
       "                      [ 0.3256, -0.0276,  0.1408,  ...,  0.1454,  0.1549,  0.0894]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0286,  0.0196,  0.0165,  0.1395, -0.0161,  0.2002,  0.1304,  0.0225,\n",
       "                      -0.1438,  0.0755, -0.0122,  0.1250, -0.0436,  0.0879, -0.0780, -0.0996,\n",
       "                      -0.2170,  0.0061,  0.0891,  0.0799,  0.0999, -0.0529, -0.0097, -0.1093,\n",
       "                       0.0731, -0.0588, -0.1403,  0.0970, -0.0883, -0.0254, -0.0019,  0.1061],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.1170,  0.0916, -0.0219,  0.0942,  0.0589, -0.0051, -0.1581, -0.1008,\n",
       "                       0.1751,  0.0371,  0.0915, -0.1489, -0.0865,  0.0103, -0.1195, -0.0916,\n",
       "                      -0.1451,  0.1011, -0.1168,  0.1082, -0.0648,  0.0260, -0.0390,  0.2157,\n",
       "                      -0.1093, -0.1658,  0.0428,  0.1888, -0.1285, -0.0735,  0.1128,  0.0019],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.1181,  0.0145,  0.0381,  0.1178,  0.0454,  0.1180, -0.1846, -0.1981,\n",
       "                       -0.0787, -0.0040,  0.1482, -0.0111,  0.1731, -0.1102, -0.1142, -0.1898,\n",
       "                       -0.1260, -0.1804,  0.2199,  0.1806, -0.1239, -0.0537,  0.0457, -0.0358,\n",
       "                       -0.2200, -0.1397,  0.0721,  0.0918, -0.0590, -0.0432,  0.1559, -0.1018]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0988], device='cuda:0'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"rnn\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb1f55fb-a478-4bee-bf57-12189db4383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7c7a7f06a0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMflJREFUeJzt3X9QFGeex/HPAAJRBMEfIDhKsrnVJLdqVnTi7XK7llNC9mrjBr1Tz0RjWW428ccqe8b4R8SsdwsaK0uyelrnJrfJVVAvieY2uSryg4BxL6hbWF7qUom3SempCPgjJURJRJm+P2YZnQDCQA/T88z7VTWF9DzT8zQzY3+m+/s87bIsyxIAAECUi4t0BwAAAOxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGCEh0h0YKD6fT2fPntXQoUPlcrki3R0AANALlmXpyy+/VHZ2tuLibn0sJmZCzdmzZ+V2uyPdDQAA0AenT5/WmDFjbtkmZkLN0KFDJfn/KKmpqRHuDQAA6I2Wlha53e7AfvxWYibUdJxySk1NJdQAABBlelM6QqEwAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGCEmJl8L1za26WDB6WGBmn0aCk/X4qPj3SvAACIPYSafti3T/r5z6UzZ24sGzNGeu45qagocv0CACAWcfqpj/btk+bODQ40klRf71++b19k+gUAQKwi1PRBe7v/CI1ldb6vY9nq1f52AABgYBBq+uDgwc5HaG5mWdLp0/52AABgYBBq+qChwd52AACg/wg1fTB6tL3tAABA/xFq+iA/3z/KyeXq+n6XS3K7/e0AAMDAINT0QXy8f9i21DnYdPxeXs58NQAADCRCTR8VFUmvvSbl5AQvHzPGv5x5agAAGFhMvtcPRUXS7NnMKAwAgBMQavopPl764Q8j3QsAAMDpJwAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABG6FOo2b59u3Jzc5WcnCyPx6MjR45023bXrl3Kz89Xenq60tPT5fV6u2z/ySef6IEHHlBaWpqGDBmiqVOn6tSpU4H7v/76ay1fvlzDhw9XSkqK5syZo6ampr50HwAAGCjkULN3714VFxerpKRER48e1aRJk1RQUKBz58512b6mpkYLFixQdXW1amtr5Xa7NWvWLNXX1wfafP755/r+97+vCRMmqKamRh999JGeeuopJScnB9qsWbNGb775pl599VUdOHBAZ8+eVVFRUR82GQAAmMhlWZYVygM8Ho+mTp2qbdu2SZJ8Pp/cbrdWrlypJ598ssfHt7e3Kz09Xdu2bdOiRYskSfPnz9egQYP0b//2b10+prm5WSNHjlRFRYXmzp0rSfr000911113qba2Vvfdd1+Pz9vS0qK0tDQ1NzcrNTW1t5sLAAAiKJT9d0hHatra2lRXVyev13tjBXFx8nq9qq2t7dU6Wltbde3aNWVkZEjyh6L//M//1Le//W0VFBRo1KhR8ng8euONNwKPqaur07Vr14Ked8KECRo7dmy3z3v16lW1tLQE3QAAgLlCCjUXLlxQe3u7MjMzg5ZnZmaqsbGxV+tYt26dsrOzAwHl3Llzunz5ssrKylRYWKh33nlHDz74oIqKinTgwAFJUmNjoxITEzVs2LBeP29paanS0tICN7fbHcqmAgCAKJMwkE9WVlamPXv2qKamJlAv4/P5JEmzZ8/WmjVrJEmTJ0/Whx9+qJ07d+oHP/hBn55r/fr1Ki4uDvze0tJCsAEAwGAhhZoRI0YoPj6+06ijpqYmZWVl3fKxW7duVVlZmd577z1NnDgxaJ0JCQm6++67g9rfdddd+sMf/iBJysrKUltbmy5duhR0tOZWz5uUlKSkpKRQNg8AAESxkE4/JSYmasqUKaqqqgos8/l8qqqq0vTp07t93JYtW7Rp0yZVVlYqLy+v0zqnTp2q48ePBy3/3//9X40bN06SNGXKFA0aNCjoeY8fP65Tp07d8nkBAEDsCPn0U3FxsRYvXqy8vDxNmzZN5eXlunLlipYsWSJJWrRokXJyclRaWipJ2rx5szZs2KCKigrl5uYGamBSUlKUkpIiSVq7dq3mzZunv/7rv9aMGTNUWVmpN998UzU1NZKktLQ0LV26VMXFxcrIyFBqaqpWrlyp6dOn92rkEwAAMF/IoWbevHk6f/68NmzYoMbGRk2ePFmVlZWB4uFTp04pLu7GAaAdO3aora0tMBS7Q0lJiTZu3ChJevDBB7Vz506VlpZq1apVGj9+vF5//XV9//vfD7T/9a9/rbi4OM2ZM0dXr15VQUGB/vmf/7kv2wwAAAwU8jw10Yp5agAAiD5hm6cGAADAqQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIAREiLdAdzQ3i4dPCg1NEijR0v5+VJ8fKR7BQBAdCDUOMS+fdLPfy6dOXNj2Zgx0nPPSUVFkesXAADRgtNPDrBvnzR3bnCgkaT6ev/yffsi0y8AAKIJoSbC2tv9R2gsq/N9HctWr/a3AwAA3SPURNjBg52P0NzMsqTTp/3tAABA9wg1EdbQYG87AABiFaEmwkaPtrcdAACxilATYfn5/lFOLlfX97tcktvtbwcAALpHqImw+Hj/sG2pc7Dp+L28nPlqAADoCaHGAYqKpNdek3JygpePGeNfzjw1AAD0jMn3HKKoSJo9mxmFAQDoK0KNg8THSz/8YaR7AQBAdOL0EwAAMAKhBgAAGIHTTwbjqt8AgFhCqDEUV/0GAMQaTj8ZiKt+AwBiEaHGMFz1GwAQq/oUarZv367c3FwlJyfL4/HoyJEj3bbdtWuX8vPzlZ6ervT0dHm93k7tH3nkEblcrqBbYWFhUJvc3NxObcrKyvrSfaOF86rf7e1STY20e7f/J8EIAOAkIYeavXv3qri4WCUlJTp69KgmTZqkgoICnTt3rsv2NTU1WrBggaqrq1VbWyu3261Zs2apvr4+qF1hYaEaGhoCt927d3da1y9/+cugNitXrgy1+8YL11W/9+2TcnOlGTOkv/97/8/cXE5lAQCcI+RQ8+yzz2rZsmVasmSJ7r77bu3cuVODBw/Wiy++2GX7V155RY8//rgmT56sCRMm6Le//a18Pp+qqqqC2iUlJSkrKytwS09P77SuoUOHBrUZMmRIqN03Xjiu+h2OGh2O+gAA7BZSqGlra1NdXZ28Xu+NFcTFyev1qra2tlfraG1t1bVr15SRkRG0vKamRqNGjdL48eP12GOP6eLFi50eW1ZWpuHDh+vee+/VM888o+vXr3f7PFevXlVLS0vQLRbYfdXvcNTocNQHABAOIYWaCxcuqL29XZmZmUHLMzMz1djY2Kt1rFu3TtnZ2UHBqLCwUC+//LKqqqq0efNmHThwQPfff7/ab9pTrlq1Snv27FF1dbUeffRR/epXv9ITTzzR7fOUlpYqLS0tcHO73aFsatSy+6rfdtfoMDILABA2Vgjq6+stSdaHH34YtHzt2rXWtGnTenx8aWmplZ6ebv33f//3Ldt9/vnnliTrvffe67bNCy+8YCUkJFhff/11l/d//fXXVnNzc+B2+vRpS5LV3NzcYz9N8PrrljVmjGX5Y4f/5nb7l4eioiJ4Hd3dKip6Xtf16537dPPN5fL38fr1vm0zAMA8zc3Nvd5/h3SkZsSIEYqPj1dTU1PQ8qamJmVlZd3ysVu3blVZWZneeecdTZw48ZZt77jjDo0YMUKfffZZt208Ho+uX7+ukydPdnl/UlKSUlNTg26xpKhIOnlSqq6WKir8P0+cCH3iPTtrdMI5MgsAgJBCTWJioqZMmRJU5NtR9Dt9+vRuH7dlyxZt2rRJlZWVysvL6/F5zpw5o4sXL2r0LfaUx44dU1xcnEaNGhXKJsSUjqt+L1jg/9mXSyTYWaMTrpFZAABIfbhMQnFxsRYvXqy8vDxNmzZN5eXlunLlipYsWSJJWrRokXJyclRaWipJ2rx5szZs2KCKigrl5uYGam9SUlKUkpKiy5cv6+mnn9acOXOUlZWlzz//XE888YTuvPNOFRQUSJJqa2t1+PBhzZgxQ0OHDlVtba3WrFmjhx56qMtRUrBPR43O3Ln+AHNzwXCoNTrhGJkFAEBAX85v/eY3v7HGjh1rJSYmWtOmTbMOHToUuO8HP/iBtXjx4sDv48aNsyR1upWUlFiWZVmtra3WrFmzrJEjR1qDBg2yxo0bZy1btsxqbGwMrKOurs7yeDxWWlqalZycbN11113Wr371q27raboSyjk5dGZHjU5HTY3LRU0NAKB3Qtl/uyyrq8G65mlpaVFaWpqam5tjrr7GLnZc9btj9JPU9VGf117jgpsAgBtC2X9zlW70WkeNTn8UFfmDS1dXEC8v73ugsSNwAQCiG6EGA66oSJo9274Qsm9f1yHpuec46gMAsYTTT4hqHaezvvku7s/pLI76AIBzhLL/7tNVugEn4BIOAICbEWoQtaLlEg5cvBMABgahBlHLzsn8wnHUR4q9Iz8EOACRRKhB1HL6JRyi4eKddoaQWAtwAJyHUIOo5eRLOITryI+d7Awh0RDgAJiPUIOo1XEJB6lzsIn0JRycfvFOO0NINAQ4ALGBUIOo1jGZX05O8PIxY0Ibzm3nUR/J2RfvtDuEOD3AAYgdTL6HqGfHZH52XrhTCu/FO/s7j04oIaQ3M0iHK8AxXxCAUBFqYASnXcKh48hPfX3XR0RcLv/9vT3y08GO2ZPtDiHhCHDhmCWakASYj9NPwE2KiqSTJ6Xqaqmiwv/zxInQd6R21vt0sKsOxu4QYvepu3AUHTMyC4gNXCYBCKOujji43aEf+Wlv9++Euztt1HHk58SJnoNSx7p6OorUm3V1sOvq63Zu5zf7ZuelNAAMHC6TADiEXUd+7CzGDcdRJLsKtu0uOg7nyCwmGgSch5oaIMzsqPexuw7Gzvqhm9fZ34Jtu7fT7qLoDlwZHnAmQg0QBcJRjGtHCPmm/gY4u7czHCOzujud1VHz44Qrw1MUjVhFTQ0QBcJRB+NEdm9nTY2/KLgn1dW9C2Phqvmx86iP3euLpYAUS9saTULaf1sxorm52ZJkNTc3R7orQJ+8/rpluVz+m3+X7791LHv99Uj30B52buf165Y1Zkzndd28Trfb3643qqu7Xs83b9XVoW1rV/3qy2sajvWNGRO8rjFj+vdeu37d//epqPD/7O3fPtzCsa2wRyj7b0INEEW6+o/X7TbvP147t9POkFRR0btQU1HR87o6Ald36wg1cNm9PrsDUsc6nRgcwrGtsE8o+29OPwFRJlYOkdu5nXYNrbfzdJbdp8bsXF8sDa0Px7bCXqHsvykUBqKMHaOpooGd22lXUbSdM0XbXcRsZzu7R431NLTe5fIPrZ89O/TXxGmXDUFkEWoAxAQ7QpKd1wize6SXne1iaWh9OC8+GytHVZ2EyfcAIAROvTK8neuLpqH1TrtsyM3949IcA4+aGgDoAzu+hdt1eQm71xdLQ+vDedkQO+uHnD6XUTiPSjGkuwuMfgLgRHaPaLNrfbE4tN7ObbVrFFpH/+wcNeb09X0TQ7q7QKgB4FR2z91i1/piYWi93dsai3MZhXs4PEO6u8DpJwAInelD629mx7bu3u2voelJRYW0YEHP/bFzuLnT19cdhnQDAGxh+tD6m9mxrXYWHts9aszp67MDoQYAMGCcNrTebrEyl1E42tmBId0AgKhj19B6u3UELqnz8HqT5jIKRzs7UFMDAIhaTp3gzo76IbuHmzt9fd2hpgYAEBOcetkQO+qH7D7N5vT12YHTTwAAhEFH4FqwwP+zLzt3u0+zOX19/cXpJwAAHM7pMwA7ZUZhQg0AAHCsUPbfnH4CAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGKFPoWb79u3Kzc1VcnKyPB6Pjhw50m3bXbt2KT8/X+np6UpPT5fX6+3U/pFHHpHL5Qq6FRYWBrX54osvtHDhQqWmpmrYsGFaunSpLl++3JfuAwAAA4Ucavbu3avi4mKVlJTo6NGjmjRpkgoKCnTu3Lku29fU1GjBggWqrq5WbW2t3G63Zs2apfr6+qB2hYWFamhoCNx2794ddP/ChQv18ccf691339Vbb72lDz74QD/96U9D7T4AADCUy7IsK5QHeDweTZ06Vdu2bZMk+Xw+ud1urVy5Uk8++WSPj29vb1d6erq2bdumRYsWSfIfqbl06ZLeeOONLh/zySef6O6779Yf//hH5eXlSZIqKyv1ox/9SGfOnFF2dnaPz9vS0qK0tDQ1NzcrNTW1l1sLAAAiKZT9d0hHatra2lRXVyev13tjBXFx8nq9qq2t7dU6Wltbde3aNWVkZAQtr6mp0ahRozR+/Hg99thjunjxYuC+2tpaDRs2LBBoJMnr9SouLk6HDx/u8nmuXr2qlpaWoBsAADBXSKHmwoULam9vV2ZmZtDyzMxMNTY29mod69atU3Z2dlAwKiws1Msvv6yqqipt3rxZBw4c0P3336/29nZJUmNjo0aNGhW0noSEBGVkZHT7vKWlpUpLSwvc3G53KJsKAACiTMJAPllZWZn27NmjmpoaJScnB5bPnz8/8O/vfOc7mjhxor71rW+ppqZGM2fO7NNzrV+/XsXFxYHfW1paCDYAABgspCM1I0aMUHx8vJqamoKWNzU1KSsr65aP3bp1q8rKyvTOO+9o4sSJt2x7xx13aMSIEfrss88kSVlZWZ0Kka9fv64vvvii2+dNSkpSampq0A0AAJgrpFCTmJioKVOmqKqqKrDM5/OpqqpK06dP7/ZxW7Zs0aZNm1RZWRlUF9OdM2fO6OLFixo9erQkafr06bp06ZLq6uoCbd5//335fD55PJ5QNgEAABgq5CHdxcXF2rVrl1566SV98skneuyxx3TlyhUtWbJEkrRo0SKtX78+0H7z5s166qmn9OKLLyo3N1eNjY1qbGwMzDFz+fJlrV27VocOHdLJkydVVVWl2bNn684771RBQYEk6a677lJhYaGWLVumI0eO6L/+67+0YsUKzZ8/v1cjnwAAgPlCrqmZN2+ezp8/rw0bNqixsVGTJ09WZWVloHj41KlTiou7kZV27NihtrY2zZ07N2g9JSUl2rhxo+Lj4/XRRx/ppZde0qVLl5Sdna1Zs2Zp06ZNSkpKCrR/5ZVXtGLFCs2cOVNxcXGaM2eOnn/++b5uNwAAMEzI89REK+apAQAg+oRtnhoAAACnItQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIAR+hRqtm/frtzcXCUnJ8vj8ejIkSPdtt21a5fy8/OVnp6u9PR0eb3eW7b/2c9+JpfLpfLy8qDlubm5crlcQbeysrK+dB8AABgo5FCzd+9eFRcXq6SkREePHtWkSZNUUFCgc+fOddm+pqZGCxYsUHV1tWpra+V2uzVr1izV19d3art//34dOnRI2dnZXa7rl7/8pRoaGgK3lStXhtp9AABgqJBDzbPPPqtly5ZpyZIluvvuu7Vz504NHjxYL774YpftX3nlFT3++OOaPHmyJkyYoN/+9rfy+XyqqqoKaldfX6+VK1fqlVde0aBBg7pc19ChQ5WVlRW4DRkyJNTuAwAAQ4UUatra2lRXVyev13tjBXFx8nq9qq2t7dU6Wltbde3aNWVkZASW+Xw+Pfzww1q7dq3uueeebh9bVlam4cOH695779Uzzzyj69evd9v26tWramlpCboBAABzJYTS+MKFC2pvb1dmZmbQ8szMTH366ae9Wse6deuUnZ0dFIw2b96shIQErVq1qtvHrVq1St/97neVkZGhDz/8UOvXr1dDQ4OeffbZLtuXlpbq6aef7lWfAABA9Asp1PRXWVmZ9uzZo5qaGiUnJ0uS6urq9Nxzz+no0aNyuVzdPra4uDjw74kTJyoxMVGPPvqoSktLlZSU1Kn9+vXrgx7T0tIit9tt49YAAAAnCen004gRIxQfH6+mpqag5U1NTcrKyrrlY7du3aqysjK98847mjhxYmD5wYMHde7cOY0dO1YJCQlKSEjQ//3f/+kXv/iFcnNzu12fx+PR9evXdfLkyS7vT0pKUmpqatANAACYK6RQk5iYqClTpgQV+XYU/U6fPr3bx23ZskWbNm1SZWWl8vLygu57+OGH9dFHH+nYsWOBW3Z2ttauXau3336723UeO3ZMcXFxGjVqVCibAAAADBXy6afi4mItXrxYeXl5mjZtmsrLy3XlyhUtWbJEkrRo0SLl5OSotLRUkr9eZsOGDaqoqFBubq4aGxslSSkpKUpJSdHw4cM1fPjwoOcYNGiQsrKyNH78eElSbW2tDh8+rBkzZmjo0KGqra3VmjVr9NBDDyk9Pb1ffwAAAGCGkEPNvHnzdP78eW3YsEGNjY2aPHmyKisrA8XDp06dUlzcjQNAO3bsUFtbm+bOnRu0npKSEm3cuLFXz5mUlKQ9e/Zo48aNunr1qm6//XatWbMmqGYGAADENpdlWVakOzEQWlpalJaWpubmZuprAACIEqHsv7n2EwAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMkRLoDUc/XLp0/KH3VIN02WhqZL8XFR7pXAADEHEJNf5zeJ9X9XGo9c2PZ4DHSlOckd1Hk+gUAQAzi9FNfnd4nHZwbHGgkqbXev/z0vsj0CwCAGEWo6Qtfu/8Ijawu7vzzsrrV/nYAAGBAEGr64vzBzkdoglhS62l/OwAAMCAINX3xVYO97QAAQL8RavrittH2tgMAAP1GqOmLkfn+UU5yddPAJQ12+9sBAIABQajpi7h4/7BtSZ2DzZ9/n1LOfDUAAAwgQk1fuYuk/NekwTnByweP8S9nnhoAAAYUk+/1h7tIypnNjMIAADgAoaa/4uKlzB9GuhcAAMQ8Tj8BAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGCEh0h3ATXzt0vmD0lcN0m2jpZH5Ulx8pHsFAEBUINQ4xel9Ut3PpdYzN5YNHiNNeU5yF0WuXwAARAlOPznB6X3SwbnBgUaSWuv9y0/vi0y/AACIIoSaSPO1+4/QyOrizj8vq1vtbwcAALrVp1Czfft25ebmKjk5WR6PR0eOHOm27a5du5Sfn6/09HSlp6fL6/Xesv3PfvYzuVwulZeXBy3/4osvtHDhQqWmpmrYsGFaunSpLl++3JfuO8v5g52P0ASxpNbT/nYAAKBbIYeavXv3qri4WCUlJTp69KgmTZqkgoICnTt3rsv2NTU1WrBggaqrq1VbWyu3261Zs2apvr6+U9v9+/fr0KFDys7O7nTfwoUL9fHHH+vdd9/VW2+9pQ8++EA//elPQ+2+83zVYG87AABilMuyrK7Oe3TL4/Fo6tSp2rZtmyTJ5/PJ7XZr5cqVevLJJ3t8fHt7u9LT07Vt2zYtWrQosLy+vl4ej0dvv/22/uZv/karV6/W6tWrJUmffPKJ7r77bv3xj39UXl6eJKmyslI/+tGPdObMmS5D0De1tLQoLS1Nzc3NSk1NDWWTw6upRqqa0XO7mdVS5g/D3RsAABwllP13SEdq2traVFdXJ6/Xe2MFcXHyer2qra3t1TpaW1t17do1ZWRkBJb5fD49/PDDWrt2re65555Oj6mtrdWwYcMCgUaSvF6v4uLidPjw4S6f5+rVq2ppaQm6OdLIfP8oJ7m6aeCSBrv97QAAQLdCCjUXLlxQe3u7MjMzg5ZnZmaqsbGxV+tYt26dsrOzg4LR5s2blZCQoFWrVnX5mMbGRo0aNSpoWUJCgjIyMrp93tLSUqWlpQVubre7V/0bcHHx/mHbkjoHmz//PqWc+WoAAOjBgI5+Kisr0549e7R//34lJydLkurq6vTcc8/pd7/7nVyu7o5WhG79+vVqbm4O3E6fPm3bum3nLpLyX5MG5wQvHzzGv5x5agAA6FFIk++NGDFC8fHxampqClre1NSkrKysWz5269atKisr03vvvaeJEycGlh88eFDnzp3T2LFjA8va29v1i1/8QuXl5Tp58qSysrI6FSJfv35dX3zxRbfPm5SUpKSkpFA2L7LcRVLObGYUBgCgj0I6UpOYmKgpU6aoqqoqsMzn86mqqkrTp0/v9nFbtmzRpk2bVFlZGVQXI0kPP/ywPvroIx07dixwy87O1tq1a/X2229LkqZPn65Lly6prq4u8Lj3339fPp9PHo8nlE1wtrh4fzFw7gL/TwINAAC9FvJlEoqLi7V48WLl5eVp2rRpKi8v15UrV7RkyRJJ0qJFi5STk6PS0lJJ/nqZDRs2qKKiQrm5uYEamJSUFKWkpGj48OEaPnx40HMMGjRIWVlZGj9+vCTprrvuUmFhoZYtW6adO3fq2rVrWrFihebPn9+rkU8AAMB8IYeaefPm6fz589qwYYMaGxs1efJkVVZWBoqHT506pbi4GweAduzYoba2Ns2dOzdoPSUlJdq4cWOvn/eVV17RihUrNHPmTMXFxWnOnDl6/vnnQ+0+AAAwVMjz1EQrx85TAwAAuhW2eWoAAACcilADAACMEHJNDWKYr50h5wAAxyLUoHdO75Pqfh58RfHBY/yzITM5IADAATj9hJ6d3icdnBscaCSptd6//PS+yPQLAICbEGpwa752/xEadTVI7s/L6lb72wEAEEGEGtza+YOdj9AEsaTW0/52AABEEKEGt/ZVg73tAAAIEwqFcWu3jba3HYDowqhHRBFCDW5tZL5/lFNrvbquq3H57x+ZP9A9g+nYmUYeox4RZTj9hFuLi/f/ByZJcn3jzj//PqWcnQ3sdXqf9PtcqWqG9OHf+3/+PpeRdgOJUY+IQoQa9MxdJOW/Jg3OCV4+eIx/Od/YYCd2ppHHqEdEKU4/oXfcRVLObE4HILx63Jm6/DvTnNm898IplFGPmT8cqF4BPSLUoPfi4vkPDOHFztQZGPWIKMXpJwDOwc7UGRj1iCjFkRoAzhHOnSmjqXqPUY+IUoQaAM4Rrp0pQ5ND0zHq8eBc+Uc53vxaMOoRzsXpJwDOEY4pBBhN1TeMekQUclmW1dXXIeO0tLQoLS1Nzc3NSk1NjXR3ANxKl0dW3P5AE8rO1Nfun9+m2+LjPx/5eeAERx26w2k7RFgo+29OPwFwHrumEGA0Vf/ZPeqRkIQwItQAcCY7dqaMpnIWapsQZtTUADAXQ5Odg9omDABCDQBzdYym6lR03MHlr9VhaHJ4cdkFDBBCDQBzcUFWZwiltgnoB0INEG187VJTjXRyt/8n325vjaHJkUdtEwYIhcJANKHQsm+4IGtkUduEAUKoAaJFR6HlN+sSOgotOepwa1yQNXK47AIGCKefEBmcQgkNhZaIZtQ2YYBwpAYDj1MooWMSOUS7jtqmLj/75Xz2e8Kkhb1CqMHA4hRK31BoCRPEWm2TXUGEL4K9RqjBwOnxFIrLfwolZ7a5/8n1FYWWMEWs1DbZFUT4IhgSamowcJirou+YRA6IHnbNnkwtXcgINRg4nELpOwotEQoK8SPHziASTV8EHfKe4/QTBg6nUPqHQkv0BvUXkWVnUX+0fBF00HuOUIOBw1wV/RdrhZYIDfUXkWdnEImGL4IOe89x+gkDh1Mo9ugotMxd4P/J3wsS9RdOYWcQcXotnQPfc4QaDCyuwwOERzTVX5jMziDi9C+CDnzPcfoJAy8cp1CYmAqxLlrqL0zXEUQOzpU/eNx8FKMPQcTJtXQOfM8Rakzm5B29nXNVOKhIDYiYaKi/iBV2BxGn1tI58D3nsiyrq5NhxmlpaVFaWpqam5uVmpoa6e6EX6zs6LsrUuv4RsQpLcQKX7v0+9yeC/EfOBH5nWGscPIXSzsM0HsulP03NTUmsmviJ6dzYJEaEDFOr7+IRaYX9TvwPUeoMU0s7egdWKQGRBSF+BhoDnvPUVNjmli6mrMDi9RinumH28PFzr+bU+svogHv375x0HuOUGOaWNrRO7BILabFSh2X3cLxd4uVi0baifdv/zjkPcfpJ9PE0o7e6RNTxZJYqeOyG383Z+B1MAahxjSxtKN3YJFalxxyobewiaU6Ljvxd3MGXgejEGpMEy07ers4rEitk9P7/EMeq2ZIH/69/+fvc8365kfBdt/wd3OGWH0dDP2yRU2NiZw8A2U4OKhILYjDLvQWNrFUx2Un/m7OEIuvg8H1Q4QaUzl1Rx8uDilSC+jxkLbLf0g7Z3b0vyaxVMdlJ/5uzhBrr4PhX7Y4/WQy0yd+crJoOaRtxyHoWKrjshN/N2eIpdchBuqHCDXAN9mxo4+GQ9p21fvEWh2XXfi7OUMsvQ7R8mWrH/oUarZv367c3FwlJyfL4/HoyJEj3bbdtWuX8vPzlZ6ervT0dHm93k7tN27cqAkTJmjIkCGBNocPHw5qk5ubK5fLFXQrKyvrS/eB7tm1o3f6IW27h7A6vWDbqfi79Z8dX0Ji5XWIhi9b/RTyBS337t2rRYsWaefOnfJ4PCovL9err76q48ePa9SoUZ3aL1y4UN/73vf0V3/1V0pOTtbmzZu1f/9+ffzxx8rJ8b+BKioqNGrUKN1xxx366quv9Otf/1qvvvqqPvvsM40cOVKSP9QsXbpUy5YtC6x76NChGjJkSK/6HXMXtETo7Lw4ppMvLhjoW3ff2PrRt1iakdXObY2lv5ud7C54Nf11aKrxf1HrycxqR9UohrL/DjnUeDweTZ06Vdu2bZMk+Xw+ud1urVy5Uk8++WSPj29vb1d6erq2bdumRYsW3XID3nvvPc2cOVOSP9SsXr1aq1evDqW7ndZJqEGXwrGjD4QkKTjYRPgK4lH6H5ujGDx6JGrY+SUkVjj5y9YthO0q3W1tbaqrq5PX672xgrg4eb1e1dbW9modra2tunbtmjIyMrp9jn/5l39RWlqaJk2aFHRfWVmZhg8frnvvvVfPPPOMrl+/3u3zXL16VS0tLUE3oFvhONfs1EPaMXAIOqyYfTbyYqDgNSxioH4opCHdFy5cUHt7uzIzM4OWZ2Zm6tNPP+3VOtatW6fs7OygYCRJb731lubPn6/W1laNHj1a7777rkaMGBG4f9WqVfrud7+rjIwMffjhh1q/fr0aGhr07LPPdvk8paWlevrpp0PZPMSycO3onTi03un1Pk4WS0P1nSyWLtxrN8PnMRvQeWrKysq0Z88e1dTUKDk5Oei+GTNm6NixY7pw4YJ27dqlv/u7v9Phw4cDdTrFxcWBthMnTlRiYqIeffRRlZaWKikpqdNzrV+/PugxLS0tcrvdYdoyRL1w7uidNodOxxDWng5BmzCE1W7sTJ2Bo43948QvWzYJ6fTTiBEjFB8fr6ampqDlTU1NysrKuuVjt27dqrKyMr3zzjuaOHFip/uHDBmiO++8U/fdd59eeOEFJSQk6IUXXuh2fR6PR9evX9fJkye7vD8pKUmpqalBN6BbsTRXRQwcgg4bdqbOwNHG/jN0HrOQQk1iYqKmTJmiqqqqwDKfz6eqqipNnz6928dt2bJFmzZtUmVlpfLy8nr1XD6fT1evXu32/mPHjikuLq7LEVdAyGJtR+/Ueh+nY2fqDLH0JQQhCfn0U3FxsRYvXqy8vDxNmzZN5eXlunLlipYsWSJJWrRokXJyclRaWipJ2rx5szZs2KCKigrl5uaqsbFRkpSSkqKUlBRduXJF//RP/6QHHnhAo0eP1oULF7R9+3bV19frb//2byVJtbW1Onz4sGbMmKGhQ4eqtrZWa9as0UMPPaT09HS7/haIdYafa+7E4EPQYcOpO2fo+BJycK78waaL0YUmfQlBr4UcaubNm6fz589rw4YNamxs1OTJk1VZWRkoHj516pTi4m4cANqxY4fa2to0d+7coPWUlJRo48aNio+P16effqqXXnpJFy5c0PDhwzV16lQdPHhQ99xzjyT/qaQ9e/Zo48aNunr1qm6//XatWbMmqGYGsEWs7eidVu/jdOxMnSPWvoSgV0KepyZaMU8NANt0OU+Nm51pJJg+YR5C2n9zlW4ACFWsHdFzMo424iaEGgDoC3amgONwlW4AAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYISYmVG44xJXLS0tEe4JAADorY79dm8uVRkzoebLL7+UJLnd7gj3BAAAhOrLL79UWlraLdvEzFW6fT6fzp49q6FDh8rlctm67paWFrndbp0+fZorgEcQr4Mz8Do4A6+DM/A69J9lWfryyy+VnZ2tuLhbV83EzJGauLg4jRkzJqzPkZqaypvWAXgdnIHXwRl4HZyB16F/ejpC04FCYQAAYARCDQAAMAKhxgZJSUkqKSlRUlJSpLsS03gdnIHXwRl4HZyB12FgxUyhMAAAMBtHagAAgBEINQAAwAiEGgAAYARCDQAAMAKhpp+2b9+u3NxcJScny+Px6MiRI5HuUkzZuHGjXC5X0G3ChAmR7lZM+OCDD/TjH/9Y2dnZcrlceuONN4LutyxLGzZs0OjRo3XbbbfJ6/XqT3/6U2Q6a7CeXodHHnmk02eksLAwMp01VGlpqaZOnaqhQ4dq1KhR+slPfqLjx48Htfn666+1fPlyDR8+XCkpKZozZ46ampoi1GNzEWr6Ye/evSouLlZJSYmOHj2qSZMmqaCgQOfOnYt012LKPffco4aGhsDtD3/4Q6S7FBOuXLmiSZMmafv27V3ev2XLFj3//PPauXOnDh8+rCFDhqigoEBff/31APfUbD29DpJUWFgY9BnZvXv3APbQfAcOHNDy5ct16NAhvfvuu7p27ZpmzZqlK1euBNqsWbNGb775pl599VUdOHBAZ8+eVVFRUQR7bSgLfTZt2jRr+fLlgd/b29ut7Oxsq7S0NIK9ii0lJSXWpEmTIt2NmCfJ2r9/f+B3n89nZWVlWc8880xg2aVLl6ykpCRr9+7dEehhbPjm62BZlrV48WJr9uzZEelPrDp37pwlyTpw4IBlWf73/qBBg6xXX3010OaTTz6xJFm1tbWR6qaROFLTR21tbaqrq5PX6w0si4uLk9frVW1tbQR7Fnv+9Kc/KTs7W3fccYcWLlyoU6dORbpLMe/EiRNqbGwM+nykpaXJ4/Hw+YiAmpoajRo1SuPHj9djjz2mixcvRrpLRmtubpYkZWRkSJLq6up07dq1oM/DhAkTNHbsWD4PNiPU9NGFCxfU3t6uzMzMoOWZmZlqbGyMUK9ij8fj0e9+9ztVVlZqx44dOnHihPLz8/Xll19GumsxreMzwOcj8goLC/Xyyy+rqqpKmzdv1oEDB3T//fervb090l0zks/n0+rVq/W9731Pf/mXfynJ/3lITEzUsGHDgtryebBfzFylG2a6//77A/+eOHGiPB6Pxo0bp3//93/X0qVLI9gzwBnmz58f+Pd3vvMdTZw4Ud/61rdUU1OjmTNnRrBnZlq+fLn+53/+h9q+COFITR+NGDFC8fHxnarXm5qalJWVFaFeYdiwYfr2t7+tzz77LNJdiWkdnwE+H85zxx13aMSIEXxGwmDFihV66623VF1drTFjxgSWZ2Vlqa2tTZcuXQpqz+fBfoSaPkpMTNSUKVNUVVUVWObz+VRVVaXp06dHsGex7fLly/r88881evToSHclpt1+++3KysoK+ny0tLTo8OHDfD4i7MyZM7p48SKfERtZlqUVK1Zo//79ev/993X77bcH3T9lyhQNGjQo6PNw/PhxnTp1is+DzTj91A/FxcVavHix8vLyNG3aNJWXl+vKlStasmRJpLsWM/7hH/5BP/7xjzVu3DidPXtWJSUlio+P14IFCyLdNeNdvnw56Nv+iRMndOzYMWVkZGjs2LFavXq1/vEf/1F/8Rd/odtvv11PPfWUsrOz9ZOf/CRynTbQrV6HjIwMPf3005ozZ46ysrL0+eef64knntCdd96pgoKCCPbaLMuXL1dFRYX+4z/+Q0OHDg3UyaSlpem2225TWlqali5dquLiYmVkZCg1NVUrV67U9OnTdd9990W494aJ9PCraPeb3/zGGjt2rJWYmGhNmzbNOnToUKS7FFPmzZtnjR492kpMTLRycnKsefPmWZ999lmkuxUTqqurLUmdbosXL7Ysyz+s+6mnnrIyMzOtpKQka+bMmdbx48cj22kD3ep1aG1ttWbNmmWNHDnSGjRokDVu3Dhr2bJlVmNjY6S7bZSu/v6SrH/9138NtPnqq6+sxx9/3EpPT7cGDx5sPfjgg1ZDQ0PkOm0ol2VZ1sBHKQAAAHtRUwMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEf4faMufiby7vHcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b608cb1-05a8-417d-8a2a-8816518de943",
   "metadata": {},
   "source": [
    "## - LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf7afa75-8e8c-4318-9c75-4e4029fdc57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: rnn_act='tanh' is ignored when using rnn_type='lstm'\n",
      "At  1.0748326778411865  epoch  1 has training loss  tensor(0.2743, device='cuda:0')  and validation loss  tensor(0.2365, device='cuda:0') .\n",
      "\n",
      "At  6.18251633644104  epoch  5 has training loss  tensor(0.2503, device='cuda:0')  and validation loss  tensor(0.2335, device='cuda:0') .\n",
      "\n",
      "At  12.641299962997437  epoch  10 has training loss  tensor(0.2477, device='cuda:0')  and validation loss  tensor(0.2336, device='cuda:0') .\n",
      "\n",
      "At  19.42552661895752  epoch  15 has training loss  tensor(0.2458, device='cuda:0')  and validation loss  tensor(0.2312, device='cuda:0') .\n",
      "\n",
      "At  26.10793972015381  epoch  20 has training loss  tensor(0.2452, device='cuda:0')  and validation loss  tensor(0.2344, device='cuda:0') .\n",
      "\n",
      "At  32.48069524765015  epoch  25 has training loss  tensor(0.2447, device='cuda:0')  and validation loss  tensor(0.2304, device='cuda:0') .\n",
      "\n",
      "At  38.90877842903137  epoch  30 has training loss  tensor(0.2443, device='cuda:0')  and validation loss  tensor(0.2304, device='cuda:0') .\n",
      "\n",
      "At  45.39295244216919  epoch  35 has training loss  tensor(0.2446, device='cuda:0')  and validation loss  tensor(0.2311, device='cuda:0') .\n",
      "\n",
      "At  51.812114238739014  epoch  40 has training loss  tensor(0.2434, device='cuda:0')  and validation loss  tensor(0.2316, device='cuda:0') .\n",
      "\n",
      "At  58.206992864608765  epoch  45 has training loss  tensor(0.2434, device='cuda:0')  and validation loss  tensor(0.2309, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 36  with validation loss:  tensor(0.2301, device='cuda:0') .\n",
      " The total number of epoch trained is  46 .\n",
      " Training completed in:  59.470561027526855 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.0069,  0.1811,  0.1279],\n",
       "                      [ 0.2459,  0.4032,  0.2393],\n",
       "                      [-0.2490, -0.3000, -0.2406],\n",
       "                      [-0.1185,  0.1376,  0.0902],\n",
       "                      [ 0.2450, -0.0417, -0.2803],\n",
       "                      [ 0.0578,  0.1179, -0.0844],\n",
       "                      [-0.0424,  0.0367,  0.1358],\n",
       "                      [-0.1225, -0.4786, -0.1143],\n",
       "                      [-0.0425, -0.0565, -0.0021],\n",
       "                      [-0.0367,  0.2773,  0.1936],\n",
       "                      [ 0.2026, -0.6658, -0.3960],\n",
       "                      [ 0.2435, -0.0487, -0.2872],\n",
       "                      [ 0.2213, -0.2336,  0.1110],\n",
       "                      [ 0.0607, -0.2668,  0.1187],\n",
       "                      [ 0.1262, -0.0500, -0.0125],\n",
       "                      [ 0.0250,  0.3876,  0.2328],\n",
       "                      [-0.0094,  0.0118, -0.0095],\n",
       "                      [-0.0987, -0.2755,  0.0026],\n",
       "                      [ 0.0923,  0.1470, -0.0529],\n",
       "                      [-0.4250, -0.0608, -0.0056],\n",
       "                      [-0.3656, -0.5486, -0.3285],\n",
       "                      [ 0.1059,  0.1513,  0.0551],\n",
       "                      [ 0.0100,  0.0130, -0.0014],\n",
       "                      [ 0.1909, -0.2455, -0.1381],\n",
       "                      [-0.1148,  0.5762,  0.3146],\n",
       "                      [-0.0052,  0.1987,  0.0629],\n",
       "                      [ 0.0022, -0.0055, -0.0096],\n",
       "                      [ 0.2796,  0.2539,  0.1095],\n",
       "                      [-0.0893,  0.0100, -0.0477],\n",
       "                      [-0.1785, -0.2729,  0.1361],\n",
       "                      [-0.1971, -0.4311, -0.2046],\n",
       "                      [ 0.0139,  0.0293,  0.0283]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 0.0412, -0.3936, -0.0962, -0.0134,  0.3826,  0.1734,  0.0759,  0.0704,\n",
       "                       0.0194, -0.0012,  0.4403, -0.5624, -0.0754,  0.2423,  0.0489,  0.3024,\n",
       "                      -0.0165,  0.2290,  0.0462,  0.4898,  0.4525, -0.3432, -0.0146, -0.2409,\n",
       "                       0.3129,  0.0036,  0.0272, -0.1457, -0.0912,  0.1124, -0.3341, -0.0011],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.2317,  0.1856, -0.1432,  ..., -0.1780,  0.2370,  0.0142],\n",
       "                      [ 0.0170, -0.0407, -0.0063,  ..., -0.0324,  0.1027,  0.0033],\n",
       "                      [-0.1094, -0.3182,  0.2347,  ...,  0.1834,  0.3727,  0.0236],\n",
       "                      ...,\n",
       "                      [ 0.0263,  0.2301, -0.0820,  ...,  0.0773,  0.0254, -0.1379],\n",
       "                      [ 0.4527, -0.3282,  0.0490,  ..., -0.0975, -0.1202,  0.4408],\n",
       "                      [ 0.2176, -0.0699, -0.1599,  ..., -0.0924,  0.0980, -0.0711]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.4456,  0.0507,  0.7273,  ...,  0.1298, -0.1539,  0.5780],\n",
       "                      [-0.1408,  0.1037, -0.1009,  ..., -0.8678,  0.0574, -0.5133],\n",
       "                      [ 0.2311,  0.1507, -0.1981,  ...,  0.9246,  0.5777,  0.2164],\n",
       "                      ...,\n",
       "                      [ 0.2492, -0.8771, -0.6296,  ...,  0.9705,  0.1573, -0.3814],\n",
       "                      [ 0.0062,  0.1042,  0.0538,  ...,  0.9150, -0.3338, -0.3413],\n",
       "                      [ 0.3815,  0.2860, -0.5249,  ...,  0.7534,  0.0410,  0.0828]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.3316, -0.5057,  0.0554, -0.2755, -0.0686, -0.1504, -0.1102, -0.0749,\n",
       "                       0.1811, -0.1539,  0.0111,  0.1353,  0.1077, -0.0717, -0.1701,  0.0916,\n",
       "                      -0.2137, -0.2951, -0.3266, -0.0127,  0.0734, -0.2507,  0.0165, -0.2718,\n",
       "                      -0.0625, -0.4720, -0.2241, -0.6282, -0.3049, -0.5354, -0.1142, -0.3366,\n",
       "                       0.2957,  0.5678,  0.4350, -0.0579,  0.1187,  0.0399,  0.0426,  0.3158,\n",
       "                       0.1435, -0.0359, -0.1362,  0.1402, -0.1535,  0.1162,  0.5572, -0.2148,\n",
       "                      -0.0318,  0.0838, -0.3519, -0.1658, -0.0833, -0.3891,  0.1197, -0.0358,\n",
       "                      -0.0217,  0.0355,  0.3625,  0.2918,  0.1041,  0.0851,  0.2861,  0.0059,\n",
       "                      -0.1761, -0.0271,  0.1748,  0.1153,  0.0097,  0.1038,  0.1728,  0.0741,\n",
       "                       0.2667,  0.0172, -0.1286, -0.0452, -0.0845, -0.0076,  0.0044,  0.1467,\n",
       "                       0.0848,  0.0604, -0.0011,  0.0776,  0.0484,  0.0302,  0.0369,  0.0293,\n",
       "                      -0.0691, -0.2069,  0.0263,  0.2676,  0.0750,  0.1344,  0.0114,  0.1975,\n",
       "                       0.2047, -0.0957, -0.3829, -0.5359,  0.0074,  0.0905, -0.1422,  0.1295,\n",
       "                       0.0152, -0.0562, -0.0028, -0.0343, -0.1382,  0.1141,  0.5125, -0.2931,\n",
       "                      -0.3311,  0.0468, -0.0811,  0.0967, -0.2007, -0.3248, -0.0444, -0.2794,\n",
       "                       0.0376, -0.2631, -0.1056, -0.0707, -0.2245, -0.2669,  0.1758, -0.2160],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-8.8549e-02, -5.2937e-01, -1.3004e-01, -1.7320e-01,  2.6681e-02,\n",
       "                      -2.2231e-01, -1.7193e-01, -1.2021e-01,  1.0195e-01, -1.4612e-02,\n",
       "                      -8.5040e-02,  5.6488e-02, -5.9794e-02, -2.0995e-01, -3.8654e-01,\n",
       "                       7.6246e-02, -1.1156e-01, -3.4893e-01, -5.6934e-02, -1.8513e-01,\n",
       "                       1.8791e-01, -4.2117e-01, -5.1045e-02, -3.6390e-01, -3.2657e-01,\n",
       "                      -4.1814e-01, -1.5989e-01, -7.0820e-01, -3.2840e-01, -6.5348e-01,\n",
       "                      -1.0752e-01, -2.1882e-01,  9.0862e-02,  8.2863e-01,  3.9657e-01,\n",
       "                      -1.0478e-02, -5.0463e-02,  1.7033e-01, -2.6971e-01,  3.1212e-01,\n",
       "                       2.5552e-01, -2.5991e-02, -5.3191e-02,  3.7042e-01, -3.8214e-02,\n",
       "                       1.3545e-01,  4.6551e-01, -2.5957e-01, -5.2676e-02, -1.3714e-01,\n",
       "                      -2.2770e-01, -3.3108e-01,  1.0820e-01, -4.4645e-01,  1.1484e-01,\n",
       "                       1.7134e-01, -2.5024e-02, -3.5697e-02,  8.9490e-02,  2.3356e-01,\n",
       "                       1.2614e-02,  1.0102e-01, -4.3026e-02,  2.0924e-01, -2.3880e-01,\n",
       "                       7.2477e-02,  9.1396e-02,  7.2033e-04, -2.3103e-01, -1.3457e-01,\n",
       "                      -5.5093e-02, -1.5555e-01,  4.6025e-02,  7.4473e-02,  1.1606e-01,\n",
       "                       2.4819e-01, -1.2268e-01, -2.2761e-02,  1.6870e-01, -1.7470e-01,\n",
       "                      -2.5953e-02,  1.0441e-02, -3.1291e-02,  4.5320e-02,  2.4888e-02,\n",
       "                       7.6519e-02,  1.1444e-01, -2.5722e-01,  1.5287e-01, -1.5460e-01,\n",
       "                       4.0361e-02,  1.6580e-01, -1.3105e-01,  2.7144e-02, -1.9940e-02,\n",
       "                      -2.4212e-02, -9.1406e-02, -7.5458e-02, -2.7376e-01, -7.0111e-01,\n",
       "                      -1.6905e-01,  2.0888e-01, -1.7869e-01,  2.9886e-01, -3.7016e-02,\n",
       "                      -2.8346e-02,  4.3057e-03,  1.7122e-01, -2.9766e-03,  1.6104e-01,\n",
       "                       4.0175e-01, -2.8064e-01, -1.2980e-01, -5.4575e-02, -1.7442e-01,\n",
       "                       3.7165e-02,  5.3997e-02, -1.0892e-01, -3.5698e-02, -5.7713e-02,\n",
       "                       8.8507e-02, -4.9803e-01,  3.3861e-03,  2.1898e-02, -3.5680e-01,\n",
       "                      -5.6063e-01,  9.8985e-02,  4.8310e-02], device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.1404,  0.0863, -0.2096,  0.3198,  0.1619,  0.0306, -0.1657,  0.0631,\n",
       "                        0.1982,  0.1974, -0.0836,  0.1116,  0.2887,  0.1497, -0.0251, -0.2737,\n",
       "                       -0.1737, -0.3410,  0.1187,  0.1497, -0.0098,  0.2129,  0.1252,  0.1107,\n",
       "                       -0.2667,  0.3283, -0.0385, -0.0567, -0.1953,  0.3865, -0.0339, -0.0470]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.0666], device='cuda:0'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"lstm\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5aa699c1-a918-4831-9f1b-8697e25bd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7c7a151c30>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41311483",
   "metadata": {},
   "source": [
    "## -GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78d16a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: rnn_act='tanh' is ignored when using rnn_type='gru'\n",
      "A new best validation loss at epoch  1  with validation loss of  tensor(0.2369, device='cuda:0') .\n",
      "At  10.680121421813965  epoch  1 has training loss  tensor(0.2716, device='cuda:0')  and validation loss  tensor(0.2369, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  3  with validation loss of  tensor(0.2345, device='cuda:0') .\n",
      "At  56.6798791885376  epoch  5 has training loss  tensor(0.2511, device='cuda:0')  and validation loss  tensor(0.2367, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  8  with validation loss of  tensor(0.2320, device='cuda:0') .\n",
      "At  115.02766442298889  epoch  10 has training loss  tensor(0.2479, device='cuda:0')  and validation loss  tensor(0.2338, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  15  with validation loss of  tensor(0.2308, device='cuda:0') .\n",
      "At  172.12605667114258  epoch  15 has training loss  tensor(0.2465, device='cuda:0')  and validation loss  tensor(0.2308, device='cuda:0') .\n",
      "\n",
      "A new best validation loss at epoch  17  with validation loss of  tensor(0.2307, device='cuda:0') .\n",
      "A new best validation loss at epoch  20  with validation loss of  tensor(0.2306, device='cuda:0') .\n",
      "At  230.5673007965088  epoch  20 has training loss  tensor(0.2457, device='cuda:0')  and validation loss  tensor(0.2306, device='cuda:0') .\n",
      "\n",
      "At  288.9007501602173  epoch  25 has training loss  tensor(0.2450, device='cuda:0')  and validation loss  tensor(0.2323, device='cuda:0') .\n",
      "\n",
      "At  347.726037979126  epoch  30 has training loss  tensor(0.2444, device='cuda:0')  and validation loss  tensor(0.2312, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 20  with validation loss:  tensor(0.2306, device='cuda:0') .\n",
      " The total number of epoch trained is  30 .\n",
      " Training completed in:  347.726037979126 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-1.3023e-02, -5.2577e-02, -4.3769e-02],\n",
       "                      [-1.6471e-01, -2.6978e-01, -1.1827e-01],\n",
       "                      [ 8.1098e-03,  3.9548e-01,  1.7032e-01],\n",
       "                      [ 1.0297e-01,  3.0256e-01,  1.9833e-01],\n",
       "                      [-5.3722e-02,  1.2781e-01,  1.6324e-02],\n",
       "                      [-4.4063e-02,  1.4656e-01,  5.3353e-02],\n",
       "                      [ 1.5958e-02,  9.6088e-02,  4.4951e-02],\n",
       "                      [-2.0763e-01,  5.1328e-01,  3.5603e-01],\n",
       "                      [ 5.8001e-02,  4.9959e-02,  5.6527e-04],\n",
       "                      [ 3.4749e-02, -2.7079e-01, -5.2085e-02],\n",
       "                      [ 6.4747e-02, -6.3508e-02, -1.1944e-01],\n",
       "                      [ 2.5353e-01, -3.9623e-01, -1.1254e-01],\n",
       "                      [ 1.2358e-01,  2.2784e-01,  2.0974e-02],\n",
       "                      [-1.1127e-01,  4.1138e-02,  7.0099e-02],\n",
       "                      [-8.0805e-02, -3.6706e-01, -3.4515e-01],\n",
       "                      [-1.4346e-01,  2.6591e-01,  8.5640e-02],\n",
       "                      [ 3.6638e-01, -5.1972e-01, -1.2010e-02],\n",
       "                      [ 1.6832e-01,  6.0887e-01,  4.1402e-01],\n",
       "                      [ 3.3092e-01, -3.7482e-01,  6.7985e-02],\n",
       "                      [-1.2321e-01,  2.7079e-01, -2.2371e-02],\n",
       "                      [-1.5599e-02,  5.5040e-03, -1.2268e-02],\n",
       "                      [ 2.1970e-01,  1.1350e-01, -2.3013e-01],\n",
       "                      [ 4.6043e-01,  4.4450e-01,  3.9136e-02],\n",
       "                      [ 1.7177e-01,  2.3377e-01, -1.1012e-01],\n",
       "                      [-3.7799e-01, -1.9885e-01,  1.9659e-01],\n",
       "                      [ 4.2059e-01,  2.6178e-01,  2.1334e-02],\n",
       "                      [-4.4943e-01, -1.5518e-01,  9.2828e-02],\n",
       "                      [ 4.7500e-01,  1.1085e-01,  1.8472e-01],\n",
       "                      [-2.9784e-01, -2.3039e-01,  1.5309e-01],\n",
       "                      [ 1.0869e-01,  2.1060e-01,  2.0164e-01],\n",
       "                      [ 1.4844e-01, -4.5352e-01, -2.8142e-01],\n",
       "                      [ 9.0599e-02, -2.2384e-01, -2.6303e-01]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 0.0136,  0.3197, -0.0358, -0.1676,  0.0863,  0.0353, -0.0219,  0.1077,\n",
       "                      -0.0987, -0.0567, -0.0838,  0.0567, -0.1743,  0.0911,  0.1409,  0.2615,\n",
       "                      -0.1395, -0.2916, -0.0305,  0.2204,  0.0215, -0.1626, -0.5356,  0.1729,\n",
       "                      -0.1442,  0.2886, -0.2916,  0.1046,  0.3744, -0.2302, -0.1585, -0.1046],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.1658,  0.1629, -0.3316,  ...,  0.0047, -0.2737, -0.6306],\n",
       "                      [ 0.2374,  0.2400, -0.4728,  ..., -0.4812,  0.4176,  0.5083],\n",
       "                      [ 0.1801,  0.0941,  0.2354,  ..., -0.0207, -0.0523, -0.1221],\n",
       "                      ...,\n",
       "                      [ 0.0082, -0.0850,  0.0015,  ..., -0.0306,  0.1000,  0.0525],\n",
       "                      [-0.0341, -0.1163, -0.0776,  ...,  0.0915,  0.0868, -0.0038],\n",
       "                      [-0.0290,  0.2188, -0.0475,  ...,  0.0569, -0.1434, -0.0282]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.1427,  0.2102,  0.1884,  ..., -0.0778, -0.1969, -0.6140],\n",
       "                      [-0.0353, -0.1195, -0.2468,  ...,  0.2257, -0.1327,  0.2685],\n",
       "                      [ 0.1517, -0.0852,  0.1601,  ...,  0.5400,  0.0979,  0.2446],\n",
       "                      ...,\n",
       "                      [-0.2213, -0.0944, -0.2286,  ..., -0.0300,  0.1971,  0.3548],\n",
       "                      [-0.2778, -0.0264,  0.0748,  ...,  0.2850,  0.1891,  0.6697],\n",
       "                      [-0.0873, -0.2633,  0.3721,  ...,  0.1473,  0.1238,  0.2476]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.1378,  0.1307,  0.5716,  0.0895,  0.2911,  0.1907,  0.0705, -0.0434,\n",
       "                       0.0496,  0.0476,  0.1319, -0.0608, -0.0750,  0.1667,  0.0787, -0.0040,\n",
       "                       0.0262,  0.0841, -0.2397, -0.2122, -0.0063,  0.0250, -0.0723,  0.0815,\n",
       "                       0.2539,  0.0882,  0.2582,  0.2252,  0.2062, -0.0923,  0.1547,  0.0449,\n",
       "                      -0.1210,  0.0661,  0.5257,  0.6587,  0.1811,  0.1660, -0.0127, -0.1942,\n",
       "                       0.1200,  0.8409, -0.0426,  0.3061,  0.3373, -0.0650,  0.0095, -0.0306,\n",
       "                       0.2025,  0.1238,  0.5103, -0.1714, -0.0753,  0.2646,  0.0552,  0.1064,\n",
       "                       0.4372,  0.4451,  0.4819,  0.9575,  0.8852,  0.1007,  0.0125, -0.0743,\n",
       "                      -0.1410,  0.0308, -0.1464,  0.1501, -0.0605, -0.0029,  0.0132, -0.0268,\n",
       "                      -0.0132, -0.1458,  0.0575, -0.1013, -0.0910, -0.0077,  0.1816,  0.1435,\n",
       "                       0.1512,  0.0643,  0.1489, -0.1372,  0.0750,  0.0359, -0.1319,  0.1240,\n",
       "                      -0.0460, -0.0500,  0.1510,  0.1595, -0.0041,  0.0122, -0.0534,  0.1233],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 1.6238e-01,  1.5407e-01,  4.5181e-01,  8.0218e-02,  1.5373e-01,\n",
       "                       4.0008e-02, -2.0111e-01, -2.8807e-01, -3.3922e-02,  8.3935e-02,\n",
       "                      -1.2040e-01, -2.1730e-01, -2.7832e-02, -1.5523e-01,  1.3269e-01,\n",
       "                       8.9221e-02,  2.2114e-02, -8.0374e-02, -2.1924e-01, -1.2471e-01,\n",
       "                       1.9602e-01, -5.7835e-02, -3.1381e-02, -8.6157e-02,  1.0605e-01,\n",
       "                      -2.1614e-01,  2.6695e-01,  2.6164e-01,  1.8203e-03, -1.9306e-01,\n",
       "                       5.7071e-03, -9.3514e-02, -2.9644e-01,  1.6542e-01,  6.7853e-01,\n",
       "                       6.5614e-01,  2.0628e-01,  1.1938e-02,  1.9651e-01, -8.7450e-02,\n",
       "                       2.9849e-02,  6.3048e-01, -1.3345e-01,  6.2219e-01,  3.3102e-01,\n",
       "                       1.1705e-01, -1.2092e-01,  1.9808e-01,  1.7999e-02,  9.4399e-02,\n",
       "                       5.3302e-01, -1.2712e-01, -7.4956e-02,  4.8259e-01, -7.4558e-02,\n",
       "                       2.2241e-01,  5.7268e-01,  2.6414e-01,  4.1299e-01,  8.6012e-01,\n",
       "                       8.3207e-01,  2.5834e-01,  9.9077e-02, -1.1034e-01,  5.3219e-02,\n",
       "                       1.6177e-01,  1.5256e-01, -1.0532e-02, -2.3208e-01, -1.7470e-01,\n",
       "                      -3.6045e-02,  8.0340e-02, -2.1453e-01, -1.4133e-01,  1.3518e-01,\n",
       "                      -9.1593e-02, -8.6297e-02, -4.3818e-04,  1.7010e-01,  5.6989e-02,\n",
       "                       3.6565e-01,  2.2069e-02,  1.9186e-01,  2.7555e-01,  4.1203e-02,\n",
       "                       3.5401e-02,  7.4882e-02,  1.8220e-01,  7.6312e-02, -1.5644e-01,\n",
       "                       1.6338e-02,  1.3159e-01, -1.1590e-01,  5.3509e-02,  5.2795e-02,\n",
       "                      -1.2434e-01], device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.1283,  0.0486,  0.0666, -0.0963,  0.0164,  0.0917,  0.0988, -0.0895,\n",
       "                        0.0300,  0.0938, -0.1258,  0.0801,  0.0891,  0.1677,  0.1425,  0.2047,\n",
       "                       -0.1833,  0.0764, -0.1595, -0.1485, -0.1620, -0.0746,  0.1179,  0.1830,\n",
       "                       -0.1300,  0.0366, -0.0905, -0.0123, -0.2945,  0.1458, -0.1260, -0.1328]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.0957], device='cuda:0'))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"gru\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef78913",
   "metadata": {},
   "source": [
    "## Training with normalization on both input and target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64325299",
   "metadata": {},
   "source": [
    "I have added normalization functionality to dataset creation function, so we can use normalization as an alternative to scaling by scalar multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3ffa765",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1190590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")\n",
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3079a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts[\"time_id\"]=df_RV_ts[\"time_id\"].astype(int)\n",
    "df_RV_ts[\"stock_id\"]=df_RV_ts[\"stock_id\"].astype(int)\n",
    "df_target[\"time_id\"]=df_target[\"time_id\"].astype(int)\n",
    "df_target[\"stock_id\"]=df_target[\"stock_id\"].astype(int)\n",
    "\n",
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a6245db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:345: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n",
      "Notice: target has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict={\"sub_int_RV\":None,\"target\":None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25243c",
   "metadata": {},
   "source": [
    "## - In following, we see some examples of feat_norm_dict and how it is used for the test dataset's creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d97d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d8c5",
   "metadata": {},
   "source": [
    "We create a deep copy for use of the test dataset creation, we need deep copy since we need to remove the normalization on target. The validation loop will take in the target normalization data and denormalize before calculating loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b790b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_feat_dict=copy.deepcopy(train_dataset.feat_norm_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40163bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0038471398027541486), np.float64(0.0029489987966883967))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict.pop(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "630660e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee121136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131))}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622afc7",
   "metadata": {},
   "source": [
    "As a reminder, do not apply normalization to target of test set. I am choosing to force the target input features to share the same mean and std as the test dataset's corresponding features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de12b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycoeusz/git/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:345: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy[\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict=test_norm_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f6a5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True,num_workers=4,pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True,num_workers=4,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc22998b",
   "metadata": {},
   "source": [
    "## - We first use simple rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f5ab2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  9.519657850265503  epoch  1 has training loss  tensor(0.4854, device='cuda:0')  and validation loss  tensor(0.2401, device='cuda:0') .\n",
      "\n",
      "At  51.078447103500366  epoch  5 has training loss  tensor(0.2699, device='cuda:0')  and validation loss  tensor(0.2436, device='cuda:0') .\n",
      "\n",
      "At  103.81416583061218  epoch  10 has training loss  tensor(0.2595, device='cuda:0')  and validation loss  tensor(0.2380, device='cuda:0') .\n",
      "\n",
      "At  157.26917004585266  epoch  15 has training loss  tensor(0.2579, device='cuda:0')  and validation loss  tensor(0.2362, device='cuda:0') .\n",
      "\n",
      "At  210.40553498268127  epoch  20 has training loss  tensor(0.2572, device='cuda:0')  and validation loss  tensor(0.2400, device='cuda:0') .\n",
      "\n",
      "At  263.6153144836426  epoch  25 has training loss  tensor(0.2563, device='cuda:0')  and validation loss  tensor(0.2399, device='cuda:0') .\n",
      "\n",
      "At  316.95305347442627  epoch  30 has training loss  tensor(0.2559, device='cuda:0')  and validation loss  tensor(0.2386, device='cuda:0') .\n",
      "\n",
      "At  370.6679525375366  epoch  35 has training loss  tensor(0.2559, device='cuda:0')  and validation loss  tensor(0.2358, device='cuda:0') .\n",
      "\n",
      "At  423.8656508922577  epoch  40 has training loss  tensor(0.2549, device='cuda:0')  and validation loss  tensor(0.2373, device='cuda:0') .\n",
      "\n",
      "At  476.60118675231934  epoch  45 has training loss  tensor(0.2554, device='cuda:0')  and validation loss  tensor(0.2400, device='cuda:0') .\n",
      "\n",
      "At  528.8209924697876  epoch  50 has training loss  tensor(0.2549, device='cuda:0')  and validation loss  tensor(0.2360, device='cuda:0') .\n",
      "\n",
      "At  581.405015707016  epoch  55 has training loss  tensor(0.2553, device='cuda:0')  and validation loss  tensor(0.2361, device='cuda:0') .\n",
      "\n",
      "At  633.8949809074402  epoch  60 has training loss  tensor(0.2544, device='cuda:0')  and validation loss  tensor(0.2361, device='cuda:0') .\n",
      "\n",
      "At  686.3474912643433  epoch  65 has training loss  tensor(0.2546, device='cuda:0')  and validation loss  tensor(0.2382, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 46  with validation loss:  tensor(0.2348, device='cuda:0') .\n",
      " The total number of epoch trained is  66 .\n",
      " Training completed in:  696.9668197631836 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 1.8142e-01,  2.3187e-01, -3.4848e-01, -4.0623e-01, -7.8979e-02],\n",
       "                      [ 2.4821e-02,  1.9011e-01,  4.5259e-01, -8.3893e-02,  9.1185e-02],\n",
       "                      [-1.2991e-01,  8.8409e-02, -8.1578e-02, -1.7593e-01,  1.6029e-01],\n",
       "                      [-5.0659e-03,  1.2081e-02,  2.3205e-02,  2.3877e-02, -5.0333e-03],\n",
       "                      [-7.8146e-03, -1.0313e-02,  3.2763e-03,  7.4478e-03, -1.4858e-02],\n",
       "                      [-8.7501e-02,  1.7605e-01,  2.2870e-01,  1.1768e-01, -8.6742e-02],\n",
       "                      [-1.7138e-01, -3.3145e-01,  2.1715e-01,  1.7347e-01, -2.8550e-01],\n",
       "                      [ 1.0519e-02,  4.5636e-01,  1.9308e-01, -1.6397e-01, -7.3479e-02],\n",
       "                      [-2.8474e-03, -1.7264e-01, -2.5335e-01, -1.4629e-01, -2.4327e-02],\n",
       "                      [ 5.1930e-01,  1.6785e-01,  5.8612e-01,  4.5359e-01, -1.9016e-02],\n",
       "                      [-6.4908e-02, -4.7496e-02, -3.9937e-02,  2.8963e-02, -1.1898e-01],\n",
       "                      [ 8.5684e-02,  1.1442e+00,  3.2545e-01, -1.4194e-01, -1.8947e-01],\n",
       "                      [-1.2607e-02, -5.0360e-01, -4.5717e-01, -1.1707e-01, -1.2196e-02],\n",
       "                      [-4.6593e-02,  6.1563e-01,  4.1080e-01,  2.1243e-02, -3.3817e-02],\n",
       "                      [ 1.2543e-01,  9.4981e-01,  5.9515e-01,  4.4431e-01,  1.4774e-01],\n",
       "                      [-1.6987e-02,  1.1214e-02, -1.7116e-01, -1.7943e-01, -6.7206e-02],\n",
       "                      [ 1.3738e-02,  4.7716e-01,  2.8756e-01, -3.1216e-01, -1.0477e-01],\n",
       "                      [ 7.5346e-04,  2.8792e-01, -3.6424e-01, -3.3615e-01, -1.0539e-01],\n",
       "                      [-3.5944e-03, -2.2341e-01,  5.5707e-03,  2.0738e-01,  8.2482e-02],\n",
       "                      [-6.5889e-03, -1.4758e-02, -1.3083e-02,  8.1120e-03, -1.9166e-02],\n",
       "                      [-5.4251e-04,  1.4519e-01,  3.3487e-01,  2.3192e-01,  5.4964e-02],\n",
       "                      [-1.8007e-01, -5.2155e-01,  5.1231e-02,  2.9568e-01, -8.2691e-02],\n",
       "                      [ 4.7452e-03,  5.1116e-01,  4.5147e-01,  1.5334e-01,  2.6831e-02],\n",
       "                      [ 2.8687e-01,  1.0885e+00,  5.0984e-01, -4.7475e-02, -1.7978e-01],\n",
       "                      [ 2.7459e-03, -4.5351e-01, -3.9907e-01, -1.7244e-01, -2.3560e-02],\n",
       "                      [-3.7388e-03, -1.6307e-02, -5.9584e-03,  8.2724e-03, -1.2615e-02],\n",
       "                      [ 1.1074e-01,  5.3334e-01, -1.6118e-01, -3.5512e-02,  1.5746e-01],\n",
       "                      [-2.9142e-03, -2.5904e-02, -3.3857e-02,  7.1617e-04, -2.1512e-02],\n",
       "                      [ 3.7732e-02,  5.6506e-01,  7.4091e-01, -5.4780e-02,  1.6407e-02],\n",
       "                      [ 1.1476e-01, -1.7963e-01, -4.3337e-01, -4.0809e-01, -1.3708e-01],\n",
       "                      [ 1.4363e-01,  3.8112e-01, -2.8481e-01, -3.5658e-01, -8.8296e-02],\n",
       "                      [-4.6614e-03,  5.4831e-02,  8.9014e-02,  5.5177e-02, -3.7476e-03]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 9.8562e-02, -7.2756e-02, -6.8683e-02, -1.9339e-03, -5.5870e-03,\n",
       "                      -4.8425e-02, -9.7037e-02,  4.7705e-03, -1.6966e-03,  2.2057e-01,\n",
       "                      -3.7607e-02,  4.4223e-02, -8.9167e-03, -2.3366e-02,  5.5942e-02,\n",
       "                      -8.6265e-03,  4.8170e-03,  2.7500e-03, -1.3534e-03, -4.3356e-03,\n",
       "                       1.2469e-03, -9.7262e-02,  5.1631e-03,  1.1599e-01,  2.2288e-05,\n",
       "                      -3.4013e-03,  6.4534e-02, -4.7663e-03, -1.9144e-01,  6.2250e-02,\n",
       "                       7.8289e-02, -2.2310e-03], device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.1683,  0.1276,  0.3855,  ..., -0.2331, -0.0979, -0.0086],\n",
       "                      [ 0.3512,  0.1708,  0.1798,  ...,  0.2764,  0.2084,  0.0176],\n",
       "                      [-0.0289, -0.1635, -0.3323,  ...,  0.1267,  0.3314,  0.0342],\n",
       "                      ...,\n",
       "                      [ 0.0205, -0.1985,  0.0980,  ...,  0.0392, -0.0473,  0.0216],\n",
       "                      [-0.3568,  0.0255, -0.0688,  ..., -0.1824, -0.2420, -0.0030],\n",
       "                      [ 0.1214, -0.0626,  0.0524,  ..., -0.0206,  0.0383, -0.0106]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.0145,  0.1376,  0.5210,  ..., -0.0656, -0.1355,  0.1973],\n",
       "                      [ 0.5360, -0.3335, -0.5969,  ...,  0.1249,  0.0282,  0.2043],\n",
       "                      [ 0.2623,  0.1030, -0.0964,  ..., -0.0973, -0.0671,  0.2550],\n",
       "                      ...,\n",
       "                      [ 0.0441,  0.0486, -0.0219,  ..., -0.8294, -0.1344,  0.1928],\n",
       "                      [ 0.2956,  0.0353,  0.3162,  ..., -0.0797,  0.0025,  0.0076],\n",
       "                      [ 0.0786, -0.1112, -0.1535,  ..., -0.1327,  0.0094, -0.5113]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.0037, -0.0933, -0.0702,  0.1364,  0.0163, -0.0172, -0.1370,  0.0638,\n",
       "                       0.1231,  0.0337,  0.0887,  0.0912,  0.0054, -0.0377, -0.0689, -0.1044,\n",
       "                       0.0125,  0.1436, -0.0696,  0.1270, -0.0944, -0.0870, -0.0620, -0.0973,\n",
       "                       0.0336, -0.0334, -0.0313, -0.0668,  0.0536, -0.0849, -0.0285,  0.0016],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.1655,  0.0495, -0.0730, -0.0900, -0.0946,  0.0664,  0.0639,  0.0711,\n",
       "                      -0.1233,  0.0057, -0.0961, -0.1149, -0.0149,  0.0640,  0.0550,  0.0174,\n",
       "                      -0.0842, -0.1653,  0.0460, -0.0823,  0.1662, -0.1470,  0.0908,  0.0319,\n",
       "                       0.0233, -0.0675,  0.0509,  0.0513,  0.0177,  0.0180, -0.0944,  0.0702],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.0489, -0.0042,  0.0207, -0.0413,  0.0015,  0.0031,  0.0024, -0.0111,\n",
       "                        0.0061,  0.0076,  0.0040, -0.0028, -0.0106,  0.0026,  0.0066, -0.0017,\n",
       "                        0.0014,  0.0106,  0.0009,  0.0103,  0.0091,  0.0594,  0.0131, -0.0250,\n",
       "                        0.0116,  0.0102,  0.0047,  0.0015, -0.0081,  0.0027,  0.0318, -0.0058]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0050], device='cuda:0'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1,norm_train_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0703dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20ecaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b859c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fdac7ed6010>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.linspace(1,len(train_loss),len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca95e1",
   "metadata": {},
   "source": [
    "## - Then let's try LSTM RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cff6791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: rnn_act='tanh' is ignored when using rnn_type='lstm'\n"
     ]
    }
   ],
   "source": [
    "RNN_model_norm_ts_lstm=training.RV_RNN_conv(n_diff=2,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1,rnn_type=\"lstm\").to(device=device)\n",
    "\n",
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts_lstm.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6580dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  5.272170782089233  epoch  1 has training loss  tensor(0.3211, device='cuda:0')  and validation loss  tensor(0.2384, device='cuda:0') .\n",
      "\n",
      "At  29.109281539916992  epoch  5 has training loss  tensor(0.2592, device='cuda:0')  and validation loss  tensor(0.2397, device='cuda:0') .\n",
      "\n",
      "At  58.707215547561646  epoch  10 has training loss  tensor(0.2559, device='cuda:0')  and validation loss  tensor(0.2353, device='cuda:0') .\n",
      "\n",
      "At  88.20372796058655  epoch  15 has training loss  tensor(0.2521, device='cuda:0')  and validation loss  tensor(0.2344, device='cuda:0') .\n",
      "\n",
      "At  117.54947423934937  epoch  20 has training loss  tensor(0.2502, device='cuda:0')  and validation loss  tensor(0.2332, device='cuda:0') .\n",
      "\n",
      "At  146.83039712905884  epoch  25 has training loss  tensor(0.2490, device='cuda:0')  and validation loss  tensor(0.2342, device='cuda:0') .\n",
      "\n",
      "At  175.9970042705536  epoch  30 has training loss  tensor(0.2481, device='cuda:0')  and validation loss  tensor(0.2378, device='cuda:0') .\n",
      "\n",
      "At  205.9397692680359  epoch  35 has training loss  tensor(0.2475, device='cuda:0')  and validation loss  tensor(0.2348, device='cuda:0') .\n",
      "\n",
      "At  234.93312549591064  epoch  40 has training loss  tensor(0.2474, device='cuda:0')  and validation loss  tensor(0.2339, device='cuda:0') .\n",
      "\n",
      "At  264.1370825767517  epoch  45 has training loss  tensor(0.2471, device='cuda:0')  and validation loss  tensor(0.2322, device='cuda:0') .\n",
      "\n",
      "At  293.29041719436646  epoch  50 has training loss  tensor(0.2464, device='cuda:0')  and validation loss  tensor(0.2339, device='cuda:0') .\n",
      "\n",
      "At  322.5560989379883  epoch  55 has training loss  tensor(0.2463, device='cuda:0')  and validation loss  tensor(0.2342, device='cuda:0') .\n",
      "\n",
      "At  351.3663237094879  epoch  60 has training loss  tensor(0.2454, device='cuda:0')  and validation loss  tensor(0.2316, device='cuda:0') .\n",
      "\n",
      "At  381.3817331790924  epoch  65 has training loss  tensor(0.2456, device='cuda:0')  and validation loss  tensor(0.2308, device='cuda:0') .\n",
      "\n",
      "At  410.87145376205444  epoch  70 has training loss  tensor(0.2453, device='cuda:0')  and validation loss  tensor(0.2324, device='cuda:0') .\n",
      "\n",
      "At  440.76120686531067  epoch  75 has training loss  tensor(0.2446, device='cuda:0')  and validation loss  tensor(0.2308, device='cuda:0') .\n",
      "\n",
      "At  470.69364285469055  epoch  80 has training loss  tensor(0.2444, device='cuda:0')  and validation loss  tensor(0.2310, device='cuda:0') .\n",
      "\n",
      "At  500.50719356536865  epoch  85 has training loss  tensor(0.2447, device='cuda:0')  and validation loss  tensor(0.2312, device='cuda:0') .\n",
      "\n",
      "At  530.0617787837982  epoch  90 has training loss  tensor(0.2437, device='cuda:0')  and validation loss  tensor(0.2311, device='cuda:0') .\n",
      "\n",
      "At  559.7241089344025  epoch  95 has training loss  tensor(0.2437, device='cuda:0')  and validation loss  tensor(0.2316, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 76  with validation loss:  tensor(0.2307, device='cuda:0') .\n",
      " The total number of epoch trained is  96 .\n",
      " Training completed in:  565.4355671405792 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 2.6276e-01, -3.1087e-02,  7.4673e-02],\n",
       "                      [ 3.0836e-01,  2.6717e-01,  6.2162e-02],\n",
       "                      [-4.4189e-01, -5.6589e-02,  2.8433e-01],\n",
       "                      [ 4.5344e-02, -2.6590e-01, -8.8099e-02],\n",
       "                      [ 2.5238e-01,  4.4319e-01,  1.7863e-01],\n",
       "                      [-1.1489e-01, -2.9253e-01, -2.6346e-01],\n",
       "                      [ 2.4519e-01,  5.2510e-01,  1.0029e-01],\n",
       "                      [ 3.3103e-01,  9.4824e-02,  4.7157e-01],\n",
       "                      [-5.0288e-03,  1.6414e-02,  1.3223e-02],\n",
       "                      [-7.9268e-02,  2.6386e-01,  1.2041e-01],\n",
       "                      [ 1.7881e-01,  2.0440e-01,  1.9558e-01],\n",
       "                      [ 6.2491e-03,  8.6430e-02,  8.8808e-02],\n",
       "                      [-2.6207e-01, -5.3071e-01,  1.5830e-02],\n",
       "                      [-4.5060e-01,  4.1023e-01, -3.3261e-01],\n",
       "                      [ 1.8825e-01,  4.1495e-01,  9.4614e-02],\n",
       "                      [-3.0322e-02, -2.0310e-01, -1.7397e-01],\n",
       "                      [ 1.0106e-02,  4.1803e-01,  2.5995e-01],\n",
       "                      [-7.9525e-02, -4.1445e-01, -2.7007e-01],\n",
       "                      [ 5.6426e-02, -3.0813e-01,  2.7927e-01],\n",
       "                      [ 3.7321e-01,  1.1634e-01,  2.6680e-01],\n",
       "                      [-3.2665e-01,  6.5326e-01,  2.7686e-01],\n",
       "                      [-1.9964e-01,  6.3909e-01,  5.1882e-01],\n",
       "                      [-5.2578e-01, -7.1907e-01, -3.3442e-01],\n",
       "                      [ 4.5790e-02,  3.6509e-01,  1.7847e-02],\n",
       "                      [ 1.1876e-01,  8.0748e-01,  6.9456e-01],\n",
       "                      [-3.2152e-01,  3.6589e-01,  3.9825e-01],\n",
       "                      [ 3.2635e-01,  9.8563e-02, -2.8164e-01],\n",
       "                      [ 2.3182e-01, -3.4158e-04, -3.8028e-01],\n",
       "                      [-1.5407e-01, -6.7645e-01, -5.8693e-01],\n",
       "                      [ 4.2968e-01,  5.9123e-01, -6.6335e-02],\n",
       "                      [-3.8514e-01,  1.2490e-01,  5.0273e-01],\n",
       "                      [-1.5336e-01, -1.1188e+00,  5.4848e-01]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 6.5647e-02, -4.2348e-02,  2.6076e-01,  2.5729e-02, -2.8384e-02,\n",
       "                      -8.4212e-02, -1.5658e-01,  4.5167e-01,  4.5311e-04, -2.5151e-01,\n",
       "                       1.3430e-01,  1.5846e-02, -4.5777e-01,  1.2876e-01,  7.7825e-02,\n",
       "                      -2.4665e-01,  7.5075e-02, -5.7220e-02, -9.2418e-02, -4.3319e-02,\n",
       "                      -3.2121e-01, -1.7724e-01, -2.4374e-02, -1.6367e-01,  7.6426e-02,\n",
       "                       3.4751e-02,  2.5928e-01,  1.6897e-01, -1.0324e-01,  2.4392e-01,\n",
       "                      -2.7373e-01, -6.6996e-02], device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.1426,  0.0308, -0.2446,  ..., -0.1713,  0.1995,  0.0550],\n",
       "                      [-0.1412,  0.4453, -0.4370,  ...,  0.2586, -0.2453, -0.4146],\n",
       "                      [ 0.2931,  0.4624, -0.0745,  ...,  0.2100, -0.2227,  0.0294],\n",
       "                      ...,\n",
       "                      [ 0.0811,  0.6373, -0.6993,  ...,  0.1501, -0.0710, -0.2545],\n",
       "                      [ 0.3324,  0.6082, -0.1777,  ..., -0.2275,  0.0477,  0.1555],\n",
       "                      [-0.1238,  0.1633, -0.3566,  ..., -0.1141, -0.0953, -0.4474]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.3716,  0.0152,  0.1263,  ...,  0.2920,  0.0796, -0.7272],\n",
       "                      [ 0.1416, -1.3463, -1.1020,  ..., -0.9202, -0.4323, -1.0398],\n",
       "                      [ 0.5324, -0.2449,  0.5439,  ...,  0.9361, -0.2177,  0.0857],\n",
       "                      ...,\n",
       "                      [-0.7688,  0.3728,  0.8253,  ...,  0.6764,  0.8984,  0.4459],\n",
       "                      [-0.5503, -0.4761,  0.9502,  ...,  0.6430, -1.6827,  0.9747],\n",
       "                      [ 0.4038,  0.1987, -0.1082,  ...,  0.7313, -1.4317,  0.0353]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-9.1830e-01, -3.1250e-01, -1.4075e-01, -2.2509e-01, -4.3431e-01,\n",
       "                      -2.3073e-01, -4.0730e-01, -9.4180e-01,  1.3665e-01, -2.0156e-01,\n",
       "                       6.4684e-02, -8.0228e-01, -1.9770e-01, -8.9594e-01, -1.9419e-01,\n",
       "                      -3.0447e-01,  6.1004e-03, -2.2566e-01, -4.1353e-01, -3.0002e-01,\n",
       "                      -3.2096e-01, -2.3415e-01, -2.0511e-01, -1.1854e-01, -1.1539e+00,\n",
       "                      -4.0345e-01, -5.6532e-01, -1.7868e-01, -3.9994e-01, -3.1995e-01,\n",
       "                       1.2683e-04, -2.7697e-01,  8.9628e-01, -1.4789e-01,  8.2212e-02,\n",
       "                      -7.4601e-02,  4.0220e-01, -1.2364e-01, -2.4650e-01,  4.2745e-01,\n",
       "                       3.4221e-02, -2.7226e-01, -3.7619e-01, -2.3771e-01, -2.5710e-01,\n",
       "                      -3.9181e-01, -2.9136e-01,  6.3673e-01, -1.5277e-01, -2.0756e-01,\n",
       "                      -1.2716e-01, -4.7426e-01, -4.1072e-01,  4.1140e-02, -5.2933e-02,\n",
       "                      -2.9482e-01, -9.0562e-01,  3.4397e-01,  7.4915e-01,  3.5626e-01,\n",
       "                      -2.4495e-01, -2.4697e-01, -2.9890e-01,  5.9791e-01,  5.4597e-02,\n",
       "                       3.0586e-02, -1.0602e-02, -3.0088e-02, -9.4155e-02,  7.0170e-02,\n",
       "                       1.3236e-01,  1.3330e-03,  9.5753e-02,  1.1374e-01, -8.8383e-02,\n",
       "                       2.9525e-02,  4.6277e-02, -1.5233e-01, -3.6443e-02,  4.5657e-02,\n",
       "                      -1.1652e-01,  9.4511e-02,  1.2062e-01, -9.5805e-02, -1.2414e-02,\n",
       "                       4.3244e-02, -1.3499e-01, -1.3601e-01,  8.6588e-02,  9.5501e-02,\n",
       "                      -1.4577e-02, -2.1549e-02,  6.1911e-02, -7.1785e-02, -8.5298e-02,\n",
       "                       2.2447e-02, -4.4418e-01, -3.9377e-01, -9.2286e-02, -3.3746e-01,\n",
       "                      -5.7704e-01, -1.5866e-01, -3.1446e-01, -2.0436e-01, -1.4012e-01,\n",
       "                      -3.7102e-01, -2.9530e-01, -7.3879e-01, -4.7034e-01, -7.6666e-01,\n",
       "                      -3.8918e-01, -2.5054e-01,  1.4495e-01, -1.6454e-02, -6.0179e-01,\n",
       "                      -5.6022e-01, -4.7997e-01, -7.1472e-01, -9.4217e-01, -7.2832e-01,\n",
       "                      -1.3306e+00, -6.3313e-01, -2.5904e-01, -6.7061e-01, -6.1566e-01,\n",
       "                      -7.0708e-01, -4.3513e-01, -2.8315e-01], device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-1.1126, -0.3188, -0.1268, -0.4702, -0.4009, -0.1478, -0.4884, -0.8530,\n",
       "                       0.0351, -0.3165, -0.1149, -0.6232, -0.3421, -0.6993, -0.0773, -0.2194,\n",
       "                      -0.0931, -0.2627, -0.3633, -0.3112, -0.4325, -0.3604, -0.3155, -0.3881,\n",
       "                      -1.0120, -0.5288, -0.4923, -0.0701, -0.4682, -0.5129, -0.1628, -0.4717,\n",
       "                       0.9004,  0.1327,  0.0950, -0.2506,  0.3611, -0.2077, -0.1053,  0.4448,\n",
       "                      -0.2377, -0.1420, -0.4203, -0.1832, -0.0540, -0.6520, -0.0840,  0.4087,\n",
       "                      -0.1912, -0.0581,  0.0531, -0.6062, -0.1558, -0.1129,  0.0759, -0.1595,\n",
       "                      -0.8478,  0.3007,  0.4594,  0.3231, -0.0886, -0.2893, -0.1472,  0.5480,\n",
       "                      -0.0665, -0.0307,  0.1010,  0.0292, -0.0751, -0.1579,  0.1711, -0.1673,\n",
       "                      -0.1280, -0.0870,  0.0305,  0.0124, -0.0302, -0.0074,  0.1931, -0.0748,\n",
       "                       0.0238, -0.1848, -0.1334, -0.0147,  0.1291, -0.0357,  0.1352,  0.0379,\n",
       "                      -0.1153, -0.0056, -0.0826, -0.0387,  0.0285, -0.0547, -0.1404, -0.0986,\n",
       "                      -0.4982, -0.2816, -0.2701, -0.3476, -0.4616, -0.2225, -0.1064, -0.2075,\n",
       "                       0.0516, -0.5137, -0.2287, -0.4421, -0.5028, -0.6293, -0.4008, -0.3789,\n",
       "                       0.2921, -0.1977, -0.4710, -0.3833, -0.3635, -0.7297, -0.6438, -0.7078,\n",
       "                      -1.0215, -0.7426, -0.0737, -0.4540, -0.5160, -0.4779, -0.3335, -0.0470],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 1.5931e-02,  3.1591e-02, -1.5060e-02,  2.6515e-03,  3.9004e-05,\n",
       "                       -4.2761e-02,  5.4758e-02,  1.0391e-02,  1.2302e-03,  1.5781e-02,\n",
       "                        8.3667e-02, -1.1456e-02,  7.9130e-03, -3.5356e-02, -1.5833e-02,\n",
       "                       -6.0807e-04, -9.4081e-04, -3.4243e-02,  4.7194e-03, -3.0885e-02,\n",
       "                        7.4809e-02,  5.6626e-03,  1.8221e-03,  8.9185e-03,  1.2070e-01,\n",
       "                       -3.3984e-02, -7.7671e-03,  2.0596e-02, -1.1141e-02,  3.7775e-03,\n",
       "                       -1.7986e-02, -5.0395e-03]], device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.0141], device='cuda:0'))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts_lstm,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1,norm_train_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cae17a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fdacf6e4c50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.linspace(1,len(train_loss),len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660ac53",
   "metadata": {},
   "source": [
    "## ** As of now, it seems that a simply scalar multiplication scaling is better for the training than the normalization method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
